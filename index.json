[{"content":"Binder通讯原理 基于Android 11的源码剖析，笔记记录binder通讯原理的实现过程；\n根据网络上的各路大神案例，都是从典型的mediaserver进程开始分析，binder服务的注册注册过程；\nmediaserver进程启动的main函数开始分析，至于init.rc的注册启动进程就跳过了；main函数代码如下：\nint main(int argc __unused, char **argv __unused) { signal(SIGPIPE, SIG_IGN); //创建与binder驱动交互和binder线程池的管理者 sp\u0026lt;ProcessState\u0026gt; proc(ProcessState::self()); //获取ServiceManager的客户端BpServiceManager sp\u0026lt;IServiceManager\u0026gt; sm(defaultServiceManager()); ALOGI(\u0026#34;ServiceManager: %p\u0026#34;, sm.get()); //创建MediaPlayerService服务，和向ServiceManager注册服务 MediaPlayerService::instantiate(); ResourceManagerService::instantiate(); registerExtensions(); ::android::hardware::configureRpcThreadpool(16, false); //启动binder线程池 ProcessState::self()-\u0026gt;startThreadPool(); IPCThreadState::self()-\u0026gt;joinThreadPool(); ::android::hardware::joinRpcThreadpool(); } Binder线程池的注册 每个采用 Binder 的进程会有一个或多个用于处理接收数据的线程，位于 Binder 线程池。采用 Binder 机制的进程最典型的就是应用程序进程了。那应用程序进程的 Binder 线程池是在什么时候启动的呢？\nProcessState 源码位置：frameworks/native/libs/binder/ProcessState.cpp\nProcessState 是 Binder 机制核心之一，它是 Binder 通信的基础，负责与 Binder 驱动的交互与 Binder 线程池的管理。它实现了单例模式，通过 self() 函数获取实例，每个进程仅有一个。\nProcessState创建 实现了单例模式，通过 self() 函数获取实例。来看看它的构造函数，如下：\nProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//访问binder设备，并与binder驱动交互 , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mBinderContextCheckFunc(nullptr) , mBinderContextUserData(nullptr) , mThreadPoolStarted(false) , mThreadPoolSeq(1) , mCallRestriction(CallRestriction::NONE) { // TODO(b/139016109): enforce in build system #if defined(__ANDROID_APEX__) LOG_ALWAYS_FATAL(\u0026#34;Cannot use libbinder in APEX (only system.img libbinder) since it is not stable.\u0026#34;); #endif if (mDriverFD \u0026gt;= 0) { //映射binder驱动，提供通讯的虚拟空间 // mmap the binder, providing a chunk of virtual address space to receive transactions. mVMStart = mmap(nullptr, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); if (mVMStart == MAP_FAILED) { // *sigh* ALOGE(\u0026#34;Using %s failed: unable to mmap transaction memory.\\n\u0026#34;, mDriverName.c_str()); close(mDriverFD); mDriverFD = -1; mDriverName.clear(); } } #ifdef __ANDROID__ LOG_ALWAYS_FATAL_IF(mDriverFD \u0026lt; 0, \u0026#34;Binder driver \u0026#39;%s\u0026#39; could not be opened. Terminating.\u0026#34;, driver); #endif } ProcessState创建是主要步骤是：\n访问binder设备，并与binder驱动交互； 映射binder驱动，提供通讯基础的虚拟空间； 其中提供通讯基础的虚拟空间默认大小是由BINDER_VM_SIZE这个宏来决定的，宏定义如下：\n//binder分配的默认内存大小为1M-8k #define BINDER_VM_SIZE ((1 * 1024 * 1024) - sysconf(_SC_PAGE_SIZE) * 2) 下面来主要看看open_driver函数，函数内容如下：\nstatic int open_driver(const char *driver) { int fd = open(driver, O_RDWR | O_CLOEXEC);//访问binder设备 if (fd \u0026gt;= 0) { int vers = 0; status_t result = ioctl(fd, BINDER_VERSION, \u0026amp;vers);//进行版本比对 if (result == -1) { ALOGE(\u0026#34;Binder ioctl to obtain version failed: %s\u0026#34;, strerror(errno)); close(fd); fd = -1; } if (result != 0 || vers != BINDER_CURRENT_PROTOCOL_VERSION) { ALOGE(\u0026#34;Binder driver protocol(%d) does not match user space protocol(%d)! ioctl() return value: %d\u0026#34;, vers, BINDER_CURRENT_PROTOCOL_VERSION, result); close(fd); fd = -1; } size_t maxThreads = DEFAULT_MAX_BINDER_THREADS; result = ioctl(fd, BINDER_SET_MAX_THREADS, \u0026amp;maxThreads);//设置binder线程池最大线程数 if (result == -1) { ALOGE(\u0026#34;Binder ioctl to set max threads failed: %s\u0026#34;, strerror(errno)); } } else { ALOGW(\u0026#34;Opening \u0026#39;%s\u0026#39; failed: %s\\n\u0026#34;, driver, strerror(errno)); } return fd; } 在open_driver函数中主要处理：\n访问binder设备，通过open函数来实现，具体现在不做详细说明；\n通过ioctl进行binder的版本比较\n通知binder驱动binder线程池的默认最大线程数，而这个最大线程数由DEFAULT_MAX_BINDER_THREADS宏来决定；宏定义如下：\n//默认binder线程池的最大线程数,那加上本身binder默认的最大可并发访问的线程数为16 #define DEFAULT_MAX_BINDER_THREADS 15 启动binder线程池 ProcessState 实例后调用其 startThreadPool 函数，以启动进程的 Binder 线程池。\nvoid ProcessState::startThreadPool() { AutoMutex _l(mLock); if (!mThreadPoolStarted) { mThreadPoolStarted = true; spawnPooledThread(true); } } void ProcessState::spawnPooledThread(bool isMain) { if (mThreadPoolStarted) { String8 name = makeBinderThreadName(); ALOGV(\u0026#34;Spawning new pooled thread, name=%s\\n\u0026#34;, name.string()); sp\u0026lt;Thread\u0026gt; t = new PoolThread(isMain);//创建线程 t-\u0026gt;run(name.string());//启动线程 } } mThreadPoolStarted 用于标识线程池是否已经启动过，以确保 Binder 线程池仅初始化一次。spawnPooledThread() 函数启动了一个 Binder 线程，类型为 PoolThread，函数参数表示这是 Binder 线程池中的第一线程。\nclass PoolThread : public Thread { public: explicit PoolThread(bool isMain) : mIsMain(isMain) { } protected: //PoolThread继承Thread类。t-\u0026gt;run()方法最终调用内部类 PoolThread的threadLoop()方法。 virtual bool threadLoop() { IPCThreadState::self()-\u0026gt;joinThreadPool(mIsMain); return false; } const bool mIsMain; }; PoolThread继承Thread类。t-\u0026gt;run()方法最终调用内部类 PoolThread的threadLoop()方法。在主要创建了IPCThreadState和执行了IPCThreadState的joinThreadPool函数；\n在mediaserver的main函数中后面又执行了一次IPCThreadState的joinThreadPool函数，这两次的区别是一个在子线程执行，一个是在进程主线程执行，**mediaserver默认binder的事件监听线程数是2吗？**这样binder线程池算基本完成！\nIPCThreadState 源码位置：frameworks/native/libs/binder/IPCThreadState.cpp\nIPCThreadState 同样是 Binder 机制的核心之一，它用于管理与 Binder 通信相关线程的状态，每个 Binder 线程都会通过此将自己注册到 Binder 驱动。一个具有多个线程的进程里应该会有多个IPCThreadState对象了，只不过每个线程只需一个IPCThreadState对象而已。所以要放在binder线程池中统一管理。\nIPCThreadState创建 IPCThreadState同样是通过 self() 函数获取实例的。\nIPCThreadState* IPCThreadState::self() { if (gHaveTLS.load(std::memory_order_acquire)) { restart: const pthread_key_t k = gTLS; //获取当前线程是否创建了IPCThreadState，如果创建了直接返回,类似Looper里的ThreadLocal IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k); if (st) return st; return new IPCThreadState; } // Racey, heuristic test for simultaneous shutdown. if (gShutdown.load(std::memory_order_relaxed)) { ALOGW(\u0026#34;Calling IPCThreadState::self() during shutdown is dangerous, expect a crash.\\n\u0026#34;); return nullptr; } pthread_mutex_lock(\u0026amp;gTLSMutex); if (!gHaveTLS.load(std::memory_order_relaxed)) { //创建线程唯一的标签 int key_create_value = pthread_key_create(\u0026amp;gTLS, threadDestructor); if (key_create_value != 0) { pthread_mutex_unlock(\u0026amp;gTLSMutex); ALOGW(\u0026#34;IPCThreadState::self() unable to create TLS key, expect a crash: %s\\n\u0026#34;, strerror(key_create_value)); return nullptr; } gHaveTLS.store(true, std::memory_order_release); } pthread_mutex_unlock(\u0026amp;gTLSMutex); goto restart;//回到开始根据线程唯一标记创建IPCThreadState } self() 函数是一个工厂函数，用于获取 IPCThreadState 实例。self() 根据 pthread_getspecific() 管理每个参与 Binder 通信线程的实例，类似Looper里的ThreadLocal，每个参与 Binder 通信的线程其 IPCThreadState 对象都是相互独立的，保证了后续操作的线程安全。构造函数内容其实，很简单主要是绑定线程唯一标记和初始化输入输出缓冲区；\nIPCThreadState::IPCThreadState() : mProcess(ProcessState::self()), mServingStackPointer(nullptr), mWorkSource(kUnsetWorkSource), mPropagateWorkSource(false), mStrictModePolicy(0), mLastTransactionBinderFlags(0), mCallRestriction(mProcess-\u0026gt;mCallRestriction) { //将线程唯一标签保存的内容设置为自身 pthread_setspecific(gTLS, this); //获取当前进程的pid和uid信息 clearCaller(); //设置输入缓冲区大小，默认256 mIn.setDataCapacity(256); //设置输出缓冲区大小，默认256 mOut.setDataCapacity(256); } IPCThreadState::joinThreadPool函数 joinThreadPool函数就是一个死循环，不断从驱动获取数据;\nvoid IPCThreadState::joinThreadPool(bool isMain) { LOG_THREADPOOL(\u0026#34;**** THREAD %p (PID %d) IS JOINING THE THREAD POOL\\n\u0026#34;, (void*)pthread_self(), getpid()); mOut.writeInt32(isMain ? BC_ENTER_LOOPER : BC_REGISTER_LOOPER); status_t result; do { //清除上一次通讯的输入缓冲区 processPendingDerefs(); //处理下一条信息或者等待 // now get the next command to be processed, waiting if necessary result = getAndExecuteCommand(); if (result \u0026lt; NO_ERROR \u0026amp;\u0026amp; result != TIMED_OUT \u0026amp;\u0026amp; result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF) { LOG_ALWAYS_FATAL(\u0026#34;getAndExecuteCommand(fd=%d) returned unexpected error %d, aborting\u0026#34;, mProcess-\u0026gt;mDriverFD, result); } // Let this thread exit the thread pool if it is no longer // needed and it is not the main process thread. if(result == TIMED_OUT \u0026amp;\u0026amp; !isMain) { break; } } while (result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF); LOG_THREADPOOL(\u0026#34;**** THREAD %p (PID %d) IS LEAVING THE THREAD POOL err=%d\\n\u0026#34;, (void*)pthread_self(), getpid(), result); mOut.writeInt32(BC_EXIT_LOOPER); talkWithDriver(false); } 如此看来IPCThreadState是通过getAndExecuteCommand来不断获取通讯数据的；\nstatus_t IPCThreadState::getAndExecuteCommand() { status_t result; int32_t cmd; //从bender驱动中获取数据 result = talkWithDriver(); if (result \u0026gt;= NO_ERROR) { size_t IN = mIn.dataAvail(); if (IN \u0026lt; sizeof(int32_t)) return result; cmd = mIn.readInt32();//读取命令字段 IF_LOG_COMMANDS() { alog \u0026lt;\u0026lt; \u0026#34;Processing top-level Command: \u0026#34; \u0026lt;\u0026lt; getReturnString(cmd) \u0026lt;\u0026lt; endl; } pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount++; if (mProcess-\u0026gt;mExecutingThreadsCount \u0026gt;= mProcess-\u0026gt;mMaxThreads \u0026amp;\u0026amp; mProcess-\u0026gt;mStarvationStartTimeMs == 0) { mProcess-\u0026gt;mStarvationStartTimeMs = uptimeMillis(); } pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); //进行binder命令解析 result = executeCommand(cmd); pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount--; if (mProcess-\u0026gt;mExecutingThreadsCount \u0026lt; mProcess-\u0026gt;mMaxThreads \u0026amp;\u0026amp; mProcess-\u0026gt;mStarvationStartTimeMs != 0) { int64_t starvationTimeMs = uptimeMillis() - mProcess-\u0026gt;mStarvationStartTimeMs; if (starvationTimeMs \u0026gt; 100) { ALOGE(\u0026#34;binder thread pool (%zu threads) starved for %\u0026#34; PRId64 \u0026#34; ms\u0026#34;, mProcess-\u0026gt;mMaxThreads, starvationTimeMs); } mProcess-\u0026gt;mStarvationStartTimeMs = 0; } pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); } return result; } getAndExecuteCommand的执行步骤：\n通过talkWithDriver向binder驱动获取通讯数据； 读取命令字段，并通过executeCommand函数进行不同命令字段的解析和处理 获取ServiceManager 获取Service Manager是通过defaultServiceManager方法来完成，当进程注册服务(addService)或 获取服务(getService)的过程之前，都需要先调用defaultServiceManager()方法来获取gDefaultServiceManager对象。\n大概流程图如下：\ndefaultServiceManager函数代码如下：\nsp\u0026lt;IServiceManager\u0026gt; defaultServiceManager() { std::call_once(gSmOnce, []() { sp\u0026lt;AidlServiceManager\u0026gt; sm = nullptr; //避免ServiceManager未启动完成，重复请求 while (sm == nullptr) { //获取BpServiceManager sm = interface_cast\u0026lt;AidlServiceManager\u0026gt;(ProcessState::self()-\u0026gt;getContextObject(nullptr)); if (sm == nullptr) { ALOGE(\u0026#34;Waiting 1s on context object on %s.\u0026#34;, ProcessState::self()-\u0026gt;getDriverName().c_str()); sleep(1); } } //创建BpServiceManager代理对象 gDefaultServiceManager = new ServiceManagerShim(sm); }); return gDefaultServiceManager; } ServiceManager的对象获取也采用了一个单例模式，一个进程中只要获取一次即可，对象存储在gDefaultServiceManager中。\n主要流程如下：\n获取ProcessState对象\u0026mdash;ProcessState::self()，在上面的流程中可知ProcessState已获取，存入了全局变量中 获取BpBinder对象 \u0026ndash;ProcessState::getContextObject(nullptr) 获取BpServiceManager对象\u0026mdash;-interface_cast\u0026lt;IServiceManager\u0026gt; 创建ServiceManagerShim对象对BpServiceManager对象进行接管 在ProcessState::getContextObject(nullptr)函数中，主要调用getStrongProxyForHandle进行处理，传入handle=0，那主要看看getStrongProxyForHandle函数；\nsp\u0026lt;IBinder\u0026gt; ProcessState::getStrongProxyForHandle(int32_t handle) { sp\u0026lt;IBinder\u0026gt; result; AutoMutex _l(mLock); //查找handle对应的资源项 handle_entry* e = lookupHandleLocked(handle); if (e != nullptr) { // We need to create a new BpBinder if there isn\u0026#39;t currently one, OR we // are unable to acquire a weak reference on this current one. The // attemptIncWeak() is safe because we know the BpBinder destructor will always // call expungeHandle(), which acquires the same lock we are holding now. // We need to do this because there is a race condition between someone // releasing a reference on this BpBinder, and a new reference on its handle // arriving from the driver. IBinder* b = e-\u0026gt;binder; if (b == nullptr || !e-\u0026gt;refs-\u0026gt;attemptIncWeak(this)) { if (handle == 0) { // Special case for context manager... // The context manager is the only object for which we create // a BpBinder proxy without already holding a reference. // Perform a dummy transaction to ensure the context manager // is registered before we create the first local reference // to it (which will occur when creating the BpBinder). // If a local reference is created for the BpBinder when the // context manager is not present, the driver will fail to // provide a reference to the context manager, but the // driver API does not return status. // // Note that this is not race-free if the context manager // dies while this code runs. // // TODO: add a driver API to wait for context manager, or // stop special casing handle 0 for context manager and add // a driver API to get a handle to the context manager with // proper reference counting. Parcel data; //测试binder是否准备就绪 status_t status = IPCThreadState::self()-\u0026gt;transact( 0, IBinder::PING_TRANSACTION, data, nullptr, 0); if (status == DEAD_OBJECT) return nullptr; } //当handle值所对应的IBinder不存在或弱引用无效时，创建一个BpBinder，handle=0 //create的实现其实就是 new BpBinder(0,trackedUid) b = BpBinder::create(handle); e-\u0026gt;binder = b; if (b) e-\u0026gt;refs = b-\u0026gt;getWeakRefs(); result = b; } else { // This little bit of nastyness is to allow us to add a primary // reference to the remote proxy when this team doesn\u0026#39;t have one // but another team is sending the handle to us. result.force_set(b); e-\u0026gt;refs-\u0026gt;decWeak(this); } } return result; } getStrongProxyForHandle的过程也很简单，当handle=0所对应的IBinder不存在或弱引用无效时，先看下Binder是否已经准备就绪，即ServiceManager是否已经就绪，准备好后，创建一个BpBinder(0,trackedUid)，创建BpBinder对象中会将handle相对应Binder的弱引用增加1，最终返回一个BpBiner的对象。\n真正获取ServiceManager的代理对象的是 interface_cast\u0026lt;AidlServiceManager\u0026gt; 方法。零号引用的 BpBinder 对象传入 interface_cast() 模版函数，会最终通过 IMPLEMENT_META_INTERFACE() 宏，生成 BpServiceManager 对象。该对象被传入 ServiceManagerShim 的构造函数中，成为其成员变量 mTheRealServiceManager。\n#define DO_NOT_DIRECTLY_USE_ME_IMPLEMENT_META_INTERFACE(INTERFACE, NAME)\\ const ::android::StaticString16 \\ I##INTERFACE##_descriptor_static_str16(__IINTF_CONCAT(u, NAME));\\ const ::android::String16 I##INTERFACE::descriptor( \\ I##INTERFACE##_descriptor_static_str16); \\ const ::android::String16\u0026amp; \\ I##INTERFACE::getInterfaceDescriptor() const { \\ return I##INTERFACE::descriptor; \\ } \\ ::android::sp\u0026lt;I##INTERFACE\u0026gt; I##INTERFACE::asInterface( \\ const ::android::sp\u0026lt;::android::IBinder\u0026gt;\u0026amp; obj) \\ { \\ ::android::sp\u0026lt;I##INTERFACE\u0026gt; intr; \\ if (obj != nullptr) { \\ intr = static_cast\u0026lt;I##INTERFACE*\u0026gt;( \\ obj-\u0026gt;queryLocalInterface( \\ I##INTERFACE::descriptor).get()); \\ if (intr == nullptr) { \\ intr = new Bp##INTERFACE(obj); \\ } \\ } \\ return intr; \\ } \\ std::unique_ptr\u0026lt;I##INTERFACE\u0026gt; I##INTERFACE::default_impl; \\ bool I##INTERFACE::setDefaultImpl(std::unique_ptr\u0026lt;I##INTERFACE\u0026gt; impl)\\ { \\ /* Only one user of this interface can use this function */ \\ /* at a time. This is a heuristic to detect if two different */ \\ /* users in the same process use this function. */ \\ assert(!I##INTERFACE::default_impl); \\ if (impl) { \\ I##INTERFACE::default_impl = std::move(impl); \\ return true; \\ } \\ return false; \\ } \\ const std::unique_ptr\u0026lt;I##INTERFACE\u0026gt;\u0026amp; I##INTERFACE::getDefaultImpl() \\ { \\ return I##INTERFACE::default_impl; \\ } \\ I##INTERFACE::I##INTERFACE() { } \\ I##INTERFACE::~I##INTERFACE() { } \\ Android 10在此之后，BpServiceManager 不再通过手动实现，而是采用 AIDL（文件为 IServiceManager.aidl），生成 IServiceManager、BnServiceManager、BpServiceManager 的头文件及具体实现。\n关于通过 AIDL 生成 C++ 代码，详见 Generating C++ Binder Interfaces with aidl-cpp\nBpServiceManager的继承关系图如下：\nBinder 数据传输流程 Binder 数据发送过程 从addService函数来分析Binder的数据传输流程；从获取servicemanage的章节我们得知，servicemanage的Client端是BpServiceManager，那我们直接来看BpServiceManager中的addService函数，如下：\nvirtual status_t addService(const String16\u0026amp; name, const sp\u0026lt;IBinder\u0026gt;\u0026amp; service, bool allowIsolated, int dumpsysPriority) { Parcel data, reply; data.writeInterfaceToken(IServiceManager::getInterfaceDescriptor()); data.writeString16(name); data.writeStrongBinder(service); data.writeInt32(allowIsolated ? 1 : 0); data.writeInt32(dumpsysPriority); status_t err = remote()-\u0026gt;transact(ADD_SERVICE_TRANSACTION, data, \u0026amp;reply); return err == NO_ERROR ? reply.readExceptionCode() : err; } //Parcel status_t Parcel::writeStrongBinder(const sp\u0026lt;IBinder\u0026gt;\u0026amp; val) { return flattenBinder(val); } status_t Parcel::flattenBinder(const sp\u0026lt;IBinder\u0026gt;\u0026amp; binder) { flat_binder_object obj; if (IPCThreadState::self()-\u0026gt;backgroundSchedulingDisabled()) { /* minimum priority for all nodes is nice 0 */ obj.flags = FLAT_BINDER_FLAG_ACCEPTS_FDS; } else { /* minimum priority for all nodes is MAX_NICE(19) */ obj.flags = 0x13 | FLAT_BINDER_FLAG_ACCEPTS_FDS; } if (binder != nullptr) { BBinder *local = binder-\u0026gt;localBinder(); if (!local) { BpBinder *proxy = binder-\u0026gt;remoteBinder(); if (proxy == nullptr) { ALOGE(\u0026#34;null proxy\u0026#34;); } const int32_t handle = proxy ? proxy-\u0026gt;handle() : 0; obj.hdr.type = BINDER_TYPE_HANDLE; obj.binder = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ obj.handle = handle; obj.cookie = 0; } else { if (local-\u0026gt;isRequestingSid()) { obj.flags |= FLAT_BINDER_FLAG_TXN_SECURITY_CTX; } obj.hdr.type = BINDER_TYPE_BINDER;//type被赋值为BINDER_TYPE_BINDER，即表示此时的obj是一个Binder实体对象 obj.binder = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local-\u0026gt;getWeakRefs());//记录Binder弱引用指针地址 obj.cookie = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local);//记录Binder实体的指针 } } else { obj.hdr.type = BINDER_TYPE_BINDER; obj.binder = 0; obj.cookie = 0; } return finishFlattenBinder(binder, obj); } 从代码分析Parcel通过writeStrongBinder函数把service封装成flat_binder_object结构体，其中保存了service的Binder弱引用指针地址和Binder实体的指针；flat_binder_object结构体定义如下：\nstruct flat_binder_object { struct binder_object_header\thdr; __u32\tflags; /* 8 bytes of data. */ union { binder_uintptr_t\tbinder;\t/* local object *///记录Binder弱引用指针地址 __u32\thandle;\t/* remote object *///这个在binder驱动中查找Binder弱引用指针用的关键key，目前这样理解 }; /* extra data associated with local object */ binder_uintptr_t\tcookie;//记录binder的实体指针 }; remote()-\u0026gt;transact()将传出，从defaultServiceManager分析总结remote对应的是在getStrongProxyForHandle函数中创建的BpBinder;而在BpBinder的transact函数中，主要是执行了status_t status = IPCThreadState::self()-\u0026gt;transact( mHandle, code, data, reply, flags);,接下来我们就分析一下IPCThreadState的transact函数；\nstatus_t IPCThreadState::transact(int32_t handle, uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { status_t err; flags |= TF_ACCEPT_FDS; IF_LOG_TRANSACTIONS() { TextOutput::Bundle _b(alog); alog \u0026lt;\u0026lt; \u0026#34;BC_TRANSACTION thr \u0026#34; \u0026lt;\u0026lt; (void*)pthread_self() \u0026lt;\u0026lt; \u0026#34; / hand \u0026#34; \u0026lt;\u0026lt; handle \u0026lt;\u0026lt; \u0026#34; / code \u0026#34; \u0026lt;\u0026lt; TypeCode(code) \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; indent \u0026lt;\u0026lt; data \u0026lt;\u0026lt; dedent \u0026lt;\u0026lt; endl; } LOG_ONEWAY(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; SEND from pid %d uid %d %s\u0026#34;, getpid(), getuid(), (flags \u0026amp; TF_ONE_WAY) == 0 ? \u0026#34;READ REPLY\u0026#34; : \u0026#34;ONE WAY\u0026#34;); //将数据打包塞到 mOut 里 err = writeTransactionData(BC_TRANSACTION, flags, handle, code, data, nullptr); if (err != NO_ERROR) { if (reply) reply-\u0026gt;setError(err); return (mLastError = err); } if ((flags \u0026amp; TF_ONE_WAY) == 0) { if (UNLIKELY(mCallRestriction != ProcessState::CallRestriction::NONE)) { if (mCallRestriction == ProcessState::CallRestriction::ERROR_IF_NOT_ONEWAY) { ALOGE(\u0026#34;Process making non-oneway call (code: %u) but is restricted.\u0026#34;, code); CallStack::logStack(\u0026#34;non-oneway call\u0026#34;, CallStack::getCurrent(10).get(), ANDROID_LOG_ERROR); } else /* FATAL_IF_NOT_ONEWAY */ { LOG_ALWAYS_FATAL(\u0026#34;Process may not make oneway calls (code: %u).\u0026#34;, code); } } #if 0 if (code == 4) { // relayout ALOGI(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; CALLING transaction 4\u0026#34;); } else { ALOGI(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; CALLING transaction %d\u0026#34;, code); } #endif if (reply) { //不是 one way 调用，需要等待回复 err = waitForResponse(reply); } else {//one way 调用，不用等待回复 Parcel fakeReply; err = waitForResponse(\u0026amp;fakeReply); } #if 0 if (code == 4) { // relayout ALOGI(\u0026#34;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; RETURNING transaction 4\u0026#34;); } else { ALOGI(\u0026#34;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; RETURNING transaction %d\u0026#34;, code); } #endif IF_LOG_TRANSACTIONS() { TextOutput::Bundle _b(alog); alog \u0026lt;\u0026lt; \u0026#34;BR_REPLY thr \u0026#34; \u0026lt;\u0026lt; (void*)pthread_self() \u0026lt;\u0026lt; \u0026#34; / hand \u0026#34; \u0026lt;\u0026lt; handle \u0026lt;\u0026lt; \u0026#34;: \u0026#34;; if (reply) alog \u0026lt;\u0026lt; indent \u0026lt;\u0026lt; *reply \u0026lt;\u0026lt; dedent \u0026lt;\u0026lt; endl; else alog \u0026lt;\u0026lt; \u0026#34;(none requested)\u0026#34; \u0026lt;\u0026lt; endl; } } else { err = waitForResponse(nullptr, nullptr); } return err; } IPCThreadState 中有 mIn、mOut 两个 Parcel 数据，mIn 用来存放从别处读取而来的数据，mOut 存放要写入到别处的数据，而在transact函数中关键代码只有两行（writeTransactionData和waitForResponse），从命名上来看就是一次请求和接收应答的过程。在 writeTransactionData函数中将一堆参数组装进binder_transaction_data结构体并存放到 mOut，准备写入到 binder 驱动;\nstatus_t IPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags, int32_t handle, uint32_t code, const Parcel\u0026amp; data, status_t* statusBuffer) { binder_transaction_data tr; tr.target.ptr = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ tr.target.handle = handle; tr.code = code; tr.flags = binderFlags; tr.cookie = 0; tr.sender_pid = 0; tr.sender_euid = 0; //检查数据是否有效 const status_t err = data.errorCheck(); if (err == NO_ERROR) { tr.data_size = data.ipcDataSize(); tr.data.ptr.buffer = data.ipcData(); tr.offsets_size = data.ipcObjectsCount()*sizeof(binder_size_t); tr.data.ptr.offsets = data.ipcObjects(); } else if (statusBuffer) { tr.flags |= TF_STATUS_CODE; *statusBuffer = err; tr.data_size = sizeof(status_t); tr.data.ptr.buffer = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(statusBuffer); tr.offsets_size = 0; tr.data.ptr.offsets = 0; } else { return (mLastError = err); } mOut.writeInt32(cmd); mOut.write(\u0026amp;tr, sizeof(tr)); return NO_ERROR; } binder_transaction_data结构体在中组装的Parcel数据：\n​\t图片来源\nbinder_transaction_data结构体定义如下：\nstruct binder_transaction_data { /* The first two are only used for bcTRANSACTION and brTRANSACTION, * identifying the target and contents of the transaction. */ union { /* target descriptor of command transaction */ __u32\thandle; /* target descriptor of return transaction */ binder_uintptr_t ptr; } target; binder_uintptr_t\tcookie;\t/* target object cookie */ __u32\tcode;\t/* transaction command */ /* General information about the transaction. */ __u32\tflags; pid_t\tsender_pid; uid_t\tsender_euid; binder_size_t\tdata_size;\t/* number of bytes of data */ binder_size_t\toffsets_size;\t/* number of bytes of offsets */ /* If this transaction is inline, the data immediately * follows here; otherwise, it ends with a pointer to * the data buffer. */ union { struct { /* transaction data */ binder_uintptr_t\tbuffer; /* offsets from buffer to flat_binder_object structs */ binder_uintptr_t\toffsets; } ptr; __u8\tbuf[8]; } data; }; waitForResponse函数去实际执行写入到 binder 驱动，简化后的 waitForResponse函数代码如下:\nstatus_t IPCThreadState::waitForResponse(Parcel *reply, status_t *acquireResult) { uint32_t cmd; int32_t err; while (1) { //进一步调用 talkWithDriver 去执行写入数据到 binder 驱动 if ((err=talkWithDriver()) \u0026lt; NO_ERROR) break; err = mIn.errorCheck();//检查数据有效性 if (err \u0026lt; NO_ERROR) break; if (mIn.dataAvail() == 0) continue;//检查数据有效性 cmd = (uint32_t)mIn.readInt32();//拿到 binder 驱动发过来的命令 switch (cmd) { //处理命令 case BR_TRANSACTION_COMPLETE: if (!reply \u0026amp;\u0026amp; !acquireResult) goto finish; break; case BR_DEAD_REPLY: err = DEAD_OBJECT; goto finish; case BR_FAILED_REPLY: err = FAILED_TRANSACTION; goto finish; case BR_ACQUIRE_RESULT: { ... } goto finish; case BR_REPLY: { ... } goto finish; default://其他命令在 executeCommand 方法中处理 err = executeCommand(cmd); if (err != NO_ERROR) goto finish; break; } } finish: if (err != NO_ERROR) { if (acquireResult) *acquireResult = err; if (reply) reply-\u0026gt;setError(err); mLastError = err; } return err; } 可以看到 waitForResponse中并没有直接执行写入数据到 binder，而是进一步调用 talkWithDriver 去处理，随后 waitForResponse处理了由 binder 驱动发送过来的命令,因为在BpServiceManager传过来的reply不等于空，所以正常的逻辑是收到BR_REPLY才退出循环；\n由 transact到 waitForResponse，已经将要发送的数据准备好，并对后续 binder 驱动的回复也做了处理，但还没看到真正写入数据给 binder 驱动的代码，但已经知道就在 talkWithDriver函数中，此函数中主要做了三个工作：\n将要发送的数据封装成binder_write_read结构体； 通过ioctl把binder_write_read结构体数据写入binder驱动； 处理驱动回复 status_t IPCThreadState::talkWithDriver(bool doReceive) { //binder驱动是否打开 if (mProcess-\u0026gt;mDriverFD \u0026lt; 0) { return -EBADF; } //binder 驱动接受的数据格式 binder_write_read bwr; // Is the read buffer empty? const bool needRead = mIn.dataPosition() \u0026gt;= mIn.dataSize(); const size_t outAvail = (!doReceive || needRead) ? mOut.dataSize() : 0; bwr.write_size = outAvail; //要写入的数据量 bwr.write_buffer = (uintptr_t)mOut.data(); //要写入的数据 // This is what we\u0026#39;ll read. if (doReceive \u0026amp;\u0026amp; needRead) { bwr.read_size = mIn.dataCapacity();//要读取的数据量 bwr.read_buffer = (uintptr_t)mIn.data();//存放读取数据的内存空间 } else { bwr.read_size = 0; bwr.read_buffer = 0; } // Return immediately if there is nothing to do. if ((bwr.write_size == 0) \u0026amp;\u0026amp; (bwr.read_size == 0)) return NO_ERROR; bwr.write_consumed = 0; bwr.read_consumed = 0; status_t err; do { #if defined(__ANDROID__) //通过ioctl写入binder驱动 if (ioctl(mProcess-\u0026gt;mDriverFD, BINDER_WRITE_READ, \u0026amp;bwr) \u0026gt;= 0) err = NO_ERROR; else err = -errno; #else err = INVALID_OPERATION; #endif if (mProcess-\u0026gt;mDriverFD \u0026lt; 0) { err = -EBADF; } } while (err == -EINTR); if (err \u0026gt;= NO_ERROR) { if (bwr.write_consumed \u0026gt; 0) { //成功写入了数据 if (bwr.write_consumed \u0026lt; mOut.dataSize()) else { //输出数据已经写入binder驱动，清空输出缓冲区 mOut.setDataSize(0); processPostWriteDerefs(); } } //存在回传数据，重置输入缓冲区的读取下标 if (bwr.read_consumed \u0026gt; 0) {//成功读取到了数据 mIn.setDataSize(bwr.read_consumed); mIn.setDataPosition(0); } return NO_ERROR; } return err; } 在IPCThreadState.h定义talkWithDriver 函数时，doReceive的默认值为true,waitForResponse() 中没有传入参数，所以这里的 doReceive 为 true。\nstatus_t talkWithDriver(bool doReceive=true); binder_write_read 是 binder 驱动与用户态共用的、存储读写操作的结构体，在 binder 驱动内部依赖 binder_write_read 决定是要读取还是写入数据：其内部变量 read_size\u0026gt;0 则代表要读取数据，write_size\u0026gt;0 代表要写入数据，若都大于 0 则先写入，后读取。binder_write_read结构体定义如下：\nstruct binder_write_read { binder_size_t\twrite_size;\t/* bytes to write */ //要写入的字节数,write_buffer的总字节数 binder_size_t\twrite_consumed;\t/* bytes consumed by driver *///驱动程序占用的字节数,write_buffer已消费的字节数 binder_uintptr_t\twrite_buffer;//写缓冲数据的指针 binder_size_t\tread_size;\t/* bytes to read *///要读的字节数,read_buffer的总字节数 binder_size_t\tread_consumed;\t/* bytes consumed by driver *///驱动程序占用的字节数,read_buffer已消费的字节数 binder_uintptr_t\tread_buffer;//读缓存数据的指针 }; 这样基本完成了数据的发送过程，其中主要的数据类型结构体一定要记住，很重要；\nflat_binder_object封装service的结构体，其中重要的参数是binder、handle、cookie binder_transaction_data组装Parcel数据的结构体; binder_write_read 是binder 驱动与用户态共用的、存储读写操作的结构体 Binder 数据接收过程 Binder 线程用于在 Server 中接收处理从 Binder 驱动发送来的数据。startThreadPool提及的函数 IPCThreadState.joinThreadPool 将自己注册到 Binder 线程池，等待接收数据。\n在joinThreadPool 函数中，循环执行getAndExecuteCommand,调用 talkWithDriver 从 mIn 窗口解析出需要执行的命令后，执行 executeCommand。在executeCommand的BR_TRANSACTION分支，其中 the_context_object 为 BBinder 对象，也就是 Server 的 Binder 本体。BBinder.transact 会再调用 BBinder.onTransact 函数，实现 Server 进程 Binder 的调用。\n而在ServiceManager采用了LooperCallback方式监听binder数据，最终也是循环执行getAndExecuteCommand；这部分的分析会在创建ServiceManager进程详细分析；\n接收数据时也在talkWithDriver中ioctl读写获取一个binder_write_read结构体，在executeCommand的BR_TRANSACTION分支中在把数据进一步解析binder_transaction_data结构体并将相应的输入数据转换buffer，buffer是Parcel对象，在 BBinder 的onTransact函数会在BnServiceManager重载onTransact函数；\nstatus_t BnServiceManager::onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { //printf(\u0026#34;ServiceManager received: \u0026#34;); data.print(); switch(code) { case GET_SERVICE_TRANSACTION: { CHECK_INTERFACE(IServiceManager, data, reply); String16 which = data.readString16(); sp\u0026lt;IBinder\u0026gt; b = const_cast\u0026lt;BnServiceManager*\u0026gt;(this)-\u0026gt;getService(which); reply-\u0026gt;writeStrongBinder(b); return NO_ERROR; } break; case CHECK_SERVICE_TRANSACTION: { CHECK_INTERFACE(IServiceManager, data, reply); String16 which = data.readString16(); sp\u0026lt;IBinder\u0026gt; b = const_cast\u0026lt;BnServiceManager*\u0026gt;(this)-\u0026gt;checkService(which); reply-\u0026gt;writeStrongBinder(b); return NO_ERROR; } break; case ADD_SERVICE_TRANSACTION: { CHECK_INTERFACE(IServiceManager, data, reply); String16 which = data.readString16(); sp\u0026lt;IBinder\u0026gt; b = data.readStrongBinder(); status_t err = addService(which, b); reply-\u0026gt;writeInt32(err); return NO_ERROR; } break; case LIST_SERVICES_TRANSACTION: { CHECK_INTERFACE(IServiceManager, data, reply); Vector\u0026lt;String16\u0026gt; list = listServices(); const size_t N = list.size(); reply-\u0026gt;writeInt32(N); for (size_t i=0; i\u0026lt;N; i++) { reply-\u0026gt;writeString16(list[i]); } return NO_ERROR; } break; default: return BBinder::onTransact(code, data, reply, flags); } } 在ADD_SERVICE_TRANSACTION分支，会通过Parcel的readStrongBinder函数将数据读取flat_binder_object结构体，再获取IBinder弱引用指针地址；其中主要执行的函数是unflattenBinder;\nstatus_t Parcel::unflattenBinder(sp\u0026lt;IBinder\u0026gt;* out) const { const flat_binder_object* flat = readObject(false); if (flat) { switch (flat-\u0026gt;hdr.type) { case BINDER_TYPE_BINDER: { sp\u0026lt;IBinder\u0026gt; binder = reinterpret_cast\u0026lt;IBinder*\u0026gt;(flat-\u0026gt;cookie); return finishUnflattenBinder(binder, out); } case BINDER_TYPE_HANDLE: { sp\u0026lt;IBinder\u0026gt; binder = ProcessState::self()-\u0026gt;getStrongProxyForHandle(flat-\u0026gt;handle); return finishUnflattenBinder(binder, out); } } } return BAD_TYPE; } 最后会调用ServiceManager的addService函数；\nStatus ServiceManager::addService(const std::string\u0026amp; name, const sp\u0026lt;IBinder\u0026gt;\u0026amp; binder, bool allowIsolated, int32_t dumpPriority) { auto ctx = mAccess-\u0026gt;getCallingContext(); // apps cannot add services if (multiuser_get_app_id(ctx.uid) \u0026gt;= AID_APP) { return Status::fromExceptionCode(Status::EX_SECURITY); } if (!mAccess-\u0026gt;canAdd(ctx, name)) { return Status::fromExceptionCode(Status::EX_SECURITY); } if (binder == nullptr) { return Status::fromExceptionCode(Status::EX_ILLEGAL_ARGUMENT); } if (!isValidServiceName(name)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Invalid service name: \u0026#34; \u0026lt;\u0026lt; name; return Status::fromExceptionCode(Status::EX_ILLEGAL_ARGUMENT); } // implicitly unlinked when the binder is removed if (binder-\u0026gt;remoteBinder() != nullptr \u0026amp;\u0026amp; binder-\u0026gt;linkToDeath(this) != OK) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not linkToDeath when adding \u0026#34; \u0026lt;\u0026lt; name; return Status::fromExceptionCode(Status::EX_ILLEGAL_STATE); } auto entry = mNameToService.emplace(name, Service { .binder = binder, .allowIsolated = allowIsolated, .dumpPriority = dumpPriority, .debugPid = ctx.debugPid, }); auto it = mNameToRegistrationCallback.find(name); if (it != mNameToRegistrationCallback.end()) { for (const sp\u0026lt;IServiceCallback\u0026gt;\u0026amp; cb : it-\u0026gt;second) { entry.first-\u0026gt;second.guaranteeClient = true; // permission checked in registerForNotifications cb-\u0026gt;onRegistration(name, binder); } } return Status::ok(); } addService函数中主要执行的是将Ibinder对象封装成Service结构体，并于name为key插入mNameToService中，而mNameToService是一个std::map\u0026lt;std::string, Service\u0026gt;；这样addService在除了内核部分的代码算是基本完成;binder驱动中的数据传递会在binder驱动分析中进行解析；\n数据传递过程如下：\nServiceManager进程创建 启动的main函数在frameworks/native/cmds/servicemanager/main.cpp中，其中关键步骤和media进行类型；\n创建ProcessState,ServiceManager进程没有调用self，而是通过initWithDriver 创建，其实关键代码还是一样的，实现了单例模式，通过initWithDriver 获取实例；并通过setThreadPoolMaxThreadCount设置最大线程数为0； 创建ServiceManager实例，同样使用addService函数同样把ServiceManager插入mNameToService中；并创建IPCThreadState实通过setTheContextObject设置the_context_object为ServiceManager ; 通过ProcessState的becomeContextManager函数设置ServiceManager进程为binder驱动的上下文管理者； 通过Looper::prepare创建Looper,Looper也是和IPCThreadState一样线程单例，这里可以理解成是java中handle事件中的looper,后续会再对native层的Looper进行详细分析；并BinderCallback的setupTo注册Looper的事件监听和ClientCallbackCallback的setupTo注册Looper的事件； 进入死循环，调用 looper-\u0026gt;pollAll函数，实则是在epoll_wait等待消息; int main(int argc, char** argv) { if (argc \u0026gt; 2) { LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;usage: \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; [binder driver]\u0026#34;; } const char* driver = argc == 2 ? argv[1] : \u0026#34;/dev/binder\u0026#34;; //创建ProcessState，并打开binder驱动 sp\u0026lt;ProcessState\u0026gt; ps = ProcessState::initWithDriver(driver); //设置最大线程数为了0 ps-\u0026gt;setThreadPoolMaxThreadCount(0); ps-\u0026gt;setCallRestriction(ProcessState::CallRestriction::FATAL_IF_NOT_ONEWAY); //创建ServiceManager实例 sp\u0026lt;ServiceManager\u0026gt; manager = new ServiceManager(std::make_unique\u0026lt;Access\u0026gt;()); if (!manager-\u0026gt;addService(\u0026#34;manager\u0026#34;, manager, false /*allowIsolated*/, IServiceManager::DUMP_FLAG_PRIORITY_DEFAULT).isOk()) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not self register servicemanager\u0026#34;; } //创建IPCThreadState实例和设置IPCThreadState的上下文管理者 IPCThreadState::self()-\u0026gt;setTheContextObject(manager); //设置ServiceManager进程为binder的上下文管理者 ps-\u0026gt;becomeContextManager(nullptr, nullptr); //创建looper sp\u0026lt;Looper\u0026gt; looper = Looper::prepare(false /*allowNonCallbacks*/); //创建looper事件监听回调 BinderCallback::setupTo(looper); //把ClientCallbackCallback作为回调，注册进入Lopper，其中创建了一个定时器对象，5秒跑一次 ClientCallbackCallback::setupTo(looper, manager); while(true) { //循环等待驱动是否有事件返回 looper-\u0026gt;pollAll(-1); } // should not be reached return EXIT_FAILURE; } 再BinderCallback中如果有事件返回会回调handleEvent，然后执行IPCThreadState::handlePolledCommands;再看看handlePolledCommands函数中执行了getAndExecuteCommand;getAndExecuteCommand在IPCThreadState::joinThreadPool函数中已经提到过了，是用于读取binder驱动的数据和命令字段的解析处理；\nstatus_t IPCThreadState::handlePolledCommands() { status_t result; //读取binder驱动数据，命令字段解析和处理 do { result = getAndExecuteCommand(); } while (mIn.dataPosition() \u0026lt; mIn.dataSize()); //清空输入缓冲区 processPendingDerefs(); //执行完成指令，并把Client需要应答的参数写入binder驱动中 flushCommands(); return result; } 这样ServiceManager进程的启动和消息监听也就分析完成了！\n那我们要想想\nbinder驱动是如果把Client端的数据进行一次拷贝到ServiceManager进程中来读取的呢？ ServiceManager进程又是如何成为binder驱动的上下文管理者？ binder驱动如何管理每个进程的binder服务呢？ ","permalink":"https://rong05.github.io/learn/android/android_binder/","summary":"Binder通讯原理 基于Android 11的源码剖析，笔记记录binder通讯原理的实现过程；\n根据网络上的各路大神案例，都是从典型的mediaserver进程开始分析，binder服务的注册注册过程；\nmediaserver进程启动的main函数开始分析，至于init.rc的注册启动进程就跳过了；main函数代码如下：\nint main(int argc __unused, char **argv __unused) { signal(SIGPIPE, SIG_IGN); //创建与binder驱动交互和binder线程池的管理者 sp\u0026lt;ProcessState\u0026gt; proc(ProcessState::self()); //获取ServiceManager的客户端BpServiceManager sp\u0026lt;IServiceManager\u0026gt; sm(defaultServiceManager()); ALOGI(\u0026#34;ServiceManager: %p\u0026#34;, sm.get()); //创建MediaPlayerService服务，和向ServiceManager注册服务 MediaPlayerService::instantiate(); ResourceManagerService::instantiate(); registerExtensions(); ::android::hardware::configureRpcThreadpool(16, false); //启动binder线程池 ProcessState::self()-\u0026gt;startThreadPool(); IPCThreadState::self()-\u0026gt;joinThreadPool(); ::android::hardware::joinRpcThreadpool(); } Binder线程池的注册 每个采用 Binder 的进程会有一个或多个用于处理接收数据的线程，位于 Binder 线程池。采用 Binder 机制的进程最典型的就是应用程序进程了。那应用程序进程的 Binder 线程池是在什么时候启动的呢？\nProcessState 源码位置：frameworks/native/libs/binder/ProcessState.cpp\nProcessState 是 Binder 机制核心之一，它是 Binder 通信的基础，负责与 Binder 驱动的交互与 Binder 线程池的管理。它实现了单例模式，通过 self() 函数获取实例，每个进程仅有一个。\nProcessState创建 实现了单例模式，通过 self() 函数获取实例。来看看它的构造函数，如下：\nProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//访问binder设备，并与binder驱动交互 , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mBinderContextCheckFunc(nullptr) , mBinderContextUserData(nullptr) , mThreadPoolStarted(false) , mThreadPoolSeq(1) , mCallRestriction(CallRestriction::NONE) { // TODO(b/139016109): enforce in build system #if defined(__ANDROID_APEX__) LOG_ALWAYS_FATAL(\u0026#34;Cannot use libbinder in APEX (only system.","title":""},{"content":"android SELinux权限配置 SELinux policy介绍 ​\tSELinux中，每种东西都会被赋予一个安全属性，就是SContext一个字符串，主要由三部分组成。\n进程的SContext ​\t进程的SContext可通过ps -Z命令来查看，如下图所示：\n​\t以第一个进程/init的SContext为例，其值是u:r:init:s0,其中：\nu为user的意思，一个SELinux用户 r为role的意思 init，代表该进程所属的domain为init s0为进程的级别 文件的SContext ​\t文件的SContext可通过ls -Z来查看，如下图所示：\n​\t以最常见到的audioserver为例，其信息为u:object_r:audioserver_exec:s0:\nu为user的意思，一个SELinux用户 object_r:文件的角色 audioserver_exec：代表该进程所属的domain为audioserver_exec，而exec表示该文件是可执行文件 s0为进程的级别 根据SELinux规范，完整的SContext字符串为：user:role:type[:range]；注意方括号中的内容表示可选项。\nandroid源码中的SELinux定义 在android平台定制的SELinux，是通过编译sepolicy；（android7.0开始目录为system/sepolicy，而在device目录下有不同厂商的定义自己的sepolicy文件夹）\n​\tsystem/sepolicy：提供了Android平台中的安全策略源文件。同时，该目录下的tools还提供了诸如m4,checkpolicy等编译安全策略文件的工具。注意，这些工具运行于主机（即不是提供给Android系统使用的） external/libselinux：提供了Android平台中的libselinux，供Android系统使用。 external/libsepol：提供了供安全策略文件编译时使用的一个工具checkcon。 对我们而言，最重要的还是external/sepolicy。通过如下make命令查看执行情况： mmm system/sepolicy \u0026ndash;just-print\nsepolicy的重头工作是编译sepolicy安全策略文件。这个文件来源于众多的te文件，初始化相关的文件（initial_sid,initial_sid_context,users,roles,fs_context等）。 file_context：该文件记载了不同目录的初始化SContext，所以它和死货打标签有关。 seapp_context：和Android中的应用程序打标签有关。 property_contexts：和Android系统中的属性服务（property_service）有关，它为各种不同的属性打标签。 SELinux分为两种模式，android 5.0后所有进程都是使用enforcing mode\nenforcing mode ： 限制访问 permissive mode： 只审查权限，不限制 SELinux Policy文件路径\n# Google原生目录 external/sepolicy (android7.0开始目录为system/sepolicy) #厂家目录,高通将mediatek 换为 qcom alps\\device\\mediatek\\common\\sepolicy alps\\device\\mediatek\\\u0026lt;platform\u0026gt;\\sepolicy 问题分析 ​\t当在android系统执行过程中SELinux权限缺失时，会报如下错误，我们可以根据错误内容进行对应的权限添加；\n​\ttype=1400 audit(862271.000:14): avc: denied { read write } for pid=666 comm=\u0026quot;cookoosvc\u0026quot; name=\u0026quot;ttyHSL3\u0026quot; dev=\u0026quot;tmpfs\u0026quot; ino=14643 scontext=u:r:cookoosvc:s0 tcontext=u:object_r:quec_device:s0 tclass=chr_file permissive=0\n缺少什么权限： denied { read write } 访问的目标文件或者进程名称：name=ttyHSL3 源SContext标签：scontext=u:r:cookoosvc:s0 目标SContext标签：tcontext=u:object_r:quec_device:s0 目标进程或者文件的类型：tclass=chr_file 然后我们就可以在自己定义的cookoosvc.te文件下添加对应的权限，添加案例如下：\nallow cookoosvc quec_device:chr_file rw_file_perms; allow是允许，cookoosvc服务或者文件访问quec_device类型的设备节点，目标进程或者文件的类型是chr_file，并且给予读写权限\nSELinux Sepolicy中添加权限 修改相应源.te文件（基本以源进程名命名），以cookoosvc.te为例，添加如下：\ntype cookoosvc, domain; type cookoosvc_exec, exec_type, file_type; init_daemon_domain(cookoosvc) binder_use(cookoosvc) # using binder call binder_call(cookoosvc, platform_app) binder_call(cookoosvc, system_app) binder_call(cookoosvc, servicemanager); binder_call(cookoosvc, system_server) binder_service(cookoosvc) allow cookoosvc cookoo_service:service_manager {add find}; #Allow mediacodec to access proc_net files allow cookoosvc proc_net:file r_file_perms; allow cookoosvc rootfs:lnk_file { getattr }; allow cookoosvc appops_service:service_manager find; allow cookoosvc audioserver_service:service_manager find; allow cookoosvc batterystats_service:service_manager find; allow cookoosvc cameraproxy_service:service_manager find; allow cookoosvc mediaserver_service:service_manager find; allow cookoosvc processinfo_service:service_manager find; allow cookoosvc scheduling_policy_service:service_manager find; allow cookoosvc surfaceflinger_service:service_manager find; allow cookoosvc system_file:file { execute_no_trans rx_file_perms }; allow cookoosvc system_file:dir r_dir_perms; allow cookoosvc quec_device:chr_file rw_file_perms; 通常不在Google default的policy下修改，推荐更新厂商相关的policy\n文件配置相关的 ​\t如果进行文件相关的policy配置，需在file_contexts中绑定对应的file，以system/bin/cookoosvc为例，如下:\n/system/bin/cookoosvc u:object_r:cookoosvc_exec:s0 在相应源.te文件添加文件type的安全类型，如下： type cookoosvc_exec, exec_type, file_type; 这是定义cookoosvc_exec类型的文件是文件类型和可执行文件类型 如果是设备节点类型需在file_contexts中定义device类型，以ttyHSL3为例，如下：\n/dev/ttyHSL3 u:object_r:quec_device:s0 如果需要访问的某类型文件的权限，需对对应的申请方式如下：\n#格式 allow 源类型 目标类型:访问类型 {操作权限};//注意分号 allow cookoosvc system_file:file { execute_no_trans rx_file_perms }; allow cookoosvc system_file:dir r_dir_perms; allow cookoosvc quec_device:chr_file rw_file_perms; chr_file - 字符设备 file - 普通文件 dir - 目录 添加property 添加一个自定义的system property: perisist.dome,并为system_app设置读写权限\n在property.te中定义system property类型\ntype demo_prop,property_type 在property_context中绑定system property的安全上下文\npersist.demo u:object_r:demo_prop:s0 在system_app.te中新增写权限，可以使用set_prop宏\nset_prop(system_app,demo_prop) 在system_app.te中新增读权限，可以使用get_prop宏\nget_prop(system_app,demo_prop) 添加系统服务 ​\t有一个扩展的系统服务，需system_app进行bind绑定；以cookoosvc为例\n在service_context中绑定service\ncookoo.uart.service u:object_r:cookoo_service:s0 # cookoo.uart.service是bind通信中ServiceManager绑定的名称 在service.te中对service类型定义\ntype cookoo_service, service_manager_type; # 这个意思是将cookoo_service类型的服务绑定service_manager_type类型 app_api_service - 应用的api类型服务 system_api_service - 系统的api类型服务 system_server_service - 系统类型服务 service_manager_type - ServiceManager标签类型 给system_app进行绑定bind通信权限\n在相应源.te文件添加服务绑定的安全类型，如下 binder_call(cookoosvc, system_app) 并在system_app.te下添加service_manager的add和find权限 allow system_app cookoo_service:service_manager { add find }; 使用Local socket ​\t一个native service通过init创建一个socket并绑定在/dev/socket/demo，而且允许某些process访问。\n在file.te中定义socket的类型\ntype demo_socket, file_type; 在file_context中绑定socket的类型\n/dev/socket/demo u:object_r:demo_socket:s0 允许所有的process访问\n#使用宏unix_socket_connect(clientdomain,sockrt,serverdomain) unix_socket_connect(appdomain,demo_socket,demo) init fork 新进程 ​\t在init.rc启动service时，需添加selinux，以cookoosvc为例，如下：\nSELinux Policy文件路径下创建一个相应源.te文件（基本以源进程名命名），如《文件配置相关的》栏\n在cookoosvc.te中定义cookoosvc类型，init启动service时类型转换。根据cookoosvc需要访问的文件权限以及设备，定义其它权限在cookoosvc.te中。\ntype cookoosvc, domain; type cookoosvc_exec, exec_type, file_type; init_daemon_domain(cookoosvc) 绑定执行档file_context类型\n/system/bin/cookoosvc u:object_r:cookoosvc_exec:s0 创建cookoosvc的入口执行档cookoosvc_exec、并配置相应的权限（如果遇到问题需添加权限，可以根据日志进行相应的分析）； 抓取SELinux log 抓kernel log, adb shell dmesg 抓kernel log, 使用命令，可以直接提出avc的log：adb shell \u0026ldquo;cat /proc/kmsg | grep avc\u0026rdquo; \u0026gt; avc_log.txt adb logcat -b events,搜索关键字：avc: denied 实际的项目使用中应根据log分析缺少的权限，来对应添加；再次强调，通常不在Google default的policy下修改，推荐更新厂商相关的policy\n","permalink":"https://rong05.github.io/learn/android/android_selinux/","summary":"android SELinux权限配置 SELinux policy介绍 ​\tSELinux中，每种东西都会被赋予一个安全属性，就是SContext一个字符串，主要由三部分组成。\n进程的SContext ​\t进程的SContext可通过ps -Z命令来查看，如下图所示：\n​\t以第一个进程/init的SContext为例，其值是u:r:init:s0,其中：\nu为user的意思，一个SELinux用户 r为role的意思 init，代表该进程所属的domain为init s0为进程的级别 文件的SContext ​\t文件的SContext可通过ls -Z来查看，如下图所示：\n​\t以最常见到的audioserver为例，其信息为u:object_r:audioserver_exec:s0:\nu为user的意思，一个SELinux用户 object_r:文件的角色 audioserver_exec：代表该进程所属的domain为audioserver_exec，而exec表示该文件是可执行文件 s0为进程的级别 根据SELinux规范，完整的SContext字符串为：user:role:type[:range]；注意方括号中的内容表示可选项。\nandroid源码中的SELinux定义 在android平台定制的SELinux，是通过编译sepolicy；（android7.0开始目录为system/sepolicy，而在device目录下有不同厂商的定义自己的sepolicy文件夹）\n​\tsystem/sepolicy：提供了Android平台中的安全策略源文件。同时，该目录下的tools还提供了诸如m4,checkpolicy等编译安全策略文件的工具。注意，这些工具运行于主机（即不是提供给Android系统使用的） external/libselinux：提供了Android平台中的libselinux，供Android系统使用。 external/libsepol：提供了供安全策略文件编译时使用的一个工具checkcon。 对我们而言，最重要的还是external/sepolicy。通过如下make命令查看执行情况： mmm system/sepolicy \u0026ndash;just-print\nsepolicy的重头工作是编译sepolicy安全策略文件。这个文件来源于众多的te文件，初始化相关的文件（initial_sid,initial_sid_context,users,roles,fs_context等）。 file_context：该文件记载了不同目录的初始化SContext，所以它和死货打标签有关。 seapp_context：和Android中的应用程序打标签有关。 property_contexts：和Android系统中的属性服务（property_service）有关，它为各种不同的属性打标签。 SELinux分为两种模式，android 5.0后所有进程都是使用enforcing mode\nenforcing mode ： 限制访问 permissive mode： 只审查权限，不限制 SELinux Policy文件路径\n# Google原生目录 external/sepolicy (android7.0开始目录为system/sepolicy) #厂家目录,高通将mediatek 换为 qcom alps\\device\\mediatek\\common\\sepolicy alps\\device\\mediatek\\\u0026lt;platform\u0026gt;\\sepolicy 问题分析 ​\t当在android系统执行过程中SELinux权限缺失时，会报如下错误，我们可以根据错误内容进行对应的权限添加；\n​\ttype=1400 audit(862271.000:14): avc: denied { read write } for pid=666 comm=\u0026quot;cookoosvc\u0026quot; name=\u0026quot;ttyHSL3\u0026quot; dev=\u0026quot;tmpfs\u0026quot; ino=14643 scontext=u:r:cookoosvc:s0 tcontext=u:object_r:quec_device:s0 tclass=chr_file permissive=0","title":""},{"content":"Binder Driver探索 binder驱动的初始化 在binder.c中有以下一行代码；\ndevice_initcall(binder_init); 在Linux内核的启动过程中，一个驱动的注册用module_init调用，即device_initcall，它可以将驱动设备加载进内核中，以供后续使用。\n在Android8.0之后，现在Binder驱动有三个：/dev/binder; /dev/hwbinder; /dev/vndbinder.\nstatic int __init binder_init(void) { int ret; char *device_name, *device_tmp; struct binder_device *device; struct hlist_node *tmp; char *device_names = NULL; //初始化binder缓冲区分配 ret = binder_alloc_shrinker_init(); if (ret) return ret; // ~0U：无符号整型，对0取反。 atomic_set(\u0026amp;binder_transaction_log.cur, ~0U); atomic_set(\u0026amp;binder_transaction_log_failed.cur, ~0U); // 创建/sys/kernel/debug/binder目录。 binder_debugfs_dir_entry_root = debugfs_create_dir(\u0026#34;binder\u0026#34;, NULL); // 创建/sys/kernel/debug/binder/proc目录用于记录每个进程基本信息。 if (binder_debugfs_dir_entry_root) binder_debugfs_dir_entry_proc = debugfs_create_dir(\u0026#34;proc\u0026#34;, binder_debugfs_dir_entry_root); if (binder_debugfs_dir_entry_root) { // 创建/sys/kernel/debug/binder/state文件用于记录状态信息， //并注册操作函数binder_state_fops。 debugfs_create_file(\u0026#34;state\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_state_fops); // 创建/sys/kernel/debug/binder/stats文件用于记录统计信息， //并注册操作函数binder_stats_fops。 debugfs_create_file(\u0026#34;stats\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_stats_fops); // 创建/sys/kernel/debug/binder/transactions文件用于记录transaction相关信息， //并注册操作函数binder_transactions_fops。 debugfs_create_file(\u0026#34;transactions\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_transactions_fops); // 创建/sys/kernel/debug/binder/transaction_log文件用于记录transaction日志相关信息， //并注册操作函数binder_transaction_log_fops。 debugfs_create_file(\u0026#34;transaction_log\u0026#34;, 0444, binder_debugfs_dir_entry_root, \u0026amp;binder_transaction_log, \u0026amp;binder_transaction_log_fops); // 创建/sys/kernel/debug/binder/failed_transaction_log文件用于记录transaction失败日志相关信息， // 并注册操作函数binder_transaction_log_fops debugfs_create_file(\u0026#34;failed_transaction_log\u0026#34;, 0444, binder_debugfs_dir_entry_root, \u0026amp;binder_transaction_log_failed, \u0026amp;binder_transaction_log_fops); } if (!IS_ENABLED(CONFIG_ANDROID_BINDERFS) \u0026amp;\u0026amp; strcmp(binder_devices_param, \u0026#34;\u0026#34;) != 0) { /* * Copy the module_parameter string, because we don\u0026#39;t want to * tokenize it in-place. */ // kzalloc：分配不超过128KB的连续的物理内存映射区域。 // GFP_KERNEL：内存分配器flags，无内存可用时可引起休眠，允许启动磁盘IO和文件系统IO。 // binder_devices_param：binder，hwbinder，vndbinder。 device_names = kstrdup(binder_devices_param, GFP_KERNEL); if (!device_names) { ret = -ENOMEM; goto err_alloc_device_names_failed; } // 创建binder设备 device_tmp = device_names; while ((device_name = strsep(\u0026amp;device_tmp, \u0026#34;,\u0026#34;))) { ret = init_binder_device(device_name); if (ret) goto err_init_binder_device_failed; } } //初始化binder文件系统 ret = init_binderfs(); if (ret) goto err_init_binder_device_failed; return ret; err_init_binder_device_failed: hlist_for_each_entry_safe(device, tmp, \u0026amp;binder_devices, hlist) { misc_deregister(\u0026amp;device-\u0026gt;miscdev); hlist_del(\u0026amp;device-\u0026gt;hlist); kfree(device); } kfree(device_names); err_alloc_device_names_failed: debugfs_remove_recursive(binder_debugfs_dir_entry_root); return ret; } binder_init函数主要内容是：\n初始化binder缓冲区分配 创建了sys/kernel/debug/binder目录，以及其子目录或文件 注册misc设备，创建binder设备 把binder_device加入到全局链表binder_devices进行管理 那来看看init_binder_device是如何注册misc设备，创建binder设备，代码如下：\nstatic int __init init_binder_device(const char *name) { int ret; struct binder_device *binder_device; binder_device = kzalloc(sizeof(*binder_device), GFP_KERNEL); if (!binder_device) return -ENOMEM; //miscdevice结构体 binder_device-\u0026gt;miscdev.fops = \u0026amp;binder_fops; //设备的文件操作结构，这是file_operations结构 binder_device-\u0026gt;miscdev.minor = MISC_DYNAMIC_MINOR;//次设备号 动态分配 binder_device-\u0026gt;miscdev.name = name;//设备名 //binder设备的引用计数 refcount_set(\u0026amp;binder_device-\u0026gt;ref, 1); //默认binder驱动的上下文管理者 binder_device-\u0026gt;context.binder_context_mgr_uid = INVALID_UID; binder_device-\u0026gt;context.name = name; mutex_init(\u0026amp;binder_device-\u0026gt;context.context_mgr_node_lock); // 注册misc设备 ret = misc_register(\u0026amp;binder_device-\u0026gt;miscdev); if (ret \u0026lt; 0) { kfree(binder_device); return ret; } // 通过全局链表binder_devices管理binder_device。 hlist_add_head(\u0026amp;binder_device-\u0026gt;hlist, \u0026amp;binder_devices); return ret; } 从init_binder_device函数看出binder驱动设备节点是通过binder_device结构体管理的；设置binder_device的miscdev参数，miscdev其实是miscdevice结构体，misc_register函数注册misc设备，miscdevice参数分别是：\n设备的文件操作结构，这是file_operations结构 次设备号 动态分配 设备名 binder_device结构体定义如下：\nstruct binder_device { // 加入binder_devices全局链表的node。 struct hlist_node hlist; // misc设备。 struct miscdevice miscdev; // 获取service manager对应的binder_node。 struct binder_context context; //属于bindfs挂载的超级块的根节点的inode。 struct inode *binderfs_inode; //binder_device的引用计数 refcount_t ref; }; file_operations结构体,指定相应文件操作的方法\nconst struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = compat_ptr_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, }; 用户态的程序调用Kernel层驱动是需要陷入内核态，进行系统调用(syscall)，比如打开Binder驱动方法的调用链为： open-\u0026gt; __open() -\u0026gt; binder_open()。通过binder_fops的定义得出以下调用规则；\n图片来源\nbinder_open 之前已经提到每个进程都会单独创建自己的ProcessState，ProcessState是进程唯一的；在ProcessState创建时会调用open函数，那对应调用的就是binder驱动中的binder_open;\nstatic int binder_open(struct inode *nodp, struct file *filp) { struct binder_proc *proc, *itr; struct binder_device *binder_dev; struct binderfs_info *info; struct dentry *binder_binderfs_dir_entry_proc = NULL; bool existing_pid = false; binder_debug(BINDER_DEBUG_OPEN_CLOSE, \u0026#34;%s: %d:%d\\n\u0026#34;, __func__, current-\u0026gt;group_leader-\u0026gt;pid, current-\u0026gt;pid); //创建binder驱动中管理IPC和保存进程信息的根结构体 proc = kzalloc(sizeof(*proc), GFP_KERNEL); if (proc == NULL) return -ENOMEM; // 初始化两个自旋锁。 // inner_lock保护线程、binder_node以及所有与进程相关的的todo队列。 // outer_lock保护binder_ref。 spin_lock_init(\u0026amp;proc-\u0026gt;inner_lock); spin_lock_init(\u0026amp;proc-\u0026gt;outer_lock); // 获取当前进程组领头进程。 get_task_struct(current-\u0026gt;group_leader); proc-\u0026gt;tsk = current-\u0026gt;group_leader;//将当前进程的task_struct保存到binder_proc INIT_LIST_HEAD(\u0026amp;proc-\u0026gt;todo);//初始化todo列表 // 判断当前进程的调度策略是否支持，binder只支持SCHED_NORMAL(00b)、SCHED_FIFO(01b)、SCHED_RR(10b)、SCHED_BATCH(11b)。 // prio为进程优先级，可通过normal_prio获取。一般分为实时优先级及静态优先级。 if (binder_supported_policy(current-\u0026gt;policy)) { proc-\u0026gt;default_priority.sched_policy = current-\u0026gt;policy; proc-\u0026gt;default_priority.prio = current-\u0026gt;normal_prio; } else { proc-\u0026gt;default_priority.sched_policy = SCHED_NORMAL; proc-\u0026gt;default_priority.prio = NICE_TO_PRIO(0); } /* binderfs stashes devices in i_private */ // 通过miscdev获取binder_device。 if (is_binderfs_device(nodp)) { binder_dev = nodp-\u0026gt;i_private; info = nodp-\u0026gt;i_sb-\u0026gt;s_fs_info; binder_binderfs_dir_entry_proc = info-\u0026gt;proc_log_dir; } else { binder_dev = container_of(filp-\u0026gt;private_data, struct binder_device, miscdev); } //binder_device的引用计数加1 refcount_inc(\u0026amp;binder_dev-\u0026gt;ref); //初始化对应进程中的binder驱动上下文管理者 proc-\u0026gt;context = \u0026amp;binder_dev-\u0026gt;context; // 初始化binder_proc的binder_alloc字段。 binder_alloc_init(\u0026amp;proc-\u0026gt;alloc); // binder驱动维护静态全局数组binder_stats，其中有一个成员数组obj_created。 // 当binder_open调用时，obj_created[BINDER_STAT_PROC]将自增。该数组用来统计binder对象的数量。 binder_stats_created(BINDER_STAT_PROC); //初始化binder_proc的pid为领头进程的pid值。 proc-\u0026gt;pid = current-\u0026gt;group_leader-\u0026gt;pid; // 初始化delivered_death及waiting_threads队列。 INIT_LIST_HEAD(\u0026amp;proc-\u0026gt;delivered_death); INIT_LIST_HEAD(\u0026amp;proc-\u0026gt;waiting_threads); // private_data保存binder_proc对象。 filp-\u0026gt;private_data = proc; // 将binder_proc加入到全局队列binder_procs中,该操作必须加锁。 mutex_lock(\u0026amp;binder_procs_lock); hlist_for_each_entry(itr, \u0026amp;binder_procs, proc_node) { if (itr-\u0026gt;pid == proc-\u0026gt;pid) { existing_pid = true; break; } } hlist_add_head(\u0026amp;proc-\u0026gt;proc_node, \u0026amp;binder_procs); mutex_unlock(\u0026amp;binder_procs_lock); // 若/sys/kernel/binder/proc目录已经创建好，则在该目录下创建一个以pid为名的文件。 if (binder_debugfs_dir_entry_proc \u0026amp;\u0026amp; !existing_pid) { char strbuf[11]; snprintf(strbuf, sizeof(strbuf), \u0026#34;%u\u0026#34;, proc-\u0026gt;pid); /* * proc debug entries are shared between contexts. * Only create for the first PID to avoid debugfs log spamming * The printing code will anyway print all contexts for a given * PID so this is not a problem. */ // proc调试条目在上下文之间共享，如果进程尝试使用其他上下文再次打开驱动程序，则此操作将失败。 proc-\u0026gt;debugfs_entry = debugfs_create_file(strbuf, 0444, binder_debugfs_dir_entry_proc, (void *)(unsigned long)proc-\u0026gt;pid, \u0026amp;proc_fops); } if (binder_binderfs_dir_entry_proc \u0026amp;\u0026amp; !existing_pid) { char strbuf[11]; struct dentry *binderfs_entry; snprintf(strbuf, sizeof(strbuf), \u0026#34;%u\u0026#34;, proc-\u0026gt;pid); /* * Similar to debugfs, the process specific log file is shared * between contexts. Only create for the first PID. * This is ok since same as debugfs, the log file will contain * information on all contexts of a given PID. */ binderfs_entry = binderfs_create_file(binder_binderfs_dir_entry_proc, strbuf, \u0026amp;proc_fops, (void *)(unsigned long)proc-\u0026gt;pid); if (!IS_ERR(binderfs_entry)) { proc-\u0026gt;binderfs_entry = binderfs_entry; } else { int error; error = PTR_ERR(binderfs_entry); pr_warn(\u0026#34;Unable to create file %s in binderfs (error %d)\\n\u0026#34;, strbuf, error); } } return 0; } 从binder_open函数的主要工作是创建binder_proc结构体，并把当前进程等信息保存到binder_proc，初始化binder_proc中管理IPC所需的各种信息并创建其它相关的子结构体；再把binder_proc保存到文件指针filp，以及把binder_proc加入到全局链表binder_procs，这一个双向链表结构。\nbinder_procs结构体 struct binder_proc { //加入binder_procs全局链表的node节点。 struct hlist_node proc_node; //记录执行传输动作的线程信息, binder_thread红黑树的根节点 struct rb_root threads; //用于记录binder实体 ,binder_node红黑树的根节点，它是Server在Binder驱动中的体现 struct rb_root nodes; //binder_ref红黑树的根节点(以handle为key struct rb_root refs_by_desc; //binder_ref红黑树的根节点（以ptr为key） struct rb_root refs_by_node; //该binder进程的线程池中等待处理binder_work的binder_thread链表 struct list_head waiting_threads; //相应进程id int pid; //相应进程的task结构体 struct task_struct *tsk; struct hlist_node deferred_work_node; int deferred_work; bool is_dead; //进程将要做的事 struct list_head todo; //binder统计信息 struct binder_stats stats; //已分发的死亡通知 struct list_head delivered_death; //最大线程数 int max_threads; //请求的线程数 int requested_threads; //已启动的请求线程数 int requested_threads_started; int tmp_ref; //默认优先级 struct binder_priority default_priority; struct dentry *debugfs_entry; //进程通信数据内存分配相关 struct binder_alloc alloc; //binder驱动的上下文管理者 struct binder_context *context; spinlock_t inner_lock; spinlock_t outer_lock; struct dentry *binderfs_entry; }; struct binder_alloc { struct mutex mutex; //指向进程虚拟地址空间的指针 struct vm_area_struct *vma; //相应进程的内存结构体 struct mm_struct *vma_vm_mm; // map 的地址就是这里了 void __user *buffer; //所有的buffers列表 struct list_head buffers; //只进行了预定，没有分配，按大小排序 struct rb_root free_buffers; //已经分配了,按地址排序 struct rb_root allocated_buffers; //用于异步请求的空间 size_t free_async_space; //所有的pages指向物理内存页 struct binder_lru_page *pages; //映射的内核空间大小 size_t buffer_size; uint32_t buffer_free; int pid; size_t pages_high; }; binder_mmap 主要功能：\n为用户进程分配一块内核空间作为缓冲区，并把分配的缓冲区指针存放到binder_proc的buffer字段； 分配pages空间，并内核分配一块同样页数的内核空间,并把它的物理内存和前面为用户进程分配的内存地址关联； 分配的内存块加入用户进程内存链表； static int binder_mmap(struct file *filp, struct vm_area_struct *vma) { //private_data保存了我们open设备时创建的binder_proc信息 struct binder_proc *proc = filp-\u0026gt;private_data; if (proc-\u0026gt;tsk != current-\u0026gt;group_leader) return -EINVAL; binder_debug(BINDER_DEBUG_OPEN_CLOSE, \u0026#34;%s: %d %lx-%lx (%ld K) vma %lx pagep %lx\\n\u0026#34;, __func__, proc-\u0026gt;pid, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end, (vma-\u0026gt;vm_end - vma-\u0026gt;vm_start) / SZ_1K, vma-\u0026gt;vm_flags, (unsigned long)pgprot_val(vma-\u0026gt;vm_page_prot)); //mmap 的 buffer 禁止用户进行写操作。mmap 只是为了分配内核空间，传递数据通过 ioctl() if (vma-\u0026gt;vm_flags \u0026amp; FORBIDDEN_MMAP_FLAGS) { pr_err(\u0026#34;%s: %d %lx-%lx %s failed %d\\n\u0026#34;, __func__, proc-\u0026gt;pid, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end, \u0026#34;bad vm_flags\u0026#34;, -EPERM); return -EPERM; } // 将 VM_DONTCOP 置起，禁止 拷贝，禁止 写操作 vma-\u0026gt;vm_flags |= VM_DONTCOPY | VM_MIXEDMAP; vma-\u0026gt;vm_flags \u0026amp;= ~VM_MAYWRITE; vma-\u0026gt;vm_ops = \u0026amp;binder_vm_ops; vma-\u0026gt;vm_private_data = proc; // 再次完善 binder buffer allocator return binder_alloc_mmap_handler(\u0026amp;proc-\u0026gt;alloc, vma); } int binder_alloc_mmap_handler(struct binder_alloc *alloc, struct vm_area_struct *vma) { int ret; const char *failure_string; //每一次Binder传输数据时，都会先从Binder内存缓存区中分配一个binder_buffer来存储传输数据 struct binder_buffer *buffer; //同步锁 mutex_lock(\u0026amp;binder_alloc_mmap_lock); // 不需要重复mmap if (alloc-\u0026gt;buffer_size) { ret = -EBUSY; failure_string = \u0026#34;already mapped\u0026#34;; goto err_already_mapped; } //vma-\u0026gt;vm_end, vma-\u0026gt;vm_start 指向要 映射的用户空间地址, map size 不允许 大于 4M alloc-\u0026gt;buffer_size = min_t(unsigned long, vma-\u0026gt;vm_end - vma-\u0026gt;vm_start, SZ_4M); mutex_unlock(\u0026amp;binder_alloc_mmap_lock); //指向用户进程内核虚拟空间的 start地址 alloc-\u0026gt;buffer = (void __user *)vma-\u0026gt;vm_start; //分配物理页的指针数组，数组大小为vma的等效page个数 alloc-\u0026gt;pages = kcalloc(alloc-\u0026gt;buffer_size / PAGE_SIZE, sizeof(alloc-\u0026gt;pages[0]), GFP_KERNEL); if (alloc-\u0026gt;pages == NULL) { ret = -ENOMEM; failure_string = \u0026#34;alloc page array\u0026#34;; goto err_alloc_pages_failed; } //申请一个binder_buffer的内存 buffer = kzalloc(sizeof(*buffer), GFP_KERNEL); if (!buffer) { ret = -ENOMEM; failure_string = \u0026#34;alloc buffer struct\u0026#34;; goto err_alloc_buf_struct_failed; } //指向用户进程内核虚拟空间的 start地址，即为当前进程mmap的内核空间地址 buffer-\u0026gt;user_data = alloc-\u0026gt;buffer; //将binder_buffer地址，加入到所属进程的buffers队列 list_add(\u0026amp;buffer-\u0026gt;entry, \u0026amp;alloc-\u0026gt;buffers); buffer-\u0026gt;free = 1; //将当前buffer加入到红黑树alloc-\u0026gt;free_buffers中，表示当前buffer是空闲buffer binder_insert_free_buffer(alloc, buffer); // 将异步事务的空间大小设置为 整个空间的一半 alloc-\u0026gt;free_async_space = alloc-\u0026gt;buffer_size / 2; binder_alloc_set_vma(alloc, vma); mmgrab(alloc-\u0026gt;vma_vm_mm); return 0; err_alloc_buf_struct_failed: kfree(alloc-\u0026gt;pages); alloc-\u0026gt;pages = NULL; err_alloc_pages_failed: alloc-\u0026gt;buffer = NULL; mutex_lock(\u0026amp;binder_alloc_mmap_lock); alloc-\u0026gt;buffer_size = 0; err_already_mapped: mutex_unlock(\u0026amp;binder_alloc_mmap_lock); binder_alloc_debug(BINDER_DEBUG_USER_ERROR, \u0026#34;%s: %d %lx-%lx %s failed %d\\n\u0026#34;, __func__, alloc-\u0026gt;pid, vma-\u0026gt;vm_start, vma-\u0026gt;vm_end, failure_string, ret); return ret; } static void binder_insert_free_buffer(struct binder_alloc *alloc, struct binder_buffer *new_buffer) { struct rb_node **p = \u0026amp;alloc-\u0026gt;free_buffers.rb_node; struct rb_node *parent = NULL; struct binder_buffer *buffer; size_t buffer_size; size_t new_buffer_size; BUG_ON(!new_buffer-\u0026gt;free); // 通过binder_alloc_buffer_size计算当前new_buffer的大小，之后将用于比较。 new_buffer_size = binder_alloc_buffer_size(alloc, new_buffer); binder_alloc_debug(BINDER_DEBUG_BUFFER_ALLOC, \u0026#34;%d: add free buffer, size %zd, at %pK\\n\u0026#34;, alloc-\u0026gt;pid, new_buffer_size, new_buffer); while (*p) { parent = *p; // 获取当前红黑树节点的buffer。 buffer = rb_entry(parent, struct binder_buffer, rb_node); BUG_ON(!buffer-\u0026gt;free); // 计算当前红黑树节点的buffer大小。 buffer_size = binder_alloc_buffer_size(alloc, buffer); // 红黑树遵循二叉树规则：当新的buffer比当前节点的buffer小时，向左子节点继续重复，否则转向右子节点。 if (new_buffer_size \u0026lt; buffer_size) p = \u0026amp;parent-\u0026gt;rb_left; else p = \u0026amp;parent-\u0026gt;rb_right; } // 找到合适位置后，将new_buffer插入到该位置。 rb_link_node(\u0026amp;new_buffer-\u0026gt;rb_node, parent, p); rb_insert_color(\u0026amp;new_buffer-\u0026gt;rb_node, \u0026amp;alloc-\u0026gt;free_buffers); } binder_mmap通过加锁，保证一次只有一个进程分配内存，保证多进程间的并发访问。将分配一块内核空间缓冲区buffer加入到红黑树alloc-\u0026gt;free_buffers中，表示当前buffer是空闲buffer；每一次Binder传输数据时，都会先从Binder内存缓存区中分配一个binder_buffer来存储传输数据。\nbinder_buffer结构体 struct binder_buffer { //buffer实体的地址 struct list_head entry; /* free and allocated entries by address */ struct rb_node rb_node; /* free entry by size or allocated entry */ /* by address */ //标记是否是空闲buffer，占位1bit unsigned free:1; //是否允许用户释放，占位1bit unsigned clear_on_free:1; unsigned allow_user_free:1; unsigned async_transaction:1; unsigned debug_id:28; //该缓存区的需要处理的事务 struct binder_transaction *transaction; //该缓存区所需处理的Binder实体 struct binder_node *target_node; //数据大小 size_t data_size; //数据偏移量 size_t offsets_size; size_t extra_buffers_size; //用户数据 void __user *user_data; int pid; }; struct binder_lru_page { struct list_head lru;//binder_alloc_lru中的条目 struct page *page_ptr;//指向mmap空间中的物理页面的指针 struct binder_alloc *alloc;//proc的binder_alloc }; binder_mmap这里主要映射的内存只允许用户空间读，不允许用户空间写；binder驱动可以读写这块内存；存映射实现一次拷贝的概念是：\n用户空间给binder驱动传入信息时，都需要内存拷贝； binder驱动给发送用户空间则不需要； 物理内存的分配和释放 binder_update_page_range函数主要的作用是分配和释放物理内存；\nbinder_ioctl binder_ioctl()函数负责在两个进程间收发IPC数据和IPC reply数据。\nioctl命令和数据类型是一体的，不同的命令对应不同的数据类型\nioctl命令 数据类型 操作 BINDER_WRITE_READ struct binder_write_read 收发Binder IPC数据 BINDER_SET_MAX_THREADS __u32 设置Binder线程最大个数 BINDER_SET_CONTEXT_MGR __s32 设置Service Manager节点 BINDER_THREAD_EXIT __s32 释放Binder线程 BINDER_VERSION struct binder_version 获取Binder版本信息 BINDER_SET_IDLE_TIMEOUT __s64 没有使用 BINDER_SET_IDLE_PRIORITY __s32 没有使用 这些命令中BINDER_WRITE_READ命令使用率最为频繁，也是ioctl最为核心的命令。\nstatic long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int ret; //oepn的时候包在filp的private_data struct binder_proc *proc = filp-\u0026gt;private_data; struct binder_thread *thread; unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; /*pr_info(\u0026#34;binder_ioctl: %d:%d %x %lx\\n\u0026#34;, proc-\u0026gt;pid, current-\u0026gt;pid, cmd, arg);*/ binder_selftest_alloc(\u0026amp;proc-\u0026gt;alloc); trace_binder_ioctl(cmd, arg); //这里时一个阻塞代码，如果binder_stop_on_user_error 大于2这里会被休眠 //这里先无视即可 ret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error \u0026lt; 2); if (ret) goto err_unlocked; //获取当前线程对应的结构体，如果没有创建过，那么就创建一个放入到proc的红黑树 thread = binder_get_thread(proc); if (thread == NULL) { ret = -ENOMEM; goto err; } switch (cmd) { case BINDER_WRITE_READ://进行binder的读写操作 ret = binder_ioctl_write_read(filp, cmd, arg, thread); if (ret) goto err; break; case BINDER_SET_MAX_THREADS: {//设置binder最大支持的线程数 int max_threads; if (copy_from_user(\u0026amp;max_threads, ubuf, sizeof(max_threads))) { ret = -EINVAL; goto err; } binder_inner_proc_lock(proc); proc-\u0026gt;max_threads = max_threads; binder_inner_proc_unlock(proc); break; } case BINDER_SET_CONTEXT_MGR_EXT: { //设置Service Manager节点，带flag参数， servicemanager进程成为上下文管理者 struct flat_binder_object fbo; if (copy_from_user(\u0026amp;fbo, ubuf, sizeof(fbo))) { ret = -EINVAL; goto err; } ret = binder_ioctl_set_ctx_mgr(filp, \u0026amp;fbo); if (ret) goto err; break; } case BINDER_SET_CONTEXT_MGR://成为binder的上下文管理者，不带flag参数，也就是ServiceManager成为守护进程 ret = binder_ioctl_set_ctx_mgr(filp, NULL); if (ret) goto err; break; case BINDER_THREAD_EXIT://当binder线程退出，释放binder线程 binder_debug(BINDER_DEBUG_THREADS, \u0026#34;%d:%d exit\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid); binder_thread_release(proc, thread); thread = NULL; break; case BINDER_VERSION: {//获取binder的版本号 struct binder_version __user *ver = ubuf; if (size != sizeof(struct binder_version)) { ret = -EINVAL; goto err; } if (put_user(BINDER_CURRENT_PROTOCOL_VERSION, \u0026amp;ver-\u0026gt;protocol_version)) { ret = -EINVAL; goto err; } break; } case BINDER_GET_NODE_INFO_FOR_REF: { struct binder_node_info_for_ref info; if (copy_from_user(\u0026amp;info, ubuf, sizeof(info))) { ret = -EFAULT; goto err; } ret = binder_ioctl_get_node_info_for_ref(proc, \u0026amp;info); if (ret \u0026lt; 0) goto err; if (copy_to_user(ubuf, \u0026amp;info, sizeof(info))) { ret = -EFAULT; goto err; } break; } case BINDER_GET_NODE_DEBUG_INFO: { struct binder_node_debug_info info; if (copy_from_user(\u0026amp;info, ubuf, sizeof(info))) { ret = -EFAULT; goto err; } ret = binder_ioctl_get_node_debug_info(proc, \u0026amp;info); if (ret \u0026lt; 0) goto err; if (copy_to_user(ubuf, \u0026amp;info, sizeof(info))) { ret = -EFAULT; goto err; } break; } default: ret = -EINVAL; goto err; } ret = 0; err: if (thread) thread-\u0026gt;looper_need_return = false; wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error \u0026lt; 2); if (ret \u0026amp;\u0026amp; ret != -ERESTARTSYS) pr_info(\u0026#34;%d:%d ioctl %x %lx returned %d\\n\u0026#34;, proc-\u0026gt;pid, current-\u0026gt;pid, cmd, arg, ret); err_unlocked: trace_binder_ioctl_done(ret); return ret; } 获取binder线程 从binder_proc中查找binder_thread,如果当前线程已经加入到proc的线程队列则直接返回，如果不存在则创建binder_thread，并将当前线程添加到当前的proc\nstatic struct binder_thread *binder_get_thread(struct binder_proc *proc) { struct binder_thread *thread; struct binder_thread *new_thread; binder_inner_proc_lock(proc); //从当前进程中获取线程 thread = binder_get_thread_ilocked(proc, NULL); binder_inner_proc_unlock(proc); if (!thread) { //如果当前进程中没有线程，那么创建一个 new_thread = kzalloc(sizeof(*thread), GFP_KERNEL); if (new_thread == NULL) return NULL; binder_inner_proc_lock(proc); thread = binder_get_thread_ilocked(proc, new_thread); binder_inner_proc_unlock(proc); if (thread != new_thread) kfree(new_thread); } return thread; } binder_thread结构体 binder_thread是当前binder操作所在的线程；\nstruct binder_thread { struct binder_proc *proc;//线程所属的进程 struct rb_node rb_node; //红黑树节点 struct list_head waiting_thread_node; int pid;//线程pid int looper; /* only modified by this thread */ bool looper_need_return; /* can be written by other thread */ struct binder_transaction *transaction_stack;//线程正在处理的事务 struct list_head todo;//将要处理的链表 bool process_todo; struct binder_error return_error;//write失败后，返回的错误码 struct binder_error reply_error; wait_queue_head_t wait; //等待队列的队头 struct binder_stats stats;//binder线程的统计信息 atomic_t tmp_ref; bool is_dead; struct task_struct *task; }; ServiceManager是如何成binder驱动的上下文管理者 ServiceManager在native层中ProcessState的becomeContextManager函数通过ioctl发送BINDER_SET_CONTEXT_MGR_EXT 命令，让自身成为上下文管理者;然后在binder驱动中的binder_ioctl接收到了BINDER_SET_CONTEXT_MGR_EXT指令后；通过binder_ioctl_set_ctx_mgr函数进行处理；\nbinder_ioctl_set_ctx_mgr()处理如下：\n通过filp-\u0026gt;private_data找到binder_proc; 对当前进程进行是否具注册Context Manager的SELinux安全权限的检查 进行uid检查，线程只能注册自己，且只能有一个线程设置为Context Manager 设置当前线程euid作为ServiceManager的uid； 创建一个binder实体binder_node，并加入到当前进程的nodes红黑树中； 把新创建的binder_node,赋值给当前进程的binder_context_mgr_node，这样就约定该进程就成为了binder驱动的上下文的管理者； static int binder_ioctl_set_ctx_mgr(struct file *filp, struct flat_binder_object *fbo) { int ret = 0; //filp-\u0026gt;private_data 在open()binder驱动时，保存了一个创建的binder_proc，即是此时调用进程的binder_proc. struct binder_proc *proc = filp-\u0026gt;private_data; //获得当前进程的context struct binder_context *context = proc-\u0026gt;context; struct binder_node *new_node; kuid_t curr_euid = current_euid(); mutex_lock(\u0026amp;context-\u0026gt;context_mgr_node_lock); //保证只创建一次mgr_node对象 if (context-\u0026gt;binder_context_mgr_node) { pr_err(\u0026#34;BINDER_SET_CONTEXT_MGR already set\\n\u0026#34;); ret = -EBUSY; goto out; } //检查当前进程是否具注册Context Manager的SEAndroid安全权限 ret = security_binder_set_context_mgr(proc-\u0026gt;tsk); if (ret \u0026lt; 0) goto out; //检查已的uid是否有效 if (uid_valid(context-\u0026gt;binder_context_mgr_uid)) { //uid有效但是与当前运行线程的效用户ID不相等，则出错。 //即线程只能注册自己，且只能有一个线程设置为Context Manager if (!uid_eq(context-\u0026gt;binder_context_mgr_uid, curr_euid)) { pr_err(\u0026#34;BINDER_SET_CONTEXT_MGR bad uid %d != %d\\n\u0026#34;, from_kuid(\u0026amp;init_user_ns, curr_euid), from_kuid(\u0026amp;init_user_ns, context-\u0026gt;binder_context_mgr_uid)); ret = -EPERM; goto out; } } else { //设置当前线程euid作为ServiceManager的uid context-\u0026gt;binder_context_mgr_uid = curr_euid; } //创建binder实体，并加入到当前进程的nodes红黑树中，我们这里可以是ServiceManager new_node = binder_new_node(proc, fbo); if (!new_node) { ret = -ENOMEM; goto out; } binder_node_lock(new_node); //更新new_node的相关强弱引用计数 new_node-\u0026gt;local_weak_refs++; new_node-\u0026gt;local_strong_refs++; new_node-\u0026gt;has_strong_ref = 1; new_node-\u0026gt;has_weak_ref = 1; //new_node 赋值给进程的上下文管理节点，作为上下文管理者 context-\u0026gt;binder_context_mgr_node = new_node; binder_node_unlock(new_node); binder_put_node(new_node); out: mutex_unlock(\u0026amp;context-\u0026gt;context_mgr_node_lock); return ret; } binder_node结构体 binder_node代表一个binder实体\nstruct binder_node { int debug_id;//节点创建时分配，具有全局唯一性，用于调试使用 spinlock_t lock; struct binder_work work; union { struct rb_node rb_node;//binder节点正常使用，union struct hlist_node dead_node;//binder节点已销毁，union }; struct binder_proc *proc;//binder所在的进程 struct hlist_head refs;//所有指向该节点的binder引用队列 int internal_strong_refs; int local_weak_refs; int local_strong_refs; int tmp_refs; binder_uintptr_t ptr;//指向用户空间binder_node的指针，对应flat_binder_object.binder binder_uintptr_t cookie;//数据，对应flat_binder_object.cooki struct { /* * bitfield elements protected by * proc inner_lock */ u8 has_strong_ref:1; u8 pending_strong_ref:1; u8 has_weak_ref:1; u8 pending_weak_ref:1; }; struct { /* * invariant after initialization */ u8 sched_policy:2; u8 inherit_rt:1; u8 accept_fds:1; u8 txn_security_ctx:1; u8 min_priority; }; bool has_async_transaction; struct list_head async_todo;//异步todo队列 }; binder_ioctl_write_read binder_ioctl_write_read是binder数据交互的核心入口,在native层中通过ioctl发送BINDER_WRITE_READ命令执行该函数，arg是一个binder_write_read结构体;\nstatic int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; if (size != sizeof(struct binder_write_read)) { ret = -EINVAL; goto out; } //把用户空间数据ubuf拷贝到bwr if (copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr))) { ret = -EFAULT; goto out; } binder_debug(BINDER_DEBUG_READ_WRITE, \u0026#34;%d:%d write %lld at %016llx, read %lld at %016llx\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid, (u64)bwr.write_size, (u64)bwr.write_buffer, (u64)bwr.read_size, (u64)bwr.read_buffer); if (bwr.write_size \u0026gt; 0) { //当写缓存中有数据，则执行binder写操作 ret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); trace_binder_write_done(ret); if (ret \u0026lt; 0) { //binder_thread_write中有错误发生，则read_consumed设为0，表示kernel没有数据返回给进程 bwr.read_consumed = 0; //将bwr返回给用户态调用者，bwr在binder_thread_write中会被修改 if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) ret = -EFAULT; goto out; } } if (bwr.read_size \u0026gt; 0) { //当读缓存中有数据，则执行binder读操作 ret = binder_thread_read(proc, thread, bwr.read_buffer, bwr.read_size, \u0026amp;bwr.read_consumed, filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK); trace_binder_read_done(ret); binder_inner_proc_lock(proc); //读取完后，如果proc-\u0026gt;todo链表不为空，则唤醒在proc-\u0026gt;wait等待队列上的进程 if (!binder_worklist_empty_ilocked(\u0026amp;proc-\u0026gt;todo)) binder_wakeup_proc_ilocked(proc); binder_inner_proc_unlock(proc); if (ret \u0026lt; 0) { //如果binder_thread_read返回小于0，可能处理一半就中断了，需要将bwr拷贝回进程的用户态地址 if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) ret = -EFAULT; goto out; } } binder_debug(BINDER_DEBUG_READ_WRITE, \u0026#34;%d:%d wrote %lld of %lld, read return %lld of %lld\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid, (u64)bwr.write_consumed, (u64)bwr.write_size, (u64)bwr.read_consumed, (u64)bwr.read_size); //将内核数据bwr拷贝到用户空间ubuf if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) { ret = -EFAULT; goto out; } out: return ret; } 流程:\n用户空间数据ubuf拷贝到内核空间bwr; 当bwr写缓存有数据，则执行binder_thread_write；当写失败则read_consumed设为0，并将bwr数据写回用户空间并退出； 当bwr读缓存有数据，则执行binder_thread_read，读取完后，如果proc-\u0026gt;todo链表不为空，则唤醒在proc-\u0026gt;wait等待队列上的进程;当读失败则再将bwr数据写回用户空间并退出； 把内核数据bwr拷贝到用户空间ubuf。 ","permalink":"https://rong05.github.io/learn/android/binder_driver/","summary":"Binder Driver探索 binder驱动的初始化 在binder.c中有以下一行代码；\ndevice_initcall(binder_init); 在Linux内核的启动过程中，一个驱动的注册用module_init调用，即device_initcall，它可以将驱动设备加载进内核中，以供后续使用。\n在Android8.0之后，现在Binder驱动有三个：/dev/binder; /dev/hwbinder; /dev/vndbinder.\nstatic int __init binder_init(void) { int ret; char *device_name, *device_tmp; struct binder_device *device; struct hlist_node *tmp; char *device_names = NULL; //初始化binder缓冲区分配 ret = binder_alloc_shrinker_init(); if (ret) return ret; // ~0U：无符号整型，对0取反。 atomic_set(\u0026amp;binder_transaction_log.cur, ~0U); atomic_set(\u0026amp;binder_transaction_log_failed.cur, ~0U); // 创建/sys/kernel/debug/binder目录。 binder_debugfs_dir_entry_root = debugfs_create_dir(\u0026#34;binder\u0026#34;, NULL); // 创建/sys/kernel/debug/binder/proc目录用于记录每个进程基本信息。 if (binder_debugfs_dir_entry_root) binder_debugfs_dir_entry_proc = debugfs_create_dir(\u0026#34;proc\u0026#34;, binder_debugfs_dir_entry_root); if (binder_debugfs_dir_entry_root) { // 创建/sys/kernel/debug/binder/state文件用于记录状态信息， //并注册操作函数binder_state_fops。 debugfs_create_file(\u0026#34;state\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_state_fops); // 创建/sys/kernel/debug/binder/stats文件用于记录统计信息， //并注册操作函数binder_stats_fops。 debugfs_create_file(\u0026#34;stats\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_stats_fops); // 创建/sys/kernel/debug/binder/transactions文件用于记录transaction相关信息， //并注册操作函数binder_transactions_fops。 debugfs_create_file(\u0026#34;transactions\u0026#34;, 0444, binder_debugfs_dir_entry_root, NULL, \u0026amp;binder_transactions_fops); // 创建/sys/kernel/debug/binder/transaction_log文件用于记录transaction日志相关信息， //并注册操作函数binder_transaction_log_fops。 debugfs_create_file(\u0026#34;transaction_log\u0026#34;, 0444, binder_debugfs_dir_entry_root, \u0026amp;binder_transaction_log, \u0026amp;binder_transaction_log_fops); // 创建/sys/kernel/debug/binder/failed_transaction_log文件用于记录transaction失败日志相关信息， // 并注册操作函数binder_transaction_log_fops debugfs_create_file(\u0026#34;failed_transaction_log\u0026#34;, 0444, binder_debugfs_dir_entry_root, \u0026amp;binder_transaction_log_failed, \u0026amp;binder_transaction_log_fops); } if (!","title":""},{"content":"MediaCodec学习记录 官方API：https://developer.android.google.cn/reference/android/media/MediaCodec\n供参考的中文翻译：https://www.jianshu.com/p/06dfc5cf95a2\nMediaCodec 介绍 MediaCodec是一个Codec，通过硬件加速解码和编码。它为芯片厂商和应用开发者搭建了一个统一接口。\n一个编解码器可以处理输入的数据来产生输出的数据，编解码器使用一组输入和输出缓冲器来异步处理数据。你可以创建一个空的输入缓冲区，填充数据后发送到编解码器进行处理。编解码器使用输入的数据进行转换，然后输出到一个空的输出缓冲区。最后你获取到输出缓冲区的数据，消耗掉里面的数据，释放回编解码器。\nMediaCodec采用异步方式处理数据，并且使用了一组输入输出buffer（ByteBuffer）。\n使用者从MediaCodec请求一个空的输入buffer（ByteBuffer），填充满数据后将它传递给MediaCodec处理。 MediaCodec处理完这些数据并将处理结果输出至一个空的输出buffer（ByteBuffer）中。 使用者从MediaCodec获取输出buffer的数据，消耗掉里面的数据，使用完输出buffer的数据之后，将其释放回编解码器。 编解码器支持的数据类型： codec 处理3种类型的数据， compressed data （待解码的数据 或 编码后的数据）、raw audio data （待编码或解码后的数据）和 raw video data （待编码或解码后的数据）。\n注意：\n数据通过ByteBuffers类来表示。还可以用 Surface 来处理 raw video data 来提高性能。 可以设置Surface来获取/呈现原始的视频数据，因为 Surface 可以直接使用 native video buffers （在 native 层分配的 buffer）而不需要映射或拷贝到 ByteBuffers （ByteBuffers 是分配在 JVM 堆中的缓冲区） 中。 通常在使用Surface的时候，无法访问原始的视频数据，但是可以使用ImageReader访问解码后的原始视频帧。在使用ByteBuffer的模式下，可以使用Image类和getInput/OutputImage(int)获取原始视频帧。 压缩数据 MediaFormat#KEY_MIME格式类型。 对于视频类型，通常是一个单独的压缩视频帧。 对于音频数据，通常是一个单独的访问单元(一个编码的音频段通常包含由格式类型决定的几毫秒的音频)，但是这个要求稍微宽松一些，因为一个buffer可能包含多个编码的音频访问单元。 在这两种情况下，buffer都不会在任意字节边界上开始或结束，而是在帧/访问单元边界上开始或结束，除非它们被BUFFER_FLAG_PARTIAL_FRAME标记。 原始音频buffer 原始音频buffer包含PCM音频数据的整个帧，这是每个通道按通道顺序的一个样本。每个样本都是一个 AudioFormat#ENCODING_PCM_16BIT。\n原始视频buffer 在ByteBuffer模式下，视频buffer根据它们的MediaFormat#KEY_COLOR_FORMAT进行布局。可以从getCodecInfo(). MediaCodecInfo.getCapabilitiesForType.CodecCapability.colorFormats获取支持的颜色格式。视频编解码器可以支持三种颜色格式:\nnative raw video format: CodecCapabilities.COLOR_FormatSurface，可以与输入/输出的Surface一起使用。 flexible YUV buffers 例如CodecCapabilities.COLOR_FormatYUV420Flexible， 可以使用getInput/OutputImage(int)与输入/输出`一起使用，也可以在ByteBuffer模式下使用。 other, specific formats: 通常只支持ByteBuffer模式。有些颜色格式是厂商特有的，其他定义在CodecCapabilities。对于等价于flexible格式的颜色格式，可以使用getInput/OutputImage(int)。 从Build.VERSION_CODES.LOLLIPOP_MR1.开始，所有视频编解码器都支持flexible的YUV 4:2:0 buffer。\nMediaCodec的生命周期 MediaCodec的生命周期有三种状态：Stopped、Executing、Released。\nStopped，包含三种子状态：Uninitialized、Configured、Error。 Executing，包含三种子状态：Flushed、Running、End-of-Stream。 Stopped的三种子状态：\nUninitialized：当创建了一个MediaCodec对象，此时处于Uninitialized状态。可以在任何状态调用reset()方法使MediaCodec返回到Uninitialized状态。 Configured：使用configure(…)方法对MediaCodec进行配置转为Configured状态。 Error：MediaCodec遇到错误时进入Error状态。错误可能是在队列操作时返回的错误或者异常导致的。 Executing的三种子状态：\nFlushed：在调用start()方法后MediaCodec立即进入Flushed子状态，此时MediaCodec会拥有所有的缓存。可以在Executing状态的任何时候通过调用flush()方法返回到Flushed子状态。 Running：一旦第一个输入缓存（input buffer）被移出队列，MediaCodec就转入Running子状态，这种状态占据了MediaCodec的大部分生命周期。通过调用stop()方法转移到Uninitialized状态。 End-of-Stream：将一个带有end-of-stream标记的输入buffer入队列时，MediaCodec将转入End-of-Stream子状态。在这种状态下，MediaCodec不再接收之后的输入buffer，但它仍然产生输出buffer直到end-of-stream标记输出。 Released\n当使用完MediaCodec后，必须调用release()方法释放其资源。调用 release()方法进入最终的Released状态。 asynchronous mode MediaCodec codec = MediaCodec.createByCodecName(name); //创建编解码器 MediaFormat mOutputFormat; // member variable codec.setCallback(new MediaCodec.Callback() {//设置callback，使用异步模式完成 @Override void onInputBufferAvailable(MediaCodec mc, int inputBufferId) {//可以开始入队 ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); } @Override void onOutputBufferAvailable(MediaCodec mc, int outputBufferId, …) {//开始出队 ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is equivalent to mOutputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); } @Override void onOutputFormatChanged(MediaCodec mc, MediaFormat format) {//输出格式发生变化 // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) mOutputFormat = format; // option B } @Override void onError(…) {//出现异常 … } }); codec.configure(format, …);//配置格式 mOutputFormat = codec.getOutputFormat(); // option B codec.start();//启动 // wait for processing to complete codec.stop();//停止 codec.release();//清空 Synchronous mode MediaCodec codec = MediaCodec.createByCodecName(name);//创建编解码器 codec.configure(format, …);//配置 MediaFormat outputFormat = codec.getOutputFormat(); // option B codec.start();//启动 for (;;) { int inputBufferId = codec.dequeueInputBuffer(timeoutUs);//从输入队列中取出一个ByteBuffer，并插入原始数据 if (inputBufferId \u0026gt;= 0) { ByteBuffer inputBuffer = codec.getInputBuffer(…); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); } int outputBufferId = codec.dequeueOutputBuffer(…);//从输出队列中取出一个ByteBuffer，获取编解码后的数据 if (outputBufferId \u0026gt;= 0) { ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is identical to outputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); } else if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) { // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) outputFormat = codec.getOutputFormat(); // option B } } codec.stop(); codec.release(); MediaCodec API简介 MediaCodec创建： createDecoderByType/createEncoderByType：根据特定MIME类型(如\u0026quot;video/avc\u0026quot;)创建codec。 createByCodecName：知道组件的确切名称(如OMX.google.mp3.decoder)的时候，根据组件名创建codec。使用MediaCodecList可以获取组件的名称。 buffer处理的接口： dequeueInputBuffer：从输入流队列中取数据进行编码操作。 queueInputBuffer：输入流入队列。 dequeueOutputBuffer：从输出队列中取出编码操作之后的数据。 releaseOutputBuffer：处理完成，释放ByteBuffer数据。 getInputBuffers：获取需要编码数据的输入流队列，返回的是一个ByteBuffer数组。 getOutputBuffers：获取编解码之后的数据输出流队列，返回的是一个ByteBuffer数组。 MediaCodec控制接口 configure：配置解码器或者编码器。 start：成功配置组件后调用start。 flush：清空的输入和输出端口。 stop：终止decode/encode会话 release：释放编解码器实例使用的资源。 MediaCodec 流控 一般编码器都可以设置一个目标码率，但编码器的实际输出码率不会完全符合设置，因为在编码过程中实际可以控制的并不是最终输出的码率，而是编码过程中的一个量化参数（Quantization Parameter，QP），它和码率并没有固定的关系，而是取决于图像内容。\nMediaCodec 流控相关的接口并不多，一是配置时设置目标码率和码率控制模式，二是动态调整目标码率(Android 19 版本以上)。\n配置时指定目标码率和码率控制模式：\nmediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, bitRate); mediaFormat.setInteger(MediaFormat.KEY_BITRATE_MODE, MediaCodecInfo.EncoderCapabilities.BITRATE_MODE_VBR); mVideoCodec.configure(mediaFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE); 码率控制模式有三种：\nCQ 表示完全不控制码率，尽最大可能保证图像质量； CBR 表示编码器会尽量把输出码率控制为设定值，即我们前面提到的“不为所动”； VBR 表示编码器会根据图像内容的复杂度（实际上是帧间变化量的大小）来动态调整输出码率，图像复杂则码率高，图像简单则码率低； 动态调整目标码率：\nBundle param = new Bundle(); param.putInt(MediaCodec.PARAMETER_KEY_VIDEO_BITRATE, bitrate); mediaCodec.setParameters(param); Android 流控策略选择:\n质量要求高、不在乎带宽、解码器支持码率剧烈波动的情况下，可以选择 CQ 码率控制策略。 VBR 输出码率会在一定范围内波动，对于小幅晃动，方块效应会有所改善，但对剧烈晃动仍无能为力；连续调低码率则会导致码率急剧下降，如果无法接受这个问题，那 VBR 就不是好的选择。 CBR 的优点是稳定可控，这样对实时性的保证有帮助。所以 WebRTC 开发中一般使用的是CBR。 参考链接： https://www.jianshu.com/p/d9bd92fca0c6\nhttps://www.jianshu.com/p/06dfc5cf95a2\nhttps://developer.android.google.cn/reference/android/media/MediaCodec\n","permalink":"https://rong05.github.io/learn/android/mediacodec_learn/","summary":"MediaCodec学习记录 官方API：https://developer.android.google.cn/reference/android/media/MediaCodec\n供参考的中文翻译：https://www.jianshu.com/p/06dfc5cf95a2\nMediaCodec 介绍 MediaCodec是一个Codec，通过硬件加速解码和编码。它为芯片厂商和应用开发者搭建了一个统一接口。\n一个编解码器可以处理输入的数据来产生输出的数据，编解码器使用一组输入和输出缓冲器来异步处理数据。你可以创建一个空的输入缓冲区，填充数据后发送到编解码器进行处理。编解码器使用输入的数据进行转换，然后输出到一个空的输出缓冲区。最后你获取到输出缓冲区的数据，消耗掉里面的数据，释放回编解码器。\nMediaCodec采用异步方式处理数据，并且使用了一组输入输出buffer（ByteBuffer）。\n使用者从MediaCodec请求一个空的输入buffer（ByteBuffer），填充满数据后将它传递给MediaCodec处理。 MediaCodec处理完这些数据并将处理结果输出至一个空的输出buffer（ByteBuffer）中。 使用者从MediaCodec获取输出buffer的数据，消耗掉里面的数据，使用完输出buffer的数据之后，将其释放回编解码器。 编解码器支持的数据类型： codec 处理3种类型的数据， compressed data （待解码的数据 或 编码后的数据）、raw audio data （待编码或解码后的数据）和 raw video data （待编码或解码后的数据）。\n注意：\n数据通过ByteBuffers类来表示。还可以用 Surface 来处理 raw video data 来提高性能。 可以设置Surface来获取/呈现原始的视频数据，因为 Surface 可以直接使用 native video buffers （在 native 层分配的 buffer）而不需要映射或拷贝到 ByteBuffers （ByteBuffers 是分配在 JVM 堆中的缓冲区） 中。 通常在使用Surface的时候，无法访问原始的视频数据，但是可以使用ImageReader访问解码后的原始视频帧。在使用ByteBuffer的模式下，可以使用Image类和getInput/OutputImage(int)获取原始视频帧。 压缩数据 MediaFormat#KEY_MIME格式类型。 对于视频类型，通常是一个单独的压缩视频帧。 对于音频数据，通常是一个单独的访问单元(一个编码的音频段通常包含由格式类型决定的几毫秒的音频)，但是这个要求稍微宽松一些，因为一个buffer可能包含多个编码的音频访问单元。 在这两种情况下，buffer都不会在任意字节边界上开始或结束，而是在帧/访问单元边界上开始或结束，除非它们被BUFFER_FLAG_PARTIAL_FRAME标记。 原始音频buffer 原始音频buffer包含PCM音频数据的整个帧，这是每个通道按通道顺序的一个样本。每个样本都是一个 AudioFormat#ENCODING_PCM_16BIT。\n原始视频buffer 在ByteBuffer模式下，视频buffer根据它们的MediaFormat#KEY_COLOR_FORMAT进行布局。可以从getCodecInfo(). MediaCodecInfo.getCapabilitiesForType.CodecCapability.colorFormats获取支持的颜色格式。视频编解码器可以支持三种颜色格式:\nnative raw video format: CodecCapabilities.COLOR_FormatSurface，可以与输入/输出的Surface一起使用。 flexible YUV buffers 例如CodecCapabilities.","title":""},{"content":"MediaCodec源码学习 在另一个篇文章中已经介绍了MediaCodec的API，详情请看MediaCodec_learn;\n主要从MediaCodec源码主要结构入手分析，并基于对主要结构的理解;\n整体框架 与Android其他API类似，MediaCodec主要分为API、JNI、Native、service四个部分。\nMediaCodec主要框架结构如：\n应用代码编写时使用的是java层MediaCodec的接口。这里主要是通过JNI调用Native代码。 进入JNI代码后，主要与JMediaCodec打交道，JMediaCodec负责调用MediaCodec(c++)的方法。 在MediaCodec(c++)和ACodec中包含了解码器（客户端）的主要逻辑。最后ACodec作为MediaCodec与OMX的桥梁，负责调用OMX服务端的功能。 OMX服务端主要是OMX封装层和OMX管理层，其中使用 OpenMax 集成层标准实现的硬件编解码器。（server端不在此篇介绍） 接下来主要看一下client端是如何创建MediaCodec的。\nMediaCodec的创建过程 MediaCodec(java)类的构造函数中主要调用了native_setup方法！\nprivate MediaCodec( @NonNull String name, boolean nameIsType, boolean encoder) { Looper looper; //获取创建MediaCodec的当前线程Looper,并且创建事件处理handler if ((looper = Looper.myLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else if ((looper = Looper.getMainLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else { mEventHandler = null; } mCallbackHandler = mEventHandler; mOnFrameRenderedHandler = mEventHandler; mBufferLock = new Object(); // save name used at creation mNameAtCreation = nameIsType ? null : name; //通过jni实现native的MediaCodec创建 native_setup(name, nameIsType, encoder); } jni中native_setup方法实现函数是android_media_MediaCodec.cpp中的android_media_MediaCodec_native_setup函数，主要看看android_media_MediaCodec_native_setup函数具体处理了过程！代码如下：\nstatic void android_media_MediaCodec_native_setup( JNIEnv *env, jobject thiz, jstring name, jboolean nameIsType, jboolean encoder) { if (name == NULL) { jniThrowException(env, \u0026#34;java/lang/NullPointerException\u0026#34;, NULL); return; } const char *tmp = env-\u0026gt;GetStringUTFChars(name, NULL); if (tmp == NULL) { return; } //创建JMediaCodec对象 sp\u0026lt;JMediaCodec\u0026gt; codec = new JMediaCodec(env, thiz, tmp, nameIsType, encoder); //获取初始化状态值，并判断初始化创建MediaCodec(c++)是否成功! const status_t err = codec-\u0026gt;initCheck(); if (err == NAME_NOT_FOUND) { // fail and do not try again. jniThrowException(env, \u0026#34;java/lang/IllegalArgumentException\u0026#34;, String8::format(\u0026#34;Failed to initialize %s, error %#x\u0026#34;, tmp, err)); env-\u0026gt;ReleaseStringUTFChars(name, tmp); return; } if (err == NO_MEMORY) { throwCodecException(env, err, ACTION_CODE_TRANSIENT, String8::format(\u0026#34;Failed to initialize %s, error %#x\u0026#34;, tmp, err)); env-\u0026gt;ReleaseStringUTFChars(name, tmp); return; } else if (err != OK) { // believed possible to try again jniThrowException(env, \u0026#34;java/io/IOException\u0026#34;, String8::format(\u0026#34;Failed to find matching codec %s, error %#x\u0026#34;, tmp, err)); env-\u0026gt;ReleaseStringUTFChars(name, tmp); return; } env-\u0026gt;ReleaseStringUTFChars(name, tmp); //注册回调事件监听 codec-\u0026gt;registerSelf(); //在MediaCodec.java绑定JMediaCodec对象的指针地址 setMediaCodec(env,thiz, codec); } static sp\u0026lt;JMediaCodec\u0026gt; setMediaCodec( JNIEnv *env, jobject thiz, const sp\u0026lt;JMediaCodec\u0026gt; \u0026amp;codec) { //执行MediaCodec,java中的lockAndGetContext函数 sp\u0026lt;JMediaCodec\u0026gt; old = (JMediaCodec *)env-\u0026gt;CallLongMethod(thiz, gFields.lockAndGetContextID); if (codec != NULL) { codec-\u0026gt;incStrong(thiz); } if (old != NULL) { /* release MediaCodec and stop the looper now before decStrong. * otherwise JMediaCodec::~JMediaCodec() could be called from within * its message handler, doing release() from there will deadlock * (as MediaCodec::release() post synchronous message to the same looper) */ old-\u0026gt;release(); old-\u0026gt;decStrong(thiz); } //执行MediaCodec,java中的setAndUnlockContext函数,并传入JMediaCodec对象的指针地址 env-\u0026gt;CallVoidMethod(thiz, gFields.setAndUnlockContextID, (jlong)codec.get()); return old; } /***************MediaCodec.java*****************/ private final long lockAndGetContext() { mNativeContextLock.lock(); return mNativeContext; } private final void setAndUnlockContext(long context) { mNativeContext = context; mNativeContextLock.unlock(); } 创建JMediaCodec对象，并获取初始化状态值，并判断初始化创建MediaCodec(c++)是否成功! 注册回调事件监听,因为JMediaCodec对象是继承AHandler； 执行MediaCodec.java的setAndUnlockContext方法绑定JMediaCodec对象的指针地址； JMediaCodec对象定义和构造函数处理，代码如下：\nstruct JMediaCodec : public AHandler { //…… private: sp\u0026lt;ALooper\u0026gt; mLooper; //mLooper-\u0026gt;setName(\u0026#34;MediaCodec_looper\u0026#34;); sp\u0026lt;MediaCodec\u0026gt; mCodec;//MediaCodec::CreateByType/CreateByComponentName //…… protected: //…… virtual void onMessageReceived(const sp\u0026lt;AMessage\u0026gt; \u0026amp;msg); }; JMediaCodec::JMediaCodec( JNIEnv *env, jobject thiz, const char *name, bool nameIsType, bool encoder) : mClass(NULL), mObject(NULL) { jclass clazz = env-\u0026gt;GetObjectClass(thiz); CHECK(clazz != NULL); mClass = (jclass)env-\u0026gt;NewGlobalRef(clazz); mObject = env-\u0026gt;NewWeakGlobalRef(thiz); cacheJavaObjects(env); //创建looper,looper主要负责消息的派发和提供线程环境用于消息的执行 mLooper = new ALooper; mLooper-\u0026gt;setName(\u0026#34;MediaCodec_looper\u0026#34;); //启动ANDROID_PRIORITY_VIDEO线程 mLooper-\u0026gt;start( false, // runOnCallingThread true, // canCallJava ANDROID_PRIORITY_VIDEO); //创建MediaCodec(c++)对象 if (nameIsType) { mCodec = MediaCodec::CreateByType(mLooper, name, encoder, \u0026amp;mInitStatus); if (mCodec == nullptr || mCodec-\u0026gt;getName(\u0026amp;mNameAtCreation) != OK) { mNameAtCreation = \u0026#34;(null)\u0026#34;; } } else { mCodec = MediaCodec::CreateByComponentName(mLooper, name, \u0026amp;mInitStatus); mNameAtCreation = name; } CHECK((mCodec != NULL) != (mInitStatus != OK)); } // static sp\u0026lt;MediaCodec\u0026gt; MediaCodec::CreateByComponentName( const sp\u0026lt;ALooper\u0026gt; \u0026amp;looper, const AString \u0026amp;name, status_t *err, pid_t pid, uid_t uid) { sp\u0026lt;MediaCodec\u0026gt; codec = new MediaCodec(looper, pid, uid); const status_t ret = codec-\u0026gt;init(name); if (err != NULL) { *err = ret; } return ret == OK ? codec : NULL; // NULL deallocates codec. } JMediaCodec构造函数处理比较简单，主要是创建looper用于消息处理和提供线程环境，再通过CreateByType/CreateByComponentName函数创建MediaCodec(c++)对象 和执行MediaCodec(c++)对象的init函数；mLooper用于MediaCodec(c++，下文如无特别说明MediaCodec均指c++中的MediaCodec类)的事件循环;接下来的分析都不在从api和jni开始，MediaCodec框架中的关键逻辑都在MediaCodec(c++)类实现；\n","permalink":"https://rong05.github.io/learn/android/mediacodec_source_learn/","summary":"MediaCodec源码学习 在另一个篇文章中已经介绍了MediaCodec的API，详情请看MediaCodec_learn;\n主要从MediaCodec源码主要结构入手分析，并基于对主要结构的理解;\n整体框架 与Android其他API类似，MediaCodec主要分为API、JNI、Native、service四个部分。\nMediaCodec主要框架结构如：\n应用代码编写时使用的是java层MediaCodec的接口。这里主要是通过JNI调用Native代码。 进入JNI代码后，主要与JMediaCodec打交道，JMediaCodec负责调用MediaCodec(c++)的方法。 在MediaCodec(c++)和ACodec中包含了解码器（客户端）的主要逻辑。最后ACodec作为MediaCodec与OMX的桥梁，负责调用OMX服务端的功能。 OMX服务端主要是OMX封装层和OMX管理层，其中使用 OpenMax 集成层标准实现的硬件编解码器。（server端不在此篇介绍） 接下来主要看一下client端是如何创建MediaCodec的。\nMediaCodec的创建过程 MediaCodec(java)类的构造函数中主要调用了native_setup方法！\nprivate MediaCodec( @NonNull String name, boolean nameIsType, boolean encoder) { Looper looper; //获取创建MediaCodec的当前线程Looper,并且创建事件处理handler if ((looper = Looper.myLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else if ((looper = Looper.getMainLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else { mEventHandler = null; } mCallbackHandler = mEventHandler; mOnFrameRenderedHandler = mEventHandler; mBufferLock = new Object(); // save name used at creation mNameAtCreation = nameIsType ?","title":""},{"content":"[TOC]\nffplay源码分析 熟悉FFmpeg项目从源码看起，以下是我阅读FFplay的源代码的总结；FFplay是FFmpeg项目提供的播放器示例，它的源代码的量也是不少的，其中很多知识点是我们可以学习和借鉴的。\n总结构图 参照雷神（雷霄骅）的FFplay的总体函数调用结构图，自己总结了一个最新版本的结构，其中还有诸多不足，以后有机会慢慢完善；如下图所示。\n这就不对主要函数分别解析，我来学习一下其中关键性的思想和ffplay的体系结构。\n视频部分 ffplay video的线程模式 ffplay选择了sdl作为显示SDK，以实现跨平台支持；因为使用了SDL，而video的显示也依赖SDL的窗口显示系统，所以先从main函数的SDL初始化看起：\nint main(int argc, char **argv) { ... /* register all codecs, demux and protocols */ #if CONFIG_AVDEVICE avdevice_register_all(); //注册所有解码器 #endif avformat_network_init(); init_opts(); signal(SIGINT, sigterm_handler); /* Interrupt (ANSI). */ signal(SIGTERM, sigterm_handler); /* Termination (ANSI). */ show_banner(argc, argv, options); //打印ffmpag库版本信息，编译时间，编译选项，类库信息等 parse_options(NULL, argc, argv, options, opt_input_file); //解析输入的命令。 ... if (SDL_Init(flags)) { //初始化sdl av_log(NULL, AV_LOG_FATAL, \u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); av_log(NULL, AV_LOG_FATAL, \u0026#34;(Did you set the DISPLAY variable?)\\n\u0026#34;); exit(1); } SDL_EventState(SDL_SYSWMEVENT, SDL_IGNORE); SDL_EventState(SDL_USEREVENT, SDL_IGNORE); //注册flush packet 只是一个标记作用，用于packet队列中，在对packet队列分析时有说明 av_init_packet(\u0026amp;flush_pkt); flush_pkt.data = (uint8_t *)\u0026amp;flush_pkt; ... if (!display_disable) { int flags = SDL_WINDOW_HIDDEN; if (alwaysontop) #if SDL_VERSION_ATLEAST(2, 0, 5) flags |= SDL_WINDOW_ALWAYS_ON_TOP; #else av_log(NULL, AV_LOG_WARNING, \u0026#34;Your SDL version doesn\u0026#39;t support SDL_WINDOW_ALWAYS_ON_TOP. Feature will be inactive.\\n\u0026#34;); #endif if (borderless) flags |= SDL_WINDOW_BORDERLESS; else flags |= SDL_WINDOW_RESIZABLE; //创建sdl 窗口 window = SDL_CreateWindow(program_name, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, default_width, default_height, flags); SDL_SetHint(SDL_HINT_RENDER_SCALE_QUALITY, \u0026#34;linear\u0026#34;); if (window) { //创建sdl 窗口的渲染器 renderer = SDL_CreateRenderer(window, -1, SDL_RENDERER_ACCELERATED | SDL_RENDERER_PRESENTVSYNC); if (!renderer) { av_log(NULL, AV_LOG_WARNING, \u0026#34;Failed to initialize a hardware accelerated renderer: %s\\n\u0026#34;, SDL_GetError()); renderer = SDL_CreateRenderer(window, -1, 0); } if (renderer) { if (!SDL_GetRendererInfo(renderer, \u0026amp;renderer_info)) av_log(NULL, AV_LOG_VERBOSE, \u0026#34;Initialized %s renderer.\\n\u0026#34;, renderer_info.name); } } if (!window || !renderer || !renderer_info.num_texture_formats) { av_log(NULL, AV_LOG_FATAL, \u0026#34;Failed to create window or renderer: %s\u0026#34;, SDL_GetError()); do_exit(NULL); } } is = stream_open(input_filename, file_iformat); //创建read_thread if (!is) { av_log(NULL, AV_LOG_FATAL, \u0026#34;Failed to initialize VideoState!\\n\u0026#34;); do_exit(NULL); } event_loop(is); //主线程 ，sdl——event事件监听和处理 } 而这里我们主要的两个函数是stream_open和event_loop；stream_open函数的作用是创建read_thread，read_thread会打开文件，解析封装，获取AVStream信息，启动解码器（创建解码线程），并开始读取文件；event_loop函数的作用是处理SDL事件队列中的事件和刷新显示数据，下面会针对这两个函数视频部分的内容进行详细说明。\nstream_open 其实在stream_open函数里的关键内容都是初始化一些参数，主要的处理逻辑在read_thread中进行。\nstatic VideoState *stream_open(const char *filename, AVInputFormat *iformat) { VideoState *is; is = av_mallocz(sizeof(VideoState)); //创建VideoState 这个很重要，它贯穿整个ffplay ... /* start video display */ //初始化解码后的帧队列 if (frame_queue_init(\u0026amp;is-\u0026gt;pictq, \u0026amp;is-\u0026gt;videoq, VIDEO_PICTURE_QUEUE_SIZE, 1) \u0026lt; 0) goto fail; ... //初始化解码前的帧队列 if (packet_queue_init(\u0026amp;is-\u0026gt;videoq) \u0026lt; 0 || ... //创建读线程的条件信号 if (!(is-\u0026gt;continue_read_thread = SDL_CreateCond())) { av_log(NULL, AV_LOG_FATAL, \u0026#34;SDL_CreateCond(): %s\\n\u0026#34;, SDL_GetError()); goto fail; } //初始化时钟 init_clock(\u0026amp;is-\u0026gt;vidclk, \u0026amp;is-\u0026gt;videoq.serial); ... is-\u0026gt;read_tid = SDL_CreateThread(read_thread, \u0026#34;read_thread\u0026#34;, is); //创建读线程 ... fail: stream_close(is);//出错free一些初始化参数 return NULL; } **VideoState**结构的参数详细说明：\n/*视频状态器，贯穿整个ffplay的结构*/ typedef struct VideoState { SDL_Thread *read_tid; //解复用（或读）线程 AVInputFormat *iformat; //输入格式 int abort_request; //中止请求 int force_refresh; //强制刷新 int paused; //暂停 int last_paused; //最后一次暂停状态 int queue_attachments_req; //队列附件请求 int seek_req; //快进请求 int seek_flags; //快进标志 int64_t seek_pos; //快进位置 int64_t seek_rel; int read_pause_return; //读暂停 AVFormatContext *ic; //解码格式上下文 int realtime; //是否实时码流 Clock audclk; //音频时钟 Clock vidclk; //视频时钟 Clock extclk; //外部时钟 FrameQueue pictq; //视频队列 FrameQueue subpq; //字幕队列 FrameQueue sampq; //pcm流队列 Decoder auddec; //音频解码器 Decoder viddec; //视频解码器 Decoder subdec; //字幕解码器 int audio_stream; //音频码流id int av_sync_type; //时钟同步类型 double audio_clock; int audio_clock_serial; //音频时钟序号 double audio_diff_cum; // 用于音频差分计算 /* used for AV difference average computation */ double audio_diff_avg_coef; double audio_diff_threshold; //音频差分阈值 int audio_diff_avg_count; // 平均差分数量 AVStream *audio_st; // 音频码流 PacketQueue audioq; // 音频源包队列 int audio_hw_buf_size; // 硬件缓冲大小 uint8_t *audio_buf; // 音频缓冲区 uint8_t *audio_buf1; // 音频缓冲区1 unsigned int audio_buf_size; // 音频缓冲大小 /* in bytes */ unsigned int audio_buf1_size; // 音频缓冲大小 1 int audio_buf_index; /* in bytes */ // 音频缓冲索引 int audio_write_buf_size; // 音频写入缓冲大小 int audio_volume; // 音量 int muted; // 是否静音 struct AudioParams audio_src; // 音频参数 #if CONFIG_AVFILTER struct AudioParams audio_filter_src; // 音频过滤器 #endif struct AudioParams audio_tgt; // 音频参数 struct SwrContext *swr_ctx; // 音频转码上下文 int frame_drops_early; int frame_drops_late; enum ShowMode { // 显示类型 SHOW_MODE_NONE = -1, SHOW_MODE_VIDEO = 0, SHOW_MODE_WAVES, SHOW_MODE_RDFT, SHOW_MODE_NB } show_mode; int16_t sample_array[SAMPLE_ARRAY_SIZE]; // 采样数组 int sample_array_index; // 采样索引 int last_i_start; // 上一开始 RDFTContext *rdft; // 自适应滤波器上下文 int rdft_bits; // 自使用比特率 FFTSample *rdft_data; // 快速傅里叶采样 int xpos; double last_vis_time; SDL_Texture *vis_texture; // 音频Texture SDL_Texture *sub_texture; // 字幕Texture SDL_Texture *vid_texture; // 视频Texture int subtitle_stream; // 字幕码流Id AVStream *subtitle_st; // 字幕码流 PacketQueue subtitleq; // 字幕源包队列 double frame_timer; // 帧计时器 double frame_last_returned_time; // 上一次返回时间 double frame_last_filter_delay; // 上一个过滤器延时 int video_stream; // 视频码流Id AVStream *video_st; // 视频码流 PacketQueue videoq; // 视频包队列 double max_frame_duration; // 最大帧间显示时间 // maximum duration of a frame - above this, we consider the jump a timestamp discontinuity struct SwsContext *img_convert_ctx; // 视频转码上下文 struct SwsContext *sub_convert_ctx; // 字幕转码上下文 int eof; // 结束标志 char *filename; // 文件名 int width, height, xleft, ytop; // 宽高，其实坐标 int step; #if CONFIG_AVFILTER int vfilter_idx; // 过滤器索引 AVFilterContext *in_video_filter; // the first filter in the video chain AVFilterContext *out_video_filter; // the last filter in the video chain AVFilterContext *in_audio_filter; // the first filter in the audio chain AVFilterContext *out_audio_filter; // the last filter in the audio chain AVFilterGraph *agraph; // audio filter graph #endif int last_video_stream, last_audio_stream, last_subtitle_stream; SDL_cond *continue_read_thread; } VideoState; 读取线程(read_thread) read_thread主要按以下步骤执行：\n准备阶段：打开文件，检测Stream信息，打开解码器 主循环读数据，解封装：读取Packet，存入PacketQueue read_thread的函数比较长，这里不贴完整代码，直接根据其功能分步分析。\n准备阶段 主要执行一下几个步骤的函数：\navformat_open_input avformat_find_stream_info av_find_best_stream stream_component_open avformat_open_input 该函数用于打开输入流（这个包括文件和网络流，在ffmpeg内部会把每一个协议封装成URLProtocol，文件对于ffmpeg也是一种协议“file”）\nic = avformat_alloc_context(); //创建 AVformatContext if (!ic) { av_log(NULL, AV_LOG_FATAL, \u0026#34;Could not allocate context.\\n\u0026#34;); ret = AVERROR(ENOMEM); goto fail; } //设置解码中断回调方法 ，这很重要，在网络中断的时候，发生调用；不设置很容易造成阻塞 ic-\u0026gt;interrupt_callback.callback = decode_interrupt_cb; ic-\u0026gt;interrupt_callback.opaque = is; if (!av_dict_get(format_opts, \u0026#34;scan_all_pmts\u0026#34;, NULL, AV_DICT_MATCH_CASE)) { av_dict_set(\u0026amp;format_opts, \u0026#34;scan_all_pmts\u0026#34;, \u0026#34;1\u0026#34;, AV_DICT_DONT_OVERWRITE); scan_all_pmts_set = 1; } err = avformat_open_input(\u0026amp;ic, is-\u0026gt;filename, is-\u0026gt;iformat, \u0026amp;format_opts); //打开文件或网络流 if (err \u0026lt; 0) { print_error(is-\u0026gt;filename, err); ret = -1; goto fail; } 重点强调：**interrupt_callback**用于ffmpeg内部在执行耗时操作时检查是否有退出请求，并提前中断，避免用户退出请求没有及时响应；\navformat_find_stream_info 该函数是通过读取媒体文件的部分数据来分析流信息；在一些缺少头信息的封装下特别有用，如注释：\nRead packets of a media file to get stream information. This is useful for file formats with no headers such as MPEG. This function also computes the real framerate in case of MPEG-2 repeat rame mode. The logical file position is not changed by this function; examined packets may be buffered for later processing. av_find_best_stream 该函数选择对应的媒体流，ffplay主要通过下述注释中的3个参数找到“最佳流”；\nint av_find_best_stream(AVFormatContext *ic, enum AVMediaType type,//要选择的流类型 int wanted_stream_nb,//目标流索引 int related_stream,//参考流索引 AVCodec **decoder_ret, int flags); stream_component_open 该函数是根据目标流打开对应的解码器；stream_component_open的函数内容比较长，接下来就逐步分析一下ffplay是如何打开解码器的：\n创建和初始化AVCodecContex，然后通过avcodec_parameters_to_context把所选流的解码参数赋给avctx，最后设了time_base.代码如下： //创建编解码器上下文 avctx = avcodec_alloc_context3(NULL); if (!avctx) return AVERROR(ENOMEM); //从找到对应的流中的codecpar，codecpar其实是avcodec_parameters， // 然后将它完全复制到创建的AVCodecContext ret = avcodec_parameters_to_context(avctx, ic-\u0026gt;streams[stream_index]-\u0026gt;codecpar); if (ret \u0026lt; 0) goto fail; avctx-\u0026gt;pkt_timebase = ic-\u0026gt;streams[stream_index]-\u0026gt;time_base; 通过avcodec_find_decoder找到对应的解码器（AVCodec）,如果用户设置了forced_codec_name，则通过avcodec_find_decoder_by_name找到对应的解码器；在找到解码器后通过avcodec_open2是否能打开解码器\ncodec = avcodec_find_decoder(avctx-\u0026gt;codec_id); //找到对应的解码器 switch (avctx-\u0026gt;codec_type) { case AVMEDIA_TYPE_AUDIO: is-\u0026gt;last_audio_stream = stream_index; forced_codec_name = audio_codec_name; break; case AVMEDIA_TYPE_SUBTITLE: is-\u0026gt;last_subtitle_stream = stream_index; forced_codec_name = subtitle_codec_name; break; case AVMEDIA_TYPE_VIDEO: is-\u0026gt;last_video_stream = stream_index; forced_codec_name = video_codec_name; break; } //通过编码器的名字，来打开对应的解码器 if (forced_codec_name) codec = avcodec_find_decoder_by_name(forced_codec_name); if (!codec) { if (forced_codec_name) av_log(NULL, AV_LOG_WARNING, \u0026#34;No codec could be found with name \u0026#39;%s\u0026#39;\\n\u0026#34;, forced_codec_name); else av_log(NULL, AV_LOG_WARNING, \u0026#34;No decoder could be found for codec %s\\n\u0026#34;, avcodec_get_name(avctx-\u0026gt;codec_id)); ret = AVERROR(EINVAL); goto fail; } ... //打开解码器 if ((ret = avcodec_open2(avctx, codec, \u0026amp;opts)) \u0026lt; 0) { goto fail; } 对于解码器特定参数的初始化和创建对应流的解码线程；（节选自AVMEDIA_TYPE_VIDEO分支）\nis-\u0026gt;video_stream = stream_index; is-\u0026gt;video_st = ic-\u0026gt;streams[stream_index]; decoder_init(\u0026amp;is-\u0026gt;viddec, avctx, \u0026amp;is-\u0026gt;videoq, is-\u0026gt;continue_read_thread); if ((ret = decoder_start(\u0026amp;is-\u0026gt;viddec, video_thread, \u0026#34;video_decoder\u0026#34;, is)) \u0026lt; 0) goto out; is-\u0026gt;queue_attachments_req = 1; 看看decoder_init和decoder_start两个函数的定义：\nstatic void decoder_init(Decoder *d, AVCodecContext *avctx, PacketQueue *queue, SDL_cond *empty_queue_cond) { memset(d, 0, sizeof(Decoder)); d-\u0026gt;avctx = avctx; d-\u0026gt;queue = queue; d-\u0026gt;empty_queue_cond = empty_queue_cond; d-\u0026gt;start_pts = AV_NOPTS_VALUE; d-\u0026gt;pkt_serial = -1; } static int decoder_start(Decoder *d, int (*fn)(void *), const char *thread_name, void *arg) { packet_queue_start(d-\u0026gt;queue); d-\u0026gt;decoder_tid = SDL_CreateThread(fn, thread_name, arg); if (!d-\u0026gt;decoder_tid) { av_log(NULL, AV_LOG_ERROR, \u0026#34;SDL_CreateThread(): %s\\n\u0026#34;, SDL_GetError()); return AVERROR(ENOMEM); } return 0; } decoder_init比较简单，看decoder_start。decoder_start中“启动”了PacketQueue，并创建了一个名为\u0026quot;decoder\u0026quot;的线程专门用于解码，具体的解码流程由传入参数fn决定。比如对于视频，是video_thread。\n主循环读数据 在读线程中的主循环读数据阶段，主要的代码就av_read_frame和packet_queue_put，av_read_frame从文件中读取视频数据，并获取一个AVPacket，packet_queue_put把它放入到对应的PacketQueue中。\nfor (;;) { if (is-\u0026gt;abort_request) //中断，结束播放 break; if (is-\u0026gt;paused != is-\u0026gt;last_paused)//暂停/恢复的处理 { ... } if (is-\u0026gt;seek_req) { //跳帧请求 ... } /* if the queue are full, no need to read more */ //数据队列满的情况 if (infinite_buffer \u0026lt; 1 \u0026amp;\u0026amp; (is-\u0026gt;audioq.size + is-\u0026gt;videoq.size + is-\u0026gt;subtitleq.size \u0026gt; MAX_QUEUE_SIZE || (stream_has_enough_packets(is-\u0026gt;audio_st, is-\u0026gt;audio_stream, \u0026amp;is-\u0026gt;audioq) \u0026amp;\u0026amp; stream_has_enough_packets(is-\u0026gt;video_st, is-\u0026gt;video_stream, \u0026amp;is-\u0026gt;videoq) \u0026amp;\u0026amp; stream_has_enough_packets(is-\u0026gt;subtitle_st, is-\u0026gt;subtitle_stream, \u0026amp;is-\u0026gt;subtitleq)))) { /* wait 10 ms */ SDL_LockMutex(wait_mutex); SDL_CondWaitTimeout(is-\u0026gt;continue_read_thread, wait_mutex, 10); SDL_UnlockMutex(wait_mutex); continue; } //循环播放处理 if (!is-\u0026gt;paused \u0026amp;\u0026amp; (!is-\u0026gt;audio_st || (is-\u0026gt;auddec.finished == is-\u0026gt;audioq.serial \u0026amp;\u0026amp; frame_queue_nb_remaining(\u0026amp;is-\u0026gt;sampq) == 0)) \u0026amp;\u0026amp; (!is-\u0026gt;video_st || (is-\u0026gt;viddec.finished == is-\u0026gt;videoq.serial \u0026amp;\u0026amp; frame_queue_nb_remaining(\u0026amp;is-\u0026gt;pictq) == 0))) { if (loop != 1 \u0026amp;\u0026amp; (!loop || --loop)) { stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0); } else if (autoexit) { ret = AVERROR_EOF; goto fail; } } ret = av_read_frame(ic, pkt); //将数据读取出，送入队列 if (ret \u0026lt; 0) { if ((ret == AVERROR_EOF || avio_feof(ic-\u0026gt;pb)) \u0026amp;\u0026amp; !is-\u0026gt;eof) { if (is-\u0026gt;video_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;videoq, is-\u0026gt;video_stream); if (is-\u0026gt;audio_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;audioq, is-\u0026gt;audio_stream); if (is-\u0026gt;subtitle_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;subtitleq, is-\u0026gt;subtitle_stream); is-\u0026gt;eof = 1; } if (ic-\u0026gt;pb \u0026amp;\u0026amp; ic-\u0026gt;pb-\u0026gt;error) { if (autoexit) goto fail; else break; } /*读取失败的话，读取失败的原因有很多，其他地方可能会重新Signal这个锁condition。如果没有singal这个condition的话，就会等待10ms之后， 再释放，重新循环读取. 那这个continue_read_thread 到底是锁了哪呢？*/ SDL_LockMutex(wait_mutex); SDL_CondWaitTimeout(is-\u0026gt;continue_read_thread, wait_mutex, 10); SDL_UnlockMutex(wait_mutex); continue; } else { is-\u0026gt;eof = 0; } /* check if packet is in play range specified by user, then queue, otherwise discard */ //记录stream_start_time stream_start_time = ic-\u0026gt;streams[pkt-\u0026gt;stream_index]-\u0026gt;start_time; //如果没有pts, 就用dts pkt_ts = pkt-\u0026gt;pts == AV_NOPTS_VALUE ? pkt-\u0026gt;dts : pkt-\u0026gt;pts; /*判断是否在范围内。如果duration还没被定义的话，通过 或者在定义的duration内才可以，用当前的pts-start_time . duration 会在解码器打开之后，才会被初始化*/ pkt_in_play_range = duration == AV_NOPTS_VALUE || (pkt_ts - (stream_start_time != AV_NOPTS_VALUE ? stream_start_time : 0)) * av_q2d(ic-\u0026gt;streams[pkt-\u0026gt;stream_index]-\u0026gt;time_base) - (double)(start_time != AV_NOPTS_VALUE ? start_time : 0) / 1000000 \u0026lt;= ((double)duration / 1000000); // 将解复用得到的数据包添加到对应的待解码队列中 if (pkt-\u0026gt;stream_index == is-\u0026gt;audio_stream \u0026amp;\u0026amp; pkt_in_play_range) { packet_queue_put(\u0026amp;is-\u0026gt;audioq, pkt); } else if (pkt-\u0026gt;stream_index == is-\u0026gt;video_stream \u0026amp;\u0026amp; pkt_in_play_range \u0026amp;\u0026amp; !(is-\u0026gt;video_st-\u0026gt;disposition \u0026amp; AV_DISPOSITION_ATTACHED_PIC)) { packet_queue_put(\u0026amp;is-\u0026gt;videoq, pkt); } else if (pkt-\u0026gt;stream_index == is-\u0026gt;subtitle_stream \u0026amp;\u0026amp; pkt_in_play_range) { packet_queue_put(\u0026amp;is-\u0026gt;subtitleq, pkt); } else { av_packet_unref(pkt); } } 暂停/恢复处理： if (is-\u0026gt;paused != is-\u0026gt;last_paused) {//如果paused变量改变，说明暂停状态改变 is-\u0026gt;last_paused = is-\u0026gt;paused; if (is-\u0026gt;paused)//如果暂停调用av_read_pause is-\u0026gt;read_pause_return = av_read_pause(ic); else//如果恢复播放调用av_read_play av_read_play(ic); } ffmpeg有专门针对暂停和恢复的函数，所以直接调用就可以了。\nseek的处理： 主要的seek操作通过avformat_seek_file完成。根据avformat_seek_file的返回值，如果seek成功，需要：\n清除PacketQueue的缓存，并放入一个flush_pkt。放入的flush_pkt可以让PacketQueue的serial增1，以区分seek前后的数据;(在分析PacketQueue会详细说明) 同步外部时钟；（在音视频同步部分会详细说明） 最后清理一些变量，通过step_to_next_frame完成 ret = avformat_seek_file(is-\u0026gt;ic, -1, seek_min, seek_target, seek_max, is-\u0026gt;seek_flags); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;%s: error while seeking\\n\u0026#34;, is-\u0026gt;ic-\u0026gt;url); } else { //清空缓冲队列，向解码线程传入flush事件 if (is-\u0026gt;audio_stream \u0026gt;= 0) { packet_queue_flush(\u0026amp;is-\u0026gt;audioq); packet_queue_put(\u0026amp;is-\u0026gt;audioq, \u0026amp;flush_pkt); } if (is-\u0026gt;subtitle_stream \u0026gt;= 0) { packet_queue_flush(\u0026amp;is-\u0026gt;subtitleq); packet_queue_put(\u0026amp;is-\u0026gt;subtitleq, \u0026amp;flush_pkt); } if (is-\u0026gt;video_stream \u0026gt;= 0) { packet_queue_flush(\u0026amp;is-\u0026gt;videoq); packet_queue_put(\u0026amp;is-\u0026gt;videoq, \u0026amp;flush_pkt); } //同步外部时钟信号 if (is-\u0026gt;seek_flags \u0026amp; AVSEEK_FLAG_BYTE) { set_clock(\u0026amp;is-\u0026gt;extclk, NAN, 0); } else { set_clock(\u0026amp;is-\u0026gt;extclk, seek_target / (double)AV_TIME_BASE, 0); } } is-\u0026gt;seek_req = 0; is-\u0026gt;queue_attachments_req = 1; is-\u0026gt;eof = 0; if (is-\u0026gt;paused) step_to_next_frame(is); 缓冲区大小判断： 缓冲区大小满的情况判断有两种：\n所有流队列缓冲大小总和大于MAX_QUEUE_SIZE（15M）时； 各种流的队列都已有够用的包； /* if the queue are full, no need to read more */ //数据队列满的情况 if (infinite_buffer \u0026lt; 1 \u0026amp;\u0026amp; (is-\u0026gt;audioq.size + is-\u0026gt;videoq.size + is-\u0026gt;subtitleq.size \u0026gt; MAX_QUEUE_SIZE //所有流队列缓冲大小总和大于MAX_QUEUE_SIZE（15M）时 || (stream_has_enough_packets(is-\u0026gt;audio_st, is-\u0026gt;audio_stream, \u0026amp;is-\u0026gt;audioq) //各种流都已有够用的包 \u0026amp;\u0026amp;stream_has_enough_packets(is-\u0026gt;video_st, is-\u0026gt;video_stream, \u0026amp;is-\u0026gt;videoq) \u0026amp;\u0026amp;stream_has_enough_packets(is-\u0026gt;subtitle_st, is-\u0026gt;subtitle_stream, \u0026amp;is-\u0026gt;subtitleq)))) { /* wait 10 ms */ SDL_LockMutex(wait_mutex); SDL_CondWaitTimeout(is-\u0026gt;continue_read_thread, wait_mutex, 10); SDL_UnlockMutex(wait_mutex); continue; } 在看看函数stream_has_enough_packets是如何判断流队列都已有够用的包\nstatic int stream_has_enough_packets(AVStream *st, int stream_id, PacketQueue *queue) { return stream_id \u0026lt; 0 || queue-\u0026gt;abort_request || (st-\u0026gt;disposition \u0026amp; AV_DISPOSITION_ATTACHED_PIC) || queue-\u0026gt;nb_packets \u0026gt; MIN_FRAMES \u0026amp;\u0026amp; (!queue-\u0026gt;duration || av_q2d(st-\u0026gt;time_base) * queue-\u0026gt;duration \u0026gt; 1.0); } 从函数内部结构可以看出，在满足PacketQueue总时长为0，或总时长超过1s的前提下：\n有这么几种情况包是够用的：\n流没有打开（stream_id \u0026lt; 0） 有退出请求（queue-\u0026gt;abort_request） 配置了AV_DISPOSITION_ATTACHED_PIC，流以附件图片/“封面图片”的形式存储在文件； 队列内包个数大于MIN_FRAMES（=25） 在播放完的情况下处理： if (!is-\u0026gt;paused \u0026amp;\u0026amp; (!is-\u0026gt;audio_st || (is-\u0026gt;auddec.finished == is-\u0026gt;audioq.serial \u0026amp;\u0026amp; frame_queue_nb_remaining(\u0026amp;is-\u0026gt;sampq) == 0)) \u0026amp;\u0026amp;(!is-\u0026gt;video_st || (is-\u0026gt;viddec.finished == is-\u0026gt;videoq.serial \u0026amp;\u0026amp; frame_queue_nb_remaining(\u0026amp;is-\u0026gt;pictq) == 0))) { if (loop != 1 \u0026amp;\u0026amp; (!loop || --loop)) { stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0); } else if (autoexit) { ret = AVERROR_EOF; goto fail; } } 判断播放已完成的条件，需要满足：\n不在暂停状态 音频未打开，或者打开了，但是解码已解码完毕，serial等于PacketQueue的serial，并且PacketQueue中没有节点了 视频未打开，或者打开了，但是解码已解码完毕，serial等于PacketQueue的serial，并且PacketQueue中没有节点了 在确认已结束的情况下，用户有两个变量可以控制播放器行为：\nloop: 控制播放次数（当前这次也算在内，也就是最小就是1次了），0表示无限次 autoexit：自动退出，也就是播放完成后自动退出。 读（解复用）处理： 解复用处理的步骤如下：\n通过av_read_frame读取一个包（AVPacket） 返回值处理，一些出错处理过程 pkt_ts重计算过程 packet_queue_put放入各自队列，或者丢弃 ret = av_read_frame(ic, pkt); //将数据读取出，送入队列 if (ret \u0026lt; 0) { //文件读取完了，调用packet_queue_put_nullpacket通知解码线程 if ((ret == AVERROR_EOF || avio_feof(ic-\u0026gt;pb)) \u0026amp;\u0026amp; !is-\u0026gt;eof) { if (is-\u0026gt;video_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;videoq, is-\u0026gt;video_stream); if (is-\u0026gt;audio_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;audioq, is-\u0026gt;audio_stream); if (is-\u0026gt;subtitle_stream \u0026gt;= 0) packet_queue_put_nullpacket(\u0026amp;is-\u0026gt;subtitleq, is-\u0026gt;subtitle_stream); is-\u0026gt;eof = 1; } //发生错误了，退出主循环 if (ic-\u0026gt;pb \u0026amp;\u0026amp; ic-\u0026gt;pb-\u0026gt;error) { if (autoexit) goto fail; else break; } /*读取失败的话，读取失败的原因有很多，其他地方可能会重新Signal这个锁condition。 如果没有singal这个condition的话，就会等待10ms之后， 再释放，重新循环读取. 那这个continue_read_thread 到底是锁了哪呢？*/ SDL_LockMutex(wait_mutex); SDL_CondWaitTimeout(is-\u0026gt;continue_read_thread, wait_mutex, 10); SDL_UnlockMutex(wait_mutex); continue; } else { is-\u0026gt;eof = 0; } /* check if packet is in play range specified by user, then queue, otherwise discard */ //记录stream_start_time stream_start_time = ic-\u0026gt;streams[pkt-\u0026gt;stream_index]-\u0026gt;start_time; //如果没有pts, 就用dts pkt_ts = pkt-\u0026gt;pts == AV_NOPTS_VALUE ? pkt-\u0026gt;dts : pkt-\u0026gt;pts; /*判断是否在范围内。如果duration还没被定义的话，通过 或者在定义的duration内才可以，用当前的pts-start_time . duration 会在解码器打开之后，才会被初始化*/ pkt_in_play_range = duration == AV_NOPTS_VALUE || (pkt_ts - (stream_start_time != AV_NOPTS_VALUE ? stream_start_time : 0)) * av_q2d(ic-\u0026gt;streams[pkt-\u0026gt;stream_index]-\u0026gt;time_base) - (double)(start_time != AV_NOPTS_VALUE ? start_time : 0) / 1000000 \u0026lt;= ((double)duration / 1000000); // 将解复用得到的数据包添加到对应的待解码队列中 if (pkt-\u0026gt;stream_index == is-\u0026gt;audio_stream \u0026amp;\u0026amp; pkt_in_play_range) { packet_queue_put(\u0026amp;is-\u0026gt;audioq, pkt); } else if (pkt-\u0026gt;stream_index == is-\u0026gt;video_stream \u0026amp;\u0026amp; pkt_in_play_range \u0026amp;\u0026amp; !(is-\u0026gt;video_st-\u0026gt;disposition \u0026amp; AV_DISPOSITION_ATTACHED_PIC)) { packet_queue_put(\u0026amp;is-\u0026gt;videoq, pkt); } else if (pkt-\u0026gt;stream_index == is-\u0026gt;subtitle_stream \u0026amp;\u0026amp; pkt_in_play_range) { packet_queue_put(\u0026amp;is-\u0026gt;subtitleq, pkt); } else { av_packet_unref(pkt); } 视频解码线程(video_thread) 在read_thread中已经创建了对应需要的解码器(AVCodec)；而在video_thread中需要创建AVFrame,来接收解码后的数据；确定视频帧率，开启循环解码；\n参数初始化 创建AVFrame和得到大致的视频帧率\nVideoState *is = arg; AVFrame *frame = av_frame_alloc(); //创建AVFrame double pts; double duration; int ret; AVRational tb = is-\u0026gt;video_st-\u0026gt;time_base; //猜测视频帧率 AVRational frame_rate = av_guess_frame_rate(is-\u0026gt;ic, is-\u0026gt;video_st, NULL); if (!frame) return AVERROR(ENOMEM); 循环解码 循环解码的总流：\nget_video_frame获取解码后的一帧图像 “计算”时长和pts 调用queue_picture将一帧图像放入FrameQueue for (;;) { ret = get_video_frame(is, frame); if (ret \u0026lt; 0) goto the_end; if (!ret) continue; //获取当前帧播放时长 duration = (frame_rate.num \u0026amp;\u0026amp; frame_rate.den ? av_q2d((AVRational){frame_rate.den, frame_rate.num}) : 0); //当前帧显示时间戳 pts = (frame-\u0026gt;pts == AV_NOPTS_VALUE) ? NAN : frame-\u0026gt;pts * av_q2d(tb); // 将当前帧压入frame_queue ret = queue_picture(is, frame, pts, duration, frame-\u0026gt;pkt_pos, is-\u0026gt;viddec.pkt_serial); av_frame_unref(frame); //释放frame if (ret \u0026lt; 0) goto the_end; } get_video_frame ​\t调用decoder_decode_frame解码,获取成功后主要做丢帧处理，丢帧的主要条件是diff - is-\u0026gt;frame_last_filter_delay \u0026lt; 0，frame_last_filter_delay与滤镜有关，可以先忽略，也就是diff \u0026lt; 0的时候丢帧——pts \u0026lt; get_master_clock(is)的时候丢帧。decoder_decode_frame真正解码函数；\nstatic int get_video_frame(VideoState *is, AVFrame *frame) { int got_picture; if ((got_picture = decoder_decode_frame(\u0026amp;is-\u0026gt;viddec, frame, NULL)) \u0026lt; 0) return -1; if (got_picture)//解码是否成功，主要做丢帧处理 { double dpts = NAN; if (frame-\u0026gt;pts != AV_NOPTS_VALUE)//通过 pts*av_q2d(timebase)可以得到准确的时间 dpts = av_q2d(is-\u0026gt;video_st-\u0026gt;time_base) * frame-\u0026gt;pts; //重新得到视频的比例 frame-\u0026gt;sample_aspect_ratio = av_guess_sample_aspect_ratio(is-\u0026gt;ic, is-\u0026gt;video_st, frame); if (framedrop \u0026gt; 0 || (framedrop \u0026amp;\u0026amp; get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) { if (frame-\u0026gt;pts != AV_NOPTS_VALUE) { //得到的是当前的时间和时间钟之间的差值。 double diff = dpts - get_master_clock(is); if (!isnan(diff) \u0026amp;\u0026amp; fabs(diff) \u0026lt; AV_NOSYNC_THRESHOLD \u0026amp;\u0026amp; diff - is-\u0026gt;frame_last_filter_delay \u0026lt; 0 \u0026amp;\u0026amp; is-\u0026gt;viddec.pkt_serial == is-\u0026gt;vidclk.serial \u0026amp;\u0026amp; is-\u0026gt;videoq.nb_packets) { is-\u0026gt;frame_drops_early++; av_frame_unref(frame); got_picture = 0; } } } } return got_picture; } decoder_decode_frame decoder_decode_frame的主干代码是一个循环，要拿到一帧解码数据，或解码出错、文件结束，才会返回。\n循环总共3个步骤：\n流连续的情况下，不断调用avcodec_receive_frame获取解码后的frame 取一个packet，顺带过滤“过时”的packet 将packet送入解码器 有一个packet_pending的概念，用于在send失败时重新发送；当收到flush_pkt时进行相应的flush事件处理，PacketQueue发生改变时第一个pkt将是flush_pkt，根据ffmpeg的API要求，需要调用avcodec_flush_buffers。\nstatic int decoder_decode_frame(Decoder *d, AVFrame *frame, AVSubtitle *sub) { int ret = AVERROR(EAGAIN); for (;;) { AVPacket pkt; //1. 流连续的情况下，不断调用avcodec_receive_frame获取解码后的frame if (d-\u0026gt;queue-\u0026gt;serial == d-\u0026gt;pkt_serial) { do { if (d-\u0026gt;queue-\u0026gt;abort_request) return -1; switch (d-\u0026gt;avctx-\u0026gt;codec_type) { case AVMEDIA_TYPE_VIDEO: ret = avcodec_receive_frame(d-\u0026gt;avctx, frame); if (ret \u0026gt;= 0) { if (decoder_reorder_pts == -1) { frame-\u0026gt;pts = frame-\u0026gt;best_effort_timestamp; } else if (!decoder_reorder_pts) { frame-\u0026gt;pts = frame-\u0026gt;pkt_dts; } } break; if (ret == AVERROR_EOF) { d-\u0026gt;finished = d-\u0026gt;pkt_serial; avcodec_flush_buffers(d-\u0026gt;avctx); return 0; } if (ret \u0026gt;= 0) return 1; } while (ret != AVERROR(EAGAIN)); } //2. 取一个packet，顺带过滤“过时”的packet do { // 队列为空 if (d-\u0026gt;queue-\u0026gt;nb_packets == 0) SDL_CondSignal(d-\u0026gt;empty_queue_cond); //如果有待重发的pkt，则先取待重发的pkt，否则从队列中取一个pkt if (d-\u0026gt;packet_pending) { av_packet_move_ref(\u0026amp;pkt, \u0026amp;d-\u0026gt;pkt); d-\u0026gt;packet_pending = 0; } else { //取出下一帧 if (packet_queue_get(d-\u0026gt;queue, \u0026amp;pkt, 1, \u0026amp;d-\u0026gt;pkt_serial) \u0026lt; 0) return -1; } //队列的序列不相同时 if (d-\u0026gt;queue-\u0026gt;serial == d-\u0026gt;pkt_serial) break; av_packet_unref(\u0026amp;pkt); } while (1); //针对flush_pkt的处理 if (pkt.data == flush_pkt.data) { avcodec_flush_buffers(d-\u0026gt;avctx); d-\u0026gt;finished = 0; d-\u0026gt;next_pts = d-\u0026gt;start_pts; d-\u0026gt;next_pts_tb = d-\u0026gt;start_pts_tb; } else { //3. 将packet送入解码器 if (avcodec_send_packet(d-\u0026gt;avctx, \u0026amp;pkt) == AVERROR(EAGAIN)) { av_log(d-\u0026gt;avctx, AV_LOG_ERROR, \u0026#34;Receive_frame and send_packet both returned EAGAIN, which is an API violation.\\n\u0026#34;); d-\u0026gt;packet_pending = 1; av_packet_move_ref(\u0026amp;d-\u0026gt;pkt, \u0026amp;pkt); } av_packet_unref(\u0026amp;pkt); } } } queue_picture queue_picture主要用于把get_video_frame函数取到正确解码后的一帧数据放入FrameQueue；\nframe_queue_peek_writable取FrameQueue的当前写节点； 把该解码后的帧数据拷贝给节点(struct Frame)保存 frame_queue_push，“push”节点到队列中 AVFrame的拷贝是通过av_frame_move_ref实现的，所以拷贝后src_frame就是无效的；\nstatic int queue_picture(VideoState *is, AVFrame *src_frame, double pts, double duration, int64_t pos, int serial) { Frame *vp; #if defined(DEBUG_SYNC) printf(\u0026#34;frame_type=%c pts=%0.3f\\n\u0026#34;, av_get_picture_type_char(src_frame-\u0026gt;pict_type), pts); #endif if (!(vp = frame_queue_peek_writable(\u0026amp;is-\u0026gt;pictq))) //判断是否有空间可以写入，并取FrameQueue的当前写节点 return -1; vp-\u0026gt;sar = src_frame-\u0026gt;sample_aspect_ratio; vp-\u0026gt;uploaded = 0; vp-\u0026gt;width = src_frame-\u0026gt;width; vp-\u0026gt;height = src_frame-\u0026gt;height; vp-\u0026gt;format = src_frame-\u0026gt;format; vp-\u0026gt;pts = pts; vp-\u0026gt;duration = duration; vp-\u0026gt;pos = pos; vp-\u0026gt;serial = serial; //修改窗口大小 set_default_window_size(vp-\u0026gt;width, vp-\u0026gt;height, vp-\u0026gt;sar); av_frame_move_ref(vp-\u0026gt;frame, src_frame); //将src_frame的内存空间指向vp-\u0026gt;frame frame_queue_push(\u0026amp;is-\u0026gt;pictq); //重新推入 return 0; } ffplay audio输出的线程分析 ffplay audio的解码过程与video的一样，都在decoder_decode_frame函数中执行，在 video已经进行分析，这里就不做单独分析了，主要分析audio的输出；ffplay的audio输出同样也是通过SDL实现的;audio输出相关内容，且尽量不涉及音视频同步知识，音视频同步将专门一个章节分析。\naudio的输出在SDL下是被动输出，即在开启SDL会在需要输出时，回调通知，在回调函数中，SDL会告知要发送多少的数据。\nsdl通过sdl_audio_callback函数向ffplay要音频数据，ffplay将sampq中的数据通过audio_decode_frame函数取出，放入is-\u0026gt;audio_buf，然后送出给sdl。在后续回调时先找audio_buf要数据，数据不足的情况下，再调用audio_decode_frame补充audio_buf\nsdl打开音频输出 在stream_component_open中的audio分支进行调用audio_open打开sdl音频输出；代码如下：\ncase AVMEDIA_TYPE_AUDIO: //音频相关 #if CONFIG_AVFILTER //过滤器 { AVFilterContext *sink; //从avctx(即AVCodecContext)中获取音频格式参数 is-\u0026gt;audio_filter_src.freq = avctx-\u0026gt;sample_rate; is-\u0026gt;audio_filter_src.channels = avctx-\u0026gt;channels; is-\u0026gt;audio_filter_src.channel_layout = get_valid_channel_layout(avctx-\u0026gt;channel_layout, avctx-\u0026gt;channels); is-\u0026gt;audio_filter_src.fmt = avctx-\u0026gt;sample_fmt; if ((ret = configure_audio_filters(is, afilters, 0)) \u0026lt; 0) goto fail; sink = is-\u0026gt;out_audio_filter; sample_rate = av_buffersink_get_sample_rate(sink); nb_channels = av_buffersink_get_channels(sink); channel_layout = av_buffersink_get_channel_layout(sink); } #else sample_rate = avctx-\u0026gt;sample_rate; nb_channels = avctx-\u0026gt;channels; channel_layout = avctx-\u0026gt;channel_layout; #endif /* prepare audio output */ //打开音频输出通道 /*调用audio_open打开sdl音频输出，实际打开的设备参数保存在audio_tgt，返回值表示输出设备的缓冲区大小*/ if ((ret = audio_open(is, channel_layout, nb_channels, sample_rate, \u0026amp;is-\u0026gt;audio_tgt)) \u0026lt; 0) goto fail; is-\u0026gt;audio_hw_buf_size = ret; is-\u0026gt;audio_src = is-\u0026gt;audio_tgt; //初始化audio_buf相关参数 is-\u0026gt;audio_buf_size = 0; is-\u0026gt;audio_buf_index = 0; /* init averaging filter */ is-\u0026gt;audio_diff_avg_coef = exp(log(0.01) / AUDIO_DIFF_AVG_NB); is-\u0026gt;audio_diff_avg_count = 0; /* since we do not have a precise anough audio FIFO fullness, we correct audio sync only if larger than this threshold */ is-\u0026gt;audio_diff_threshold = (double)(is-\u0026gt;audio_hw_buf_size) / is-\u0026gt;audio_tgt.bytes_per_sec; is-\u0026gt;audio_stream = stream_index; is-\u0026gt;audio_st = ic-\u0026gt;streams[stream_index]; decoder_init(\u0026amp;is-\u0026gt;auddec, avctx, \u0026amp;is-\u0026gt;audioq, is-\u0026gt;continue_read_thread); //初始化对应的解码线程 if ((is-\u0026gt;ic-\u0026gt;iformat-\u0026gt;flags \u0026amp; (AVFMT_NOBINSEARCH | AVFMT_NOGENSEARCH | AVFMT_NO_BYTE_SEEK)) \u0026amp;\u0026amp; !is-\u0026gt;ic-\u0026gt;iformat-\u0026gt;read_seek) { is-\u0026gt;auddec.start_pts = is-\u0026gt;audio_st-\u0026gt;start_time; is-\u0026gt;auddec.start_pts_tb = is-\u0026gt;audio_st-\u0026gt;time_base; } if ((ret = decoder_start(\u0026amp;is-\u0026gt;auddec, audio_thread, \u0026#34;audio_decoder\u0026#34;, is)) \u0026lt; 0) // 正式开启解码线程。 goto out; SDL_PauseAudioDevice(audio_dev, 0); break; 由于不同的音频输出设备支持的参数不同，音轨的参数不一定能被输出设备支持（此时就需要重采样了），audio_tgt就保存了输出设备参数。\n介绍下audio_buf相关的几个变量：\naudio_buf: 从要输出的AVFrame中取出的音频数据（PCM），如果有必要，则对该数据重采样。 audio_buf_size: audio_buf的总大小 audio_buf_index: 下一次可读的audio_buf的index位置。 audio_write_buf_size：audio_buf已经输出的大小，即audio_buf_size - audio_buf_index 音频输出逻辑 在audio_open函数内，通过通过SDL_OpenAudioDevice注册sdl_audio_callback函数为音频输出的回调函数。那么，主要的音频输出的逻辑就在sdl_audio_callback函数内了。\n/* prepare a new audio buffer */ static void sdl_audio_callback(void *opaque, Uint8 *stream, int len) { VideoState *is = opaque; int audio_size, len1; audio_callback_time = av_gettime_relative(); while (len \u0026gt; 0)//循环发送，直到发够所需数据长度 { //如果audio_buf消耗完了，就调用audio_decode_frame重新填充audio_buf if (is-\u0026gt;audio_buf_index \u0026gt;= is-\u0026gt;audio_buf_size) { audio_size = audio_decode_frame(is);//填充audio_buf if (audio_size \u0026lt; 0) { /* if error, just output silence */ is-\u0026gt;audio_buf = NULL; is-\u0026gt;audio_buf_size = SDL_AUDIO_MIN_BUFFER_SIZE / is-\u0026gt;audio_tgt.frame_size * is-\u0026gt;audio_tgt.frame_size; } else { if (is-\u0026gt;show_mode != SHOW_MODE_VIDEO) update_sample_display(is, (int16_t *)is-\u0026gt;audio_buf, audio_size); is-\u0026gt;audio_buf_size = audio_size; } is-\u0026gt;audio_buf_index = 0; } //根据缓冲区剩余大小量力而行 len1 = is-\u0026gt;audio_buf_size - is-\u0026gt;audio_buf_index; if (len1 \u0026gt; len) len1 = len; //根据audio_volume决定如何输出audio_buf if (!is-\u0026gt;muted \u0026amp;\u0026amp; is-\u0026gt;audio_buf \u0026amp;\u0026amp; is-\u0026gt;audio_volume == SDL_MIX_MAXVOLUME) memcpy(stream, (uint8_t *)is-\u0026gt;audio_buf + is-\u0026gt;audio_buf_index, len1); else { memset(stream, 0, len1); if (!is-\u0026gt;muted \u0026amp;\u0026amp; is-\u0026gt;audio_buf) SDL_MixAudioFormat(stream, (uint8_t *)is-\u0026gt;audio_buf + is-\u0026gt;audio_buf_index, AUDIO_S16SYS, len1, is-\u0026gt;audio_volume); } //调整各buffer len -= len1; stream += len1; is-\u0026gt;audio_buf_index += len1; } is-\u0026gt;audio_write_buf_size = is-\u0026gt;audio_buf_size - is-\u0026gt;audio_buf_index; /* Let\u0026#39;s assume the audio driver that is used by SDL has two periods. */ if (!isnan(is-\u0026gt;audio_clock))//更新audclk { set_clock_at(\u0026amp;is-\u0026gt;audclk, is-\u0026gt;audio_clock - (double)(2 * is-\u0026gt;audio_hw_buf_size + is-\u0026gt;audio_write_buf_size) / is-\u0026gt;audio_tgt.bytes_per_sec, is-\u0026gt;audio_clock_serial, audio_callback_time / 1000000.0); sync_clock_to_slave(\u0026amp;is-\u0026gt;extclk, \u0026amp;is-\u0026gt;audclk); } } sdl_audio_callback的缓冲区输出过程:\n输出audio_buf到stream，如果audio_volume为最大音量，则只需memcpy复制给stream即可。否则，可以利用SDL_MixAudioFormat进行音量调整和混音 如果audio_buf消耗完了，就调用audio_decode_frame重新填充audio_buf set_clock_at更新audclk时，完整的帧包含的时间戳-实际写入的帧数+2个硬件buffer的延迟，audio_clock是当前audio_buf的显示结束时间(pts+duration)，由于audio driver本身会持有一小块缓冲区，典型地，会是两块交替使用，所以有2 * is-\u0026gt;audio_hw_buf_size. 因为我们的写入的时候，还需要考虑传入的buffer的大小，预期情况下，如果buffer相同，则这里就是原来的pts-硬件延迟的时间。 填充audio_buf 调用audio_decode_frame重新填充audio_buf，audio_decode_frame并没有真正意义上的decode代码，最多是进行了重采样。主流程有以下步骤：\n从sampq取一帧，必要时丢帧。如发生了seek，此时serial会不连续，就需要丢帧处理 计算这一帧的字节数。通过av_samples_get_buffer_size可以方便计算出结果 获取这一帧的数据。对于frame格式和输出设备不同的，需要重采样；如果格式相同，则直接拷贝指针输出即可。总之，需要在audio_buf中保存与输出设备格式相同的音频数据 更新audio_clock，audio_clock_serial。用于设置audclk. /** * Decode one audio frame and return its uncompressed size. * * The processed audio frame is decoded, converted if required, and * stored in is-\u0026gt;audio_buf, with size in bytes given by the return * value. */ static int audio_decode_frame(VideoState *is) { int data_size, resampled_data_size; int64_t dec_channel_layout; av_unused double audio_clock0; int wanted_nb_samples; Frame *af; if (is-\u0026gt;paused)//暂停状态，返回-1，sdl_audio_callback会处理为输出静音 return -1; do { #if defined(_WIN32) while (frame_queue_nb_remaining(\u0026amp;is-\u0026gt;sampq) == 0) { if ((av_gettime_relative() - audio_callback_time) \u0026gt; 1000000LL * is-\u0026gt;audio_hw_buf_size / is-\u0026gt;audio_tgt.bytes_per_sec / 2) return -1; av_usleep(1000); } #endif if (!(af = frame_queue_peek_readable(\u0026amp;is-\u0026gt;sampq)))//1. 从sampq取一帧，必要时丢帧 return -1; frame_queue_next(\u0026amp;is-\u0026gt;sampq); } while (af-\u0026gt;serial != is-\u0026gt;audioq.serial); //2. 计算这一帧的字节数 data_size = av_samples_get_buffer_size(NULL, af-\u0026gt;frame-\u0026gt;channels, af-\u0026gt;frame-\u0026gt;nb_samples, af-\u0026gt;frame-\u0026gt;format, 1); //[]计算dec_channel_layout，用于确认是否需要重新初始化重采样 dec_channel_layout = (af-\u0026gt;frame-\u0026gt;channel_layout \u0026amp;\u0026amp; af-\u0026gt;frame-\u0026gt;channels == av_get_channel_layout_nb_channels(af-\u0026gt;frame-\u0026gt;channel_layout)) ? af-\u0026gt;frame-\u0026gt;channel_layout : av_get_default_channel_layout(af-\u0026gt;frame-\u0026gt;channels); wanted_nb_samples = synchronize_audio(is, af-\u0026gt;frame-\u0026gt;nb_samples); //[]判断是否需要重新初始化重采样 if (af-\u0026gt;frame-\u0026gt;format != is-\u0026gt;audio_src.fmt || dec_channel_layout != is-\u0026gt;audio_src.channel_layout || af-\u0026gt;frame-\u0026gt;sample_rate != is-\u0026gt;audio_src.freq || (wanted_nb_samples != af-\u0026gt;frame-\u0026gt;nb_samples \u0026amp;\u0026amp; !is-\u0026gt;swr_ctx)) { swr_free(\u0026amp;is-\u0026gt;swr_ctx); //创建和设置swr is-\u0026gt;swr_ctx = swr_alloc_set_opts(NULL, is-\u0026gt;audio_tgt.channel_layout, is-\u0026gt;audio_tgt.fmt, is-\u0026gt;audio_tgt.freq, dec_channel_layout, af-\u0026gt;frame-\u0026gt;format, af-\u0026gt;frame-\u0026gt;sample_rate, 0, NULL); if (!is-\u0026gt;swr_ctx || swr_init(is-\u0026gt;swr_ctx) \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot create sample rate converter for conversion of %d Hz %s %d channels to %d Hz %s %d channels!\\n\u0026#34;, af-\u0026gt;frame-\u0026gt;sample_rate, av_get_sample_fmt_name(af-\u0026gt;frame-\u0026gt;format), af-\u0026gt;frame-\u0026gt;channels, is-\u0026gt;audio_tgt.freq, av_get_sample_fmt_name(is-\u0026gt;audio_tgt.fmt), is-\u0026gt;audio_tgt.channels); swr_free(\u0026amp;is-\u0026gt;swr_ctx); return -1; } is-\u0026gt;audio_src.channel_layout = dec_channel_layout; is-\u0026gt;audio_src.channels = af-\u0026gt;frame-\u0026gt;channels; is-\u0026gt;audio_src.freq = af-\u0026gt;frame-\u0026gt;sample_rate; is-\u0026gt;audio_src.fmt = af-\u0026gt;frame-\u0026gt;format; } //3. 获取这一帧的数据 if (is-\u0026gt;swr_ctx)//[]如果初始化了重采样，则对这一帧数据重采样输出 { const uint8_t **in = (const uint8_t **)af-\u0026gt;frame-\u0026gt;extended_data; uint8_t **out = \u0026amp;is-\u0026gt;audio_buf1; int out_count = (int64_t)wanted_nb_samples * is-\u0026gt;audio_tgt.freq / af-\u0026gt;frame-\u0026gt;sample_rate + 256; int out_size = av_samples_get_buffer_size(NULL, is-\u0026gt;audio_tgt.channels, out_count, is-\u0026gt;audio_tgt.fmt, 0); int len2; if (out_size \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;av_samples_get_buffer_size() failed\\n\u0026#34;); return -1; } if (wanted_nb_samples != af-\u0026gt;frame-\u0026gt;nb_samples) { if (swr_set_compensation(is-\u0026gt;swr_ctx, (wanted_nb_samples - af-\u0026gt;frame-\u0026gt;nb_samples) * is-\u0026gt;audio_tgt.freq / af-\u0026gt;frame-\u0026gt;sample_rate, wanted_nb_samples * is-\u0026gt;audio_tgt.freq / af-\u0026gt;frame-\u0026gt;sample_rate) \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;swr_set_compensation() failed\\n\u0026#34;); return -1; } } av_fast_malloc(\u0026amp;is-\u0026gt;audio_buf1, \u0026amp;is-\u0026gt;audio_buf1_size, out_size); if (!is-\u0026gt;audio_buf1) return AVERROR(ENOMEM); //进行转换 len2 = swr_convert(is-\u0026gt;swr_ctx, out, out_count, in, af-\u0026gt;frame-\u0026gt;nb_samples); if (len2 \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;swr_convert() failed\\n\u0026#34;); return -1; } if (len2 == out_count) { av_log(NULL, AV_LOG_WARNING, \u0026#34;audio buffer is probably too small\\n\u0026#34;); if (swr_init(is-\u0026gt;swr_ctx) \u0026lt; 0) swr_free(\u0026amp;is-\u0026gt;swr_ctx); } is-\u0026gt;audio_buf = is-\u0026gt;audio_buf1; //重新计算采样的数据大小，并返回 resampled_data_size = len2 * is-\u0026gt;audio_tgt.channels * av_get_bytes_per_sample(is-\u0026gt;audio_tgt.fmt); } else { is-\u0026gt;audio_buf = af-\u0026gt;frame-\u0026gt;data[0]; resampled_data_size = data_size; } //audio_clock0用于打印调试信息 audio_clock0 = is-\u0026gt;audio_clock; /* update the audio clock with the pts */ //4. 更新audio_clock，audio_clock_serial,更新pts 这个pts 等于当前的帧包含的所有帧数 if (!isnan(af-\u0026gt;pts)) is-\u0026gt;audio_clock = af-\u0026gt;pts + (double)af-\u0026gt;frame-\u0026gt;nb_samples / af-\u0026gt;frame-\u0026gt;sample_rate; else is-\u0026gt;audio_clock = NAN; is-\u0026gt;audio_clock_serial = af-\u0026gt;serial; #ifdef DEBUG { static double last_clock; printf(\u0026#34;audio: delay=%0.3f clock=%0.3f clock0=%0.3f\\n\u0026#34;, is-\u0026gt;audio_clock - last_clock, is-\u0026gt;audio_clock, audio_clock0); last_clock = is-\u0026gt;audio_clock; } #endif return resampled_data_size;//返回audio_buf的数据大小 } ffplay时间同步 由于音频和视频的输出不在同一个线程，而且，也不一定会同时解出同一个pts的音频帧和视频帧。因此，在进行音频和视频的播放时，需要对音频和视频的播放速度、播放时刻进行控制，以实现音频和视频保持同步，即所谓的音视频同步。\n在ffplay中，音频（audio）和视频（video）有各自的输出线程，其中音频的输出线程是sdl的音频输出回调线程，video的输出线程是程序的主线程。\n音视频的同步策略，一般有如下几种：\n视频同步到音频，即音频为主时钟 音频同步到视频，即视频为主时钟 视频、音频同步到外部时钟，即外部时钟（系统时间）为主时钟 视频和音频各自输出，即不作同步处理，或称之为各自为主时钟 由于人耳对于声音变化的敏感度比视觉高，因此，一般采样的策略是将视频同步到音频，即对画面进行适当的丢帧或重复以追赶或等待音频。\nDTS和PTS 在音视频流中的包都含有DTS和PTS，我们以此作为选择基准，到底是播放快了还是慢了，或者正以同步的速度播放。\nDTS：Decoding Time Stamp 解码时间戳——告诉解码器packet解码顺序 PTS：Presenting Time Stamp 显示时间戳——指示从packet中解码出来的数据的显示顺序 计算视频Frame的显示时间 要想知道ffmpeg如果计算视频一帧的显示时间，就需先了解ffmpeg的timebase；因为pts的单位就是timebase；\ntimebase的类型是结构体AVRational（用于表示分数），如下：\ntypedef struct AVRational{ int num; ///\u0026lt; Numerator int den; ///\u0026lt; Denominator } AVRational; 如timebase={1, 1000}表示千分之一秒，那么pts=1000，即为1秒，那么这一帧就需要在第一秒的时候呈现在ffplay中，将pts转化为秒，一般做法是：pts * av_q2d(timebase)\n\u0026ldquo;时钟\u0026quot;的概念，ffplay定义的结构体是Clock：\ntypedef struct Clock { double pts; /* clock base */// 时钟基准 double pts_drift; /* clock base minus time at which we updated the clock */// 更新时钟的差值 double last_updated;// 上一次更新的时间 double speed;// 速度 int serial; // 时钟基于使用该序列的包 /* clock is based on a packet with this serial */ int paused;// 停止标志 int *queue_serial; // 指向当前数据包队列序列的指针，用于过时的时钟检测 /* pointer to the current packet queue serial, used for obsolete clock detection */ } Clock; 时钟的工作原理：\n通过set_clock_at不断对时； 获取的时间是一个估算值。估算是通过对时时记录的pts_drift估算的 /** * 更新视频的pts * @param is [description] * @param pts [description] * @param pos [description] * @param serial [description] */ static void update_video_pts(VideoState *is, double pts, int64_t pos, int serial) { /* update current video pts */ set_clock(\u0026amp;is-\u0026gt;vidclk, pts, serial); //将尾部的时间钟，用视频的时机钟来进行同步 sync_clock_to_slave(\u0026amp;is-\u0026gt;extclk, \u0026amp;is-\u0026gt;vidclk); } static void set_clock(Clock *c, double pts, int serial) { double time = av_gettime_relative() / 1000000.0; set_clock_at(c, pts, serial, time); } //使用当前的事来计算这几个值。也就是这一帧送显之前的操作的时间。 static void set_clock_at(Clock *c, double pts, int serial, double time) { c-\u0026gt;pts = pts; c-\u0026gt;last_updated = time; c-\u0026gt;pts_drift = c-\u0026gt;pts - time; c-\u0026gt;serial = serial; } 以一个时间轴，从左往右看。首先我们调用set_clock_at进行一次对时，假设这时的pts是落后系统时间time的，那么计算pts_drift = pts - time。\n接着，过了一会儿，且在下次对时前，通过get_clock来查询时间，因为这时的pts已经过时，不能直接拿pts当做这个时钟的时间。不过我们前面计算过pts_drift，也就是pts和time的差值，所以我们可以通过当前时刻的系统时间来估算这个时刻的pts：pts = time + pts_drift.\n当然，由于pts_drift是一直在变动的(drift与漂移、抖动的意思)，所以get_clock是估算值，真实的pts可能落在比如图示虚线圆的位置。\nstatic double get_clock(Clock *c) { if (*c-\u0026gt;queue_serial != c-\u0026gt;serial) return NAN; if (c-\u0026gt;paused) { return c-\u0026gt;pts; } else { //pts_drift 是更新的时间钟的差值？ //最后的时间是 更新的差值+ 当前的时间-当前的时间和上一次更新的时间之间的差值*速度 //默认的情况下，根据上一次的drift计算下一次要出现的时间。 double time = av_gettime_relative() / 1000000.0; return c-\u0026gt;pts_drift + time - (time - c-\u0026gt;last_updated) * (1.0 - c-\u0026gt;speed); } } 以音频为主时钟同步 接下来主要讲以音频为主时钟的部分，大致流程如下：\n在这个流程中，“计算上一帧显示时长”这一步骤至关重要。代码如下：\n/* called to display each frame */ static void video_refresh(void *opaque, double *remaining_time) { if (is-\u0026gt;video_st) { retry: if (frame_queue_nb_remaining(\u0026amp;is-\u0026gt;pictq) == 0) { //判断队列是否有数据 // nothing to do, no picture to display in the queue } else { double last_duration, duration, delay; Frame *vp, *lastvp; //lastvp上一帧，vp当前帧 ，nextvp下一帧 /* dequeue the picture */ //出队 lastvp = frame_queue_peek_last(\u0026amp;is-\u0026gt;pictq); vp = frame_queue_peek(\u0026amp;is-\u0026gt;pictq); /* 1、刚开始的时候（第一帧）lastvp == vp ，因为还没有调用frame_queue_next f-\u0026gt;rindex_shown还未为1 2、调用frame_queue_next，将f-\u0026gt;rindex_shown置1，还没有增加f-\u0026gt;rindex 3、第二帧开始lastvp上一帧，vp 将要显示的一帧 */ /*如果将要显示的一帧的序列与现在解码的不同就直接抛弃*/ if (vp-\u0026gt;serial != is-\u0026gt;videoq.serial) { frame_queue_next(\u0026amp;is-\u0026gt;pictq);//移动读索引 goto retry;//重新获取 } //如果上一帧序号不等于将要显示的一帧序号，表示将要显示的一帧是新的播放序列 /* 新的播放序列重置当前时间，这样就会走到正常显示将要显示的一帧（新序的第一帧） */ if (lastvp-\u0026gt;serial != vp-\u0026gt;serial) is-\u0026gt;frame_timer = av_gettime_relative() / 1000000.0; //获取当前时间，用于帧间对比 if (is-\u0026gt;paused) //暂停后重新开 goto display; /* compute nominal last_duration */ last_duration = vp_duration(is, lastvp, vp);//计算上一帧的持续时长 delay = compute_target_delay(last_duration, is); //音视频同步信息，参考audio clock计算上一帧真正的持续时 time = av_gettime_relative() / 1000000.0;//取系统时刻 /*delay ： 是上一帧要持续显示的时长，也就是将要显示的一帧的开始显示时间 is-\u0026gt;frame_timer ： 上一帧显示的时间 is-\u0026gt;frame_timer + delay ： 将要显示这一帧的时间 如果time 还没达到显示这一帧的时间，就计算等待时间用于上一层等待，继续显示上一帧 如果seek后，delay = 0 ，time 就会大于is-\u0026gt;frame_timer + delay，就往下走显示 */ if (time \u0026lt; is-\u0026gt;frame_timer + delay)//如果上一帧显示时长未满，重复显示上一帧 { //进入视频显示，计算一个等待时间返回上一层，现在视频快了，让视频继续显示上一帧等待 *remaining_time = FFMIN(is-\u0026gt;frame_timer + delay - time, *remaining_time); goto display; } /*第一帧数据时is-\u0026gt;frame_timer = 0，会执行到time - is-\u0026gt;frame_timer \u0026gt; AV_SYNC_THRESHOLD_MAX 如果与系统时间的偏离太大，则修正为系统时间*/ is-\u0026gt;frame_timer += delay;//frame_timer更新为上一帧结束时刻，也是当前帧开始时刻 if (delay \u0026gt; 0 \u0026amp;\u0026amp; time - is-\u0026gt;frame_timer \u0026gt; AV_SYNC_THRESHOLD_MAX) is-\u0026gt;frame_timer = time;//如果与系统时间的偏离太大，则修正为系统时间 SDL_LockMutex(is-\u0026gt;pictq.mutex); /*更新视频时钟 注意：这个更新视频时钟在丢帧之前，那么如果这帧pts设置视频时钟后 下面又将这帧丢弃，视频时钟就是被丢弃的这一帧*/ if (!isnan(vp-\u0026gt;pts)) update_video_pts(is, vp-\u0026gt;pts, vp-\u0026gt;pos, vp-\u0026gt;serial); //更新视频时钟检测 SDL_UnlockMutex(is-\u0026gt;pictq.mutex); /*drop帧处理 队列要有将要显示这一帧的下一帧 第一帧，队列内有2帧 后面就是，队列内有3帧，因为保留了上一帧（显示帧）*/ //丢帧逻辑 if (frame_queue_nb_remaining(\u0026amp;is-\u0026gt;pictq) \u0026gt; 1) { Frame *nextvp = frame_queue_peek_next(\u0026amp;is-\u0026gt;pictq);//获取将要显示帧的下一帧 duration = vp_duration(is, vp, nextvp);//当前帧显示时长 //如果系统时间已经大于当前帧，则丢弃当前帧 if (!is-\u0026gt;step //非逐帧模式播放情况下 \u0026amp;\u0026amp; (framedrop \u0026gt; 0 //允许drop帧处理 || (framedrop \u0026amp;\u0026amp; get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) //主时钟不是视频 \u0026amp;\u0026amp; time \u0026gt; is-\u0026gt;frame_timer + duration)//当前时间已经到了nextvp的播放时间， { //此时is-\u0026gt;frame_timer就是将要显示这一帧vp的播放时间了 is-\u0026gt;frame_drops_late++;//丢帧统计 frame_queue_next(\u0026amp;is-\u0026gt;pictq);//丢弃将要显示这一帧，移动读索引读到下一帧 goto retry;//回到函数开始位置，继续重试(这里不能直接while丢帧，因为很可能audio clock重新对时了，这样delay值需要重新计算) } } /*上一帧与将要显示这一帧之间的duration用来计算将要显示这一帧的播放时间 将要显示这一帧与上一帧之间的duration用来计算是否丢弃将要显示这一帧*/ ... frame_queue_next(\u0026amp;is-\u0026gt;pictq); is-\u0026gt;force_refresh = 1;//刷新画面 if (is-\u0026gt;step \u0026amp;\u0026amp; !is-\u0026gt;paused) stream_toggle_pause(is); } display: /* display picture */ if (!display_disable \u0026amp;\u0026amp; is-\u0026gt;force_refresh \u0026amp;\u0026amp; is-\u0026gt;show_mode == SHOW_MODE_VIDEO \u0026amp;\u0026amp; is-\u0026gt;pictq.rindex_shown) video_display(is);//显示视频 } } 如果视频播放过快，则重复播放上一帧，以等待音频；如果视频播放过慢，则丢帧追赶音频。实现的方式是，参考audio clock，计算上一帧（在屏幕上的那个画面）还应显示多久（含帧本身时长），然后与系统时刻对比，是否该显示下一帧了。\nframe_timer frame_timer:可以理解为帧显示时刻，如更新前，是上一帧的显示时刻；对于更新后（is-\u0026gt;frame_timer += delay），则为当前帧显示时刻。\n上一帧显示时刻加上delay（还应显示多久（含帧本身时长））即为上一帧应结束显示的时刻。具体原理看如下示意图：\n这里给出了3种情况的示意图：\ntime1：系统时刻小于lastvp结束显示的时刻（frame_timer+dealy），即虚线圆圈位置。此时应该继续显示lastvp time2：系统时刻大于lastvp的结束显示时刻，但小于vp的结束显示时刻（vp的显示时间开始于虚线圆圈，结束于黑色圆圈）。此时既不重复显示lastvp，也不丢弃vp，即应显示vp time3：系统时刻大于vp结束显示时刻（黑色圆圈位置，也是nextvp预计的开始显示时刻）。此时应该丢弃vp。 dealy计算 lastvp的显示时长delay是如何计算的，主要在compute_target_delay中实现，代码如下：\nstatic double compute_target_delay(double delay, VideoState *is) { double sync_threshold, diff = 0; /* update delay to follow master synchronisation source */ //只有同步时钟不是视频时钟时才计算， if (get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER) { // 判断同步类型， /* if video is slave, we try to correct big delays by duplicating or deleting a frame */ /* get_clock(\u0026amp;is-\u0026gt;vidclk) ：返回经过从上次设置时钟到现在数据时间到了什么时间位置 get_master_clock(is) ： 返回主时钟到了什么时间位置（音频时钟或者外部时钟） diff ： 就是当前视频播放的位置与主时钟之前的差值 \u0026lt;0 ： 视频慢了 \u0026gt;0 ：视频快了 */ diff = get_clock(\u0026amp;is-\u0026gt;vidclk) - get_master_clock(is); /* skip or repeat frame. We take into account the delay to compute the threshold. I still don\u0026#39;t know if it is the best guess */ /*AV_SYNC_THRESHOLD_MIN 同步阀值最小范围：0.04 （秒） 1/25帧的时间 AV_SYNC_THRESHOLD_MAX 同步阀值最大范围：0.1 （秒） 1/10帧的时间 delay ： 理论上的两帧之间的时间 返回一个同步阀值在同步阀值范围内，使用delay设置 因为delay上层传来是两帧之间的时间，那只要在阀值范围内，这个时间就是sync_threshold*/ sync_threshold = FFMAX(AV_SYNC_THRESHOLD_MIN, FFMIN(AV_SYNC_THRESHOLD_MAX, delay)); if (!isnan(diff) \u0026amp;\u0026amp; fabs(diff) \u0026lt; is-\u0026gt;max_frame_duration) { //根据阀值判断是快了还是慢了 if (diff \u0026lt;= -sync_threshold)//差值已经超出阀值最小，视频慢了 delay = FFMAX(0, delay + diff);/*上一帧需要加快，delay + -diff，这样算出来的delay基本都是0，上一帧还要显示delay时间*/ else if (diff \u0026gt;= sync_threshold \u0026amp;\u0026amp; delay \u0026gt; AV_SYNC_FRAMEDUP_THRESHOLD) delay = delay + diff;/*视频快了，上一帧就要减慢，delay+diff，AV_SYNC_FRAMEDUP_THRESHOLD 0.1秒，如果帧持续时间超过这个值，它将不会被成倍来补偿进行同步*/ else if (diff \u0026gt;= sync_threshold) delay = 2 * delay;/*视频快了，delay 相当上一帧显示两次，因为diff == sync_threshold也是快了一帧*/ } } av_log(NULL, AV_LOG_TRACE, \u0026#34;video: delay=%0.3f A-V=%f\\n\u0026#34;, delay, -diff); return delay; } sync_threshold理解： 从图上可以看出来sync_threshold是建立一块区域，在这块区域内无需调整lastvp的显示时长，直接返回delay即可。也就是在这块区域内认为是准同步的。\n如果小于-sync_threshold，那就是视频播放较慢，需要适当丢帧。具体是返回一个最大为0的值。根据前面frame_timer的图，至少应更新画面为vp。\n如果大于sync_threshold，那么视频播放太快，需要适当重复显示lastvp。具体是返回2倍的delay，也就是2倍的lastvp显示时长，也就是让lastvp再显示一帧。\n总结 基本策略是：如果视频播放过快，则重复播放上一帧，以等待音频；如果视频播放过慢，则丢帧追赶音频。 这一策略的实现方式是：引入frame_timer概念，标记帧的显示时刻和应结束显示的时刻，再与系统时刻对比，决定重复还是丢帧。 lastvp的应结束显示的时刻，除了考虑这一帧本身的显示时长，还应考虑了video clock与audio clock的差值。 并不是每时每刻都在同步，而是有一个“准同步”的差值区域。 FrameQueue的分析 ffplay 是通过FrameQueue来保存解码后的数据；\nFrame结构体 Frame是用来存储解码后的一帧数据，其中包括视频、音频和字幕；\ntypedef struct Frame { AVFrame *frame;//音视频解码数据 AVSubtitle sub;//字幕解码数据 int serial; double pts; /* presentation timestamp for the frame */ double duration; /* estimated duration of the frame */ int64_t pos; /* byte position of the frame in the input file */ int width; int height; int format; AVRational sar; int uploaded; int flip_v; } Frame; FrameQueue结构体 FrameQueue是用来表示整个帧队列；\ntypedef struct FrameQueue { Frame queue[FRAME_QUEUE_SIZE];//队列元素，用数组模拟队列 int rindex;//读指针 int windex;//写指针 int size;//当前存储的节点个数 int max_size;//最大允许存储的节点个数 int keep_last;//是否要保留最后一个读节点 int rindex_shown;//当前节点是否已经显示 SDL_mutex *mutex; SDL_cond *cond; PacketQueue *pktq;//关联的PacketQueue } FrameQueue; FrameQueue的设计思想是通过数组实现队列（环形缓冲区）；\n设计理念：\n高效率的读写模型 高效的内存模型 环形缓冲区设计，同时可以访问上一读节点 FrameQueue实现函数分析 初始化函数 FrameQueue的初始化函数是frame_queue_init;\nstatic int frame_queue_init(FrameQueue *f, PacketQueue *pktq, int max_size, int keep_last) { int i; memset(f, 0, sizeof(FrameQueue)); if (!(f-\u0026gt;mutex = SDL_CreateMutex())) { av_log(NULL, AV_LOG_FATAL, \u0026#34;SDL_CreateMutex(): %s\\n\u0026#34;, SDL_GetError()); return AVERROR(ENOMEM); } if (!(f-\u0026gt;cond = SDL_CreateCond())) { av_log(NULL, AV_LOG_FATAL, \u0026#34;SDL_CreateCond(): %s\\n\u0026#34;, SDL_GetError()); return AVERROR(ENOMEM); } f-\u0026gt;pktq = pktq; f-\u0026gt;max_size = FFMIN(max_size, FRAME_QUEUE_SIZE); f-\u0026gt;keep_last = !!keep_last; for (i = 0; i \u0026lt; f-\u0026gt;max_size; i++) if (!(f-\u0026gt;queue[i].frame = av_frame_alloc())) return AVERROR(ENOMEM); return 0; } 其中主要是内存初始化和锁初始化，关键参数是max_size和keep_last;max_size是最大允许存储的节点个数,最大不能超过\nFRAME_QUEUE_SIZE，FRAME_QUEUE_SIZE定义如下：\n#define VIDEO_PICTURE_QUEUE_SIZE 3 //视频显示缓存最大帧数 #define SUBPICTURE_QUEUE_SIZE 16 //字幕缓存最大帧数 #define SAMPLE_QUEUE_SIZE 9 //默认最大帧数 #define FRAME_QUEUE_SIZE FFMAX(SAMPLE_QUEUE_SIZE, FFMAX(VIDEO_PICTURE_QUEUE_SIZE, SUBPICTURE_QUEUE_SIZE)) 如此看来最大不能超过16；\nkeep_last是一个bool值，表示是否在环形缓冲区的读写过程中保留最后一个读节点不被覆写。f-\u0026gt;keep_last = !!keep_last;里的双感叹号是C中的一种技巧，旨在让int参数规整为0/1的“bool值”。\n数组queue中的每个元素的frame(AVFrame*)的字段调用av_frame_alloc分配内存。\n反初始化函数 static void frame_queue_destory(FrameQueue *f) { int i; for (i = 0; i \u0026lt; f-\u0026gt;max_size; i++) { Frame *vp = \u0026amp;f-\u0026gt;queue[i]; frame_queue_unref_item(vp); av_frame_free(\u0026amp;vp-\u0026gt;frame); } SDL_DestroyMutex(f-\u0026gt;mutex); SDL_DestroyCond(f-\u0026gt;cond); } queue元素的释放分两步；\nframe_queue_unref_item,释放的内存都是关联的内存，而非结构体自身内存; av_frame_free,av_frame_free与初始化中的av_frame_alloc对应，用于释放AVFrame. frame_queue_unref_item定义如下：\nstatic void frame_queue_unref_item(Frame *vp) { av_frame_unref(vp-\u0026gt;frame);//frame计数减1 avsubtitle_free(\u0026amp;vp-\u0026gt;sub);//sub关联的内存释放 } AVFrame内部有许多的AVBufferRef类型字段，而AVBufferRef只是AVBuffer的引用，AVBuffer通过引用计数自动管理内存（简易垃圾回收机制）。因此AVFrame在不需要的时候，需要通过av_frame_unref减少引用计数。(这个还在学习阶段)\nFrameQueue的‘写’操作 FrameQueue的‘写’操作分为两个步骤；\nframe_queue_peek_writable获取一个可写节点； frame_queue_push告知FrameQueue“存入”该节点。 FrameQueue始终是一个线程写，另一个线程读。读写没有其他线程产生竞争，唯一需要的是读与写线程间的同步。FrameQueue的整个优化和设计思路正是基于这一点的。这个设计思想类似于Linux内核中的kfifo。\nframe_queue_peek_writable定义如下：\nstatic Frame *frame_queue_peek_writable(FrameQueue *f) { /* wait until we have space to put a new frame */ SDL_LockMutex(f-\u0026gt;mutex); while (f-\u0026gt;size \u0026gt;= f-\u0026gt;max_size \u0026amp;\u0026amp; !f-\u0026gt;pktq-\u0026gt;abort_request) { SDL_CondWait(f-\u0026gt;cond, f-\u0026gt;mutex); } SDL_UnlockMutex(f-\u0026gt;mutex); if (f-\u0026gt;pktq-\u0026gt;abort_request) return NULL; return \u0026amp;f-\u0026gt;queue[f-\u0026gt;windex]; } 函数分3步：\n加锁情况下，等待直到队列有空余空间可写（f-\u0026gt;size \u0026lt; f-\u0026gt;max_size） 如果有退出请求（f-\u0026gt;pktq-\u0026gt;abort_request），则返回NULL 返回windex位置的元素（windex指向当前应写位置） 因为queue数组被当做一个环形缓冲区使用，那么的确存在underrun和overrun的情况，即读过快，或写过快的情况，这时如果不加控制，就会呈现缓冲区覆盖。\nFrameQueue的精明之处在于，先通过size判断当前缓冲区内空间是否够写，或者够读，比如这里先通过一个循环的条件等待，判断f-\u0026gt;size \u0026gt;= f-\u0026gt;max_size，如果f-\u0026gt;size \u0026gt;= f-\u0026gt;max_size，那么说明队列中的节点已经写满，也就是已经overrun了，此时如果再写，肯定会覆写未读数据，那么就需要继续等待。当无需等待时，windex指向的内存一定是已经读过的（除非代码异常了）。\n调用frame_queue_peek_writable取到Frame指针后，就可以对Frame内的字段自由改写，因为只有一个写进程，且无需担心读进程覆写（如上分析，读进程要读一个节点时，也会先判断underrun的情况）。\n实现步骤：\nFrame* vp = frame_queue_peek_writable(q); //将要存储的数据写入frame字段，比如： av_frame_move_ref(vp-\u0026gt;frame, src_frame); //存入队列 frame_queue_push(q); frame_queue_push代码如下：\nstatic void frame_queue_push(FrameQueue *f) { if (++f-\u0026gt;windex == f-\u0026gt;max_size) f-\u0026gt;windex = 0; SDL_LockMutex(f-\u0026gt;mutex); f-\u0026gt;size++; SDL_CondSignal(f-\u0026gt;cond); SDL_UnlockMutex(f-\u0026gt;mutex); } 执行两个步骤：\nwindex加1，如果超过max_size，则回环为0 加锁情况下大小加1. frame_queue的写过程总结示意图如下：\nFrameQueue的\u0026rsquo;读\u0026rsquo;操作 FrameQueue的‘读’操作分为两个步骤；\nframe_queue_peek_readable获取一个可读节点 frame_queue_next告知FrameQueue“取出”该节点。 frame_queue_peek_readable代码如下：\nstatic Frame *frame_queue_peek_readable(FrameQueue *f) { /* wait until we have a readable a new frame */ SDL_LockMutex(f-\u0026gt;mutex); //加锁情况下，判断是否有可读节点 while (f-\u0026gt;size - f-\u0026gt;rindex_shown \u0026lt;= 0 \u0026amp;\u0026amp; !f-\u0026gt;pktq-\u0026gt;abort_request) { SDL_CondWait(f-\u0026gt;cond, f-\u0026gt;mutex); } SDL_UnlockMutex(f-\u0026gt;mutex); //如果有退出请求，则返回NULL if (f-\u0026gt;pktq-\u0026gt;abort_request) return NULL; //读取当前可读节点 return \u0026amp;f-\u0026gt;queue[(f-\u0026gt;rindex + f-\u0026gt;rindex_shown) % f-\u0026gt;max_size]; } frame_queue_next代码如下：\nstatic void frame_queue_next(FrameQueue *f) { //如果支持keep_last，且rindex_shown为0，则rindex_shown赋1，返回 if (f-\u0026gt;keep_last \u0026amp;\u0026amp; !f-\u0026gt;rindex_shown) { f-\u0026gt;rindex_shown = 1; return; } //否则，移动rindex指针，并减小size frame_queue_unref_item(\u0026amp;f-\u0026gt;queue[f-\u0026gt;rindex]); if (++f-\u0026gt;rindex == f-\u0026gt;max_size) f-\u0026gt;rindex = 0; SDL_LockMutex(f-\u0026gt;mutex); f-\u0026gt;size--; SDL_CondSignal(f-\u0026gt;cond); SDL_UnlockMutex(f-\u0026gt;mutex); } frame_queue_next用于在读完一个节点后调用，用于标记一个节点已经被读过。\n读过程可以描述为：\nFrame* vp = frame_queue_peek_readable(f); //读取vp的数据，比如 printf(\u0026#34;pict_type=%d\\n\u0026#34;, vp-\u0026gt;frame-\u0026gt;pict_type); frame_queue_next(f); 标记一个节点为已读，执行两个步骤：\nrindex加1，如果超过max_size，则回环为0 加锁情况下大小减1. 对于以及读过的节点，需要调用frame_queue_unref_item释放关联内存。\n执行rindex操作前，需要先判断rindex_shown的值，如果为0，则赋1。如下图：\n这里模拟了从初始化开始的2次“读”。\n还没开始读，rindex和rindex_shown均为0。这时要peek的读节点是节点0(图中黑色块）。\n第一次读，调用next，满足条件f-\u0026gt;keep_last \u0026amp;\u0026amp; !f-\u0026gt;rindex_shown，所以rindex仍然是0，而rindex_shown为1.此时节点0（灰色块）是已读节点，也是要keep的last节点，将要读的节点是节点1（黑色块）。（恰好是rindex+rindex_shown）\n第二次读，peek了黑色块后，调用next，不满足条件f-\u0026gt;keep_last \u0026amp;\u0026amp; !f-\u0026gt;rindex_shown，所以rindex为1，而rindex_shown为2.此时节点1（灰色块）是last节点，节点2（黑色块）是将要读的节点。（也恰好是rindex+rindex_shown）\n继续往后分析，会一直重复第二次读的情况，始终是rindex指向了last，而rindex_shown一直为1，rindex+rindex_shown刚好是将要读的节点。\nFrameQueue的读过程也分析完了。\n辅助函数 //（上文中的用词是“将要读的节点”，也就是黑色块），与frame_queue_peek_readable等效，但没有检查是否有可读节点 //读当前节点 static Frame *frame_queue_peek(FrameQueue *f) { return \u0026amp;f-\u0026gt;queue[(f-\u0026gt;rindex + f-\u0026gt;rindex_shown) % f-\u0026gt;max_size]; } //读下一个节点 static Frame *frame_queue_peek_next(FrameQueue *f) { return \u0026amp;f-\u0026gt;queue[(f-\u0026gt;rindex + f-\u0026gt;rindex_shown + 1) % f-\u0026gt;max_size]; } //读上一个节点 static Frame *frame_queue_peek_last(FrameQueue *f) { return \u0026amp;f-\u0026gt;queue[f-\u0026gt;rindex]; } /* return the number of undisplayed frames in the queue */ static int frame_queue_nb_remaining(FrameQueue *f) { return f-\u0026gt;size - f-\u0026gt;rindex_shown; } /* return last shown position */ static int64_t frame_queue_last_pos(FrameQueue *f) { Frame *fp = \u0026amp;f-\u0026gt;queue[f-\u0026gt;rindex]; if (f-\u0026gt;rindex_shown \u0026amp;\u0026amp; fp-\u0026gt;serial == f-\u0026gt;pktq-\u0026gt;serial) return fp-\u0026gt;pos; else return -1; } 看下节点位置：\n参考链接： https://www.zhihu.com/column/avtec\nhttps://cloud.tencent.com/developer/article/1373966\n","permalink":"https://rong05.github.io/learn/av-learn/ffplay_learn/","summary":"[TOC]\nffplay源码分析 熟悉FFmpeg项目从源码看起，以下是我阅读FFplay的源代码的总结；FFplay是FFmpeg项目提供的播放器示例，它的源代码的量也是不少的，其中很多知识点是我们可以学习和借鉴的。\n总结构图 参照雷神（雷霄骅）的FFplay的总体函数调用结构图，自己总结了一个最新版本的结构，其中还有诸多不足，以后有机会慢慢完善；如下图所示。\n这就不对主要函数分别解析，我来学习一下其中关键性的思想和ffplay的体系结构。\n视频部分 ffplay video的线程模式 ffplay选择了sdl作为显示SDK，以实现跨平台支持；因为使用了SDL，而video的显示也依赖SDL的窗口显示系统，所以先从main函数的SDL初始化看起：\nint main(int argc, char **argv) { ... /* register all codecs, demux and protocols */ #if CONFIG_AVDEVICE avdevice_register_all(); //注册所有解码器 #endif avformat_network_init(); init_opts(); signal(SIGINT, sigterm_handler); /* Interrupt (ANSI). */ signal(SIGTERM, sigterm_handler); /* Termination (ANSI). */ show_banner(argc, argv, options); //打印ffmpag库版本信息，编译时间，编译选项，类库信息等 parse_options(NULL, argc, argv, options, opt_input_file); //解析输入的命令。 ... if (SDL_Init(flags)) { //初始化sdl av_log(NULL, AV_LOG_FATAL, \u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); av_log(NULL, AV_LOG_FATAL, \u0026#34;(Did you set the DISPLAY variable?","title":""},{"content":"rtp协议解析 ​\trtp (实时传输协议)是一个网络传输协议，属于应用层协议\n​\tRTP协议详细说明了在互联网上传递音频和视频的标准数据包格式。它一开始被设计为一个多播协议，但后来被用在很多单播应用中。RTP协议常用于流媒体系统（配合RTSP协议），视频会议和一键通（Push to Talk）系统（配合H.323或SIP），使它成为IP电话产业的技术基础。RTP协议和RTP控制协议RTCP一起使用，而且它是创建在UDP协议上的。\n​\trtp被划分在传输层，建立在udp上。同UDP协议一样，为了实现其实时传输功能，RTP也有固定的封装形式。RTP用来为端到端的实时传输提供时间信息和流同步，但并不保证服务质量。服务质量由RTCP来提供。\nRtp协议封装 ​\trtp传输过程中，根据以太网的MTU一般为1500字节，去除ip协议包头、udp协议包头和PPPoE协议内容，rtp数据分组最大值应为1400字节（这个只是标准值，实际值应该按照MTU大小来决定）。\n​\t注意 RTP 本身没有提供任何的机制来确保实时的传输或其他的服务质量保证，而是由低层的服务来完成。它不保证传输或防止乱序传输,它不假定下层网络是否可靠,是否按顺序传送数据包。RTP 包含的序列号允许接受方重构发送方的数据包顺序，但序列号也用来确定一个数据包的正确位置,例如,在视频解码的时候不用按顺序的对数据包进行解码。\nrtp head ​\n​\trtp头结构体的定义中大端和小端模式是有区别的，需要区分对待。\n​\t前 12 个字节出现在每个 RTP 包中，仅仅在被混合器插入时，才出现 CSRC 识别符列表。各个域的含义如下所示：\n版本(version)：2 比特，此域定义了 RTP 的版本。此协议定义的版本是 2。(值 1 被 RTP 草案版本使用,值 0 用在最初\u0026quot;vat\u0026quot;语音工具使用的协议中。)\n填充(P)：1 比特，若填料比特被设置,则此包包含一到多个附加在末端的填充比特,填充比特不算作负载的一部分。填充的最后一个字节指明可以忽略多少个填充比特。填充可能用于某些具有固定长度的加密算法，或者用于在底层数据单元中传输多个 RTP 包。\n扩展(X)：1 比特，若设置扩展比特,固定头(仅)后面跟随一个头扩展。\nCSRC 计数(CC)：4 比特，CSRC 计数包含了跟在固定头后面 CSRC 识别符的数目。\n标志(M)：1 比特，标志的解释由具体协议规定。它用来允许在比特流中标记重要的事件,如帧边界。\n负载类型(PT)：7 比特，此域定义了负载的格式，由具体应用决定其解释，协议可以规定负载类型码和负载格式之间一个默认的匹配。其他的负载类型码可以通过非 RTP 方法动态定义。RTP发送端在任意给定时间发出一个单独的 RTP 负载类型；此域不用来复用不同的媒体流。\n序列号(sequence number)：16 比特，每发送一个 RTP 数据包,序列号加 1，接收端可以据此检测丢包和重建包序列。序列号的初始值是随机的(不可预测),以使即便在源本身不加密时(有时包要通过翻译器,它会这样做)，对加密算法泛知的普通文本攻击也会更加困难。\n时间戳(timestamp) ：32 比特，时间戳反映了 RTP 数据包中第一个字节的采样时间。时钟频率依赖于负载数据格式,并在描述文件(profile)中进行描述。也可以通过 RTP 方法对负载格式动态描述。\nSSRC：32 比特，用以识别同步源。标识符被随机生成，以使在同一个 RTP 会话期中没有任何两个同步源有相同的 SSRC 识别符。尽管多个源选择同一个 SSRC 识别符的概率很低，所有 RTP 实现工具都必须准备检测和解决冲突。若一个源改变本身的源传输地址，必须选择新的SSRC 识别符，以避免被当作一个环路源。\n如音频编码。SSRC 标识符是一个随机选取的值，它在特定的 RTP 会话中是全局唯一(globally unique)的。参与者并不需要在一个多媒体会议的所有 RTP 会话中，使用相同的 SSRC 标识符；SSRC 标识符的绑定通过RTCP。如果参与者在一个 RTP 会话中生成了多个流，例如来自多个摄影机，则每个摄影机都必须标识成单独的同步源。\nCSRC 列表：0 到 15 项，每项 32 比特，CSRC 列表识别在此包中负载的所有贡献源。识别符的数目在 CC 域中给定。若有贡献源多于 15 个，仅识别 15 个。CSRC 识别符由混合器插入，并列出所有贡献源的 SSRC 识别符。例如语音包，混合产生新包的所有源的 SSRC 标识符都被列出，以在接收端处正确指示参与者。\n提供信源用来标志对一个RTP混合器产生的新包有贡献的所有RTP包的源。是指当混合器接收到一个或多个同步信源的RTP报文后，经过混合处理产生一个新的组合RTP报文，并把混合器作为组合RTP报文的SSRC，而将原来所有的SSRC都作为CSRC传送给接收者，使接收者知道组成组合报文的各个SSRC。\n注：基本的RTP说明并不定义任何头扩展本身，如果遇到X=1，需要特殊处理\n若 RTP 固定头中的扩展比特位置 1，则一个长度可变的头扩展部分被加到 RTP 固定头之后，其格式如下：\n​\t头扩展包含 16 比特的长度域，指示扩展项中 32 比特字的个数，不包括 4 个字节扩展头(因此零是有效值)。RTP 固定头之后只允许有一个头扩展。为允许多个互操作实现独立生成不同的头扩展，或某种特定实现有多种不同的头扩展,扩展项的前 16 比特用以识别标识符或参数。这 16 比特的格式由具体实现的上层协议定义。基本的 RTP 说明并不定义任何头扩展本身。\n","permalink":"https://rong05.github.io/learn/av-learn/rtp_protocol/","summary":"rtp协议解析 ​\trtp (实时传输协议)是一个网络传输协议，属于应用层协议\n​\tRTP协议详细说明了在互联网上传递音频和视频的标准数据包格式。它一开始被设计为一个多播协议，但后来被用在很多单播应用中。RTP协议常用于流媒体系统（配合RTSP协议），视频会议和一键通（Push to Talk）系统（配合H.323或SIP），使它成为IP电话产业的技术基础。RTP协议和RTP控制协议RTCP一起使用，而且它是创建在UDP协议上的。\n​\trtp被划分在传输层，建立在udp上。同UDP协议一样，为了实现其实时传输功能，RTP也有固定的封装形式。RTP用来为端到端的实时传输提供时间信息和流同步，但并不保证服务质量。服务质量由RTCP来提供。\nRtp协议封装 ​\trtp传输过程中，根据以太网的MTU一般为1500字节，去除ip协议包头、udp协议包头和PPPoE协议内容，rtp数据分组最大值应为1400字节（这个只是标准值，实际值应该按照MTU大小来决定）。\n​\t注意 RTP 本身没有提供任何的机制来确保实时的传输或其他的服务质量保证，而是由低层的服务来完成。它不保证传输或防止乱序传输,它不假定下层网络是否可靠,是否按顺序传送数据包。RTP 包含的序列号允许接受方重构发送方的数据包顺序，但序列号也用来确定一个数据包的正确位置,例如,在视频解码的时候不用按顺序的对数据包进行解码。\nrtp head ​\n​\trtp头结构体的定义中大端和小端模式是有区别的，需要区分对待。\n​\t前 12 个字节出现在每个 RTP 包中，仅仅在被混合器插入时，才出现 CSRC 识别符列表。各个域的含义如下所示：\n版本(version)：2 比特，此域定义了 RTP 的版本。此协议定义的版本是 2。(值 1 被 RTP 草案版本使用,值 0 用在最初\u0026quot;vat\u0026quot;语音工具使用的协议中。)\n填充(P)：1 比特，若填料比特被设置,则此包包含一到多个附加在末端的填充比特,填充比特不算作负载的一部分。填充的最后一个字节指明可以忽略多少个填充比特。填充可能用于某些具有固定长度的加密算法，或者用于在底层数据单元中传输多个 RTP 包。\n扩展(X)：1 比特，若设置扩展比特,固定头(仅)后面跟随一个头扩展。\nCSRC 计数(CC)：4 比特，CSRC 计数包含了跟在固定头后面 CSRC 识别符的数目。\n标志(M)：1 比特，标志的解释由具体协议规定。它用来允许在比特流中标记重要的事件,如帧边界。\n负载类型(PT)：7 比特，此域定义了负载的格式，由具体应用决定其解释，协议可以规定负载类型码和负载格式之间一个默认的匹配。其他的负载类型码可以通过非 RTP 方法动态定义。RTP发送端在任意给定时间发出一个单独的 RTP 负载类型；此域不用来复用不同的媒体流。\n序列号(sequence number)：16 比特，每发送一个 RTP 数据包,序列号加 1，接收端可以据此检测丢包和重建包序列。序列号的初始值是随机的(不可预测),以使即便在源本身不加密时(有时包要通过翻译器,它会这样做)，对加密算法泛知的普通文本攻击也会更加困难。\n时间戳(timestamp) ：32 比特，时间戳反映了 RTP 数据包中第一个字节的采样时间。时钟频率依赖于负载数据格式,并在描述文件(profile)中进行描述。也可以通过 RTP 方法对负载格式动态描述。","title":""},{"content":"camx 高通camx框架 目前高通主流芯片使用camera框架基本都是camx架构。 之前旧的架构叫做mm-camera，camx架构和之前架构代码更加复杂、具有较强的客制化。 我们先来看下camx整体的架构图：\ncamx的框架入口为camx包中的camxhal3entry.cpp，代码路径在vendor/qcom/proprietary/camx/下,编译结果是camera.qcom.so Camx通过chxentensionInterface调用到chi-cdk包下的代码，这里面一般是手机厂商自己定制功能的地方，代码目录在vendor/qcom/proprietary/chi-cdk/，编译结果是com.qti.chi.override.so Chi对Camx的操作，需要通过ExtensionModule进行操作，因此，CamX对外提供的接口扩展需要通过ExtensionModule进行，里面一个重要的变量就是g_chiContextOps。 Camx对Chi的操作，是通过HAL3Module接口的m_ChiAppCallbacks进行的，因此chi里面释放的接口，都会在m_ChiAppCallbacks里面体现。 camera数据通路 在camx框架上大致的camera数据流向如下图：\nCSID: 摄像机串行接口解码器模块 IFE：图像前端 IFE_Lite：图像前端 lite BPS：Bayer处理区段 IFE：图像处理引擎 VPU：视频处理单元（编解码器） DPU：显示处理单元 这些都是表示的是芯片内部的一个硬件处理单元，数据在这些单元内部的处理还是比较复杂的，在不同的处理单元里面，会进行一些复杂的算法处理；有个认识，有个基本概念。\nCamx基本组件及概念 usecase 是一种抽象概念；高通的介绍是A set of streams configured by the client combined with a set of static properties specifying the processing of those streams(由客户端配置的一组流，这组流是有着一系列静态属性相结合描述的流。)See createCaptureSession in the Android CameraDevice documentation；\n具体实现是在CHI中通过Usecase类完成的，该类主要负责了其中的业务处理以及资源的管理。 简单说明：按照android 的Camera2 API来说；把预览的surface和录像的surface都设进去，然后去创建session，就是表示我预览和录像都需要拿到camera数据。假设我预览设置的size是1080 x 720，录像是1080p的，那这个1080 x 720预览+1080p录像就是一个usecase（用例）。\nCameraUsecaseBase作为Usecase类的基类提供了一系列通用接口，其中，AdvancedCameraUsecase\n又继承于CameraUsecaseBase，相机中绝大部分场景会通过实例化AdvancedCameraUsecase\n来完成，它包括了几个主要接口：\ncreate创建AdvancedCameraUsecase实例，并获取相对应的Usecase配置信息 ExecuteCaptureRequest用于下发一次Request ProcessResultCb在创建session时作为回调方法注册到其中，一旦Session数据处理完成的时候便会调用该方法将结果发送到AdvancedCameraUsecase中。 ProcessDriverPartialCaptureResult在创建session时作为回调方法注册到其中，一旦Session中产生了partial meta data的时候，便会调用该方法将其发送至AdvancedCameraUsecase中。 ProcessMessageCb在创建session时作为回调方法注册到其中，一旦Session产生任何事件，便会调用该方法通知到AdvancedCameraUsecase中。 ExecuteFlush用于刷新AdvancedCameraUsecase。 Destroy用于安全销毁AdvancedCameraUsecase。 Feature 代表一个特定的功能。高通上的feature有HDR(高动态范围)、SuperNight（超级夜景）、MFNR（多帧降噪）等等,usecase选择相应的feature，然后关联一组pipeline，上层下发request请求，hal层会根据request去选择对应的feature。（feature2内部代码相对复杂，目前还不太了解，还在学习过程中）\nNode 单个具有独立处理功能的抽象模块，可以是软件单元也可以是硬件单元。Node是camx中非常重要的一个父类，是处理camera 请求的一个中间节点，用于处理pipeline下发的请求。Node 节点在camx chi架构中至关重要，数据的处理都是通过封装好的Node节点来进行的。 Node类其主要方法如下：\nCreate: 用于实例化一个Node对象。 ExecuteProcessRequest: 该方法用于针对hwl node下发request的操作。 ProcessRequestIdDone: 一旦该Node当前request已经处理完成，便会通过调用该方法通知Pipeline。 ProcessMetadataDone: 一旦该Node的当前request的metadata已经生成，便会通过调用该方法通知到Pipeline。 ProcessPartialMetadataDone: 一旦该Node的当前request的partial metadata已经生成，便会通过调用该方法通知到Pipeline。 CreateImageBufferManager: 创建ImageBufferManager Port 作为Node的输入输出的端口，每一个Node都可以根据需要使用一个或者多个输入输出端口，使用OutputPort以及InputPort结构体来进行在代码中定义。\nLink 用于定义不同Port的连接，一个Port可以根据需要建立多条与其它从属于不同Node的Port的连接,它通过标签来进行定义，其中包括了作为输入端口，作为输出端口。 一个Link中包含了一个SrcPort和一个DstPort，分别代表了输入端口和输出端口，然后BufferProperties用于表示两个端口之间的buffer配置。\npipeline 作为提供单一特定功能的所有资源的集合，维护着所有硬件资源以及数据的流转，每一个Pipeline包括了其中的Node/Link，在CamX中通过Pipeline类进行实现，负责整条Pipeline的软硬件资源的维护以及业务逻辑的处理，接下来我们简单看下该类的几个主要接口：\nCreate: 根据传入的PipelineCreateInputData信息来实例化一个Pipeline对象。 StreamOn: 通知Pipeline开始硬件的数据传输 StreamOff: 通知Pipeline停止硬件的数据传输 FinalizePipeline: 用于完成Pipeline的设置工作 penRequest: open一个CSL用于流转的Request ProcessRequest: 下发Request NotifyNodeMetadataDone: 该方法是Pipeline提供给Node，当Node内部生成了metadata,便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessMetadataRequestIdDone通知Session。 NotifyNodePartialMetadataDone: 该方法是Pipeline提供给Node，当Node内部生成了partial metadata,便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessPartialMetadataRequestIdDone通知Session。 SinkPortFenceSignaled: 用来通知Session 某个sink port的fence处于被触发的状态。 NonSinkPortFenceSignaled: 用来通知Session 某个non sink port的fence处于被触发的状态。 ","permalink":"https://rong05.github.io/learn/camera/cmax/camx/","summary":"camx 高通camx框架 目前高通主流芯片使用camera框架基本都是camx架构。 之前旧的架构叫做mm-camera，camx架构和之前架构代码更加复杂、具有较强的客制化。 我们先来看下camx整体的架构图：\ncamx的框架入口为camx包中的camxhal3entry.cpp，代码路径在vendor/qcom/proprietary/camx/下,编译结果是camera.qcom.so Camx通过chxentensionInterface调用到chi-cdk包下的代码，这里面一般是手机厂商自己定制功能的地方，代码目录在vendor/qcom/proprietary/chi-cdk/，编译结果是com.qti.chi.override.so Chi对Camx的操作，需要通过ExtensionModule进行操作，因此，CamX对外提供的接口扩展需要通过ExtensionModule进行，里面一个重要的变量就是g_chiContextOps。 Camx对Chi的操作，是通过HAL3Module接口的m_ChiAppCallbacks进行的，因此chi里面释放的接口，都会在m_ChiAppCallbacks里面体现。 camera数据通路 在camx框架上大致的camera数据流向如下图：\nCSID: 摄像机串行接口解码器模块 IFE：图像前端 IFE_Lite：图像前端 lite BPS：Bayer处理区段 IFE：图像处理引擎 VPU：视频处理单元（编解码器） DPU：显示处理单元 这些都是表示的是芯片内部的一个硬件处理单元，数据在这些单元内部的处理还是比较复杂的，在不同的处理单元里面，会进行一些复杂的算法处理；有个认识，有个基本概念。\nCamx基本组件及概念 usecase 是一种抽象概念；高通的介绍是A set of streams configured by the client combined with a set of static properties specifying the processing of those streams(由客户端配置的一组流，这组流是有着一系列静态属性相结合描述的流。)See createCaptureSession in the Android CameraDevice documentation；\n具体实现是在CHI中通过Usecase类完成的，该类主要负责了其中的业务处理以及资源的管理。 简单说明：按照android 的Camera2 API来说；把预览的surface和录像的surface都设进去，然后去创建session，就是表示我预览和录像都需要拿到camera数据。假设我预览设置的size是1080 x 720，录像是1080p的，那这个1080 x 720预览+1080p录像就是一个usecase（用例）。\nCameraUsecaseBase作为Usecase类的基类提供了一系列通用接口，其中，AdvancedCameraUsecase\n又继承于CameraUsecaseBase，相机中绝大部分场景会通过实例化AdvancedCameraUsecase\n来完成，它包括了几个主要接口：\ncreate创建AdvancedCameraUsecase实例，并获取相对应的Usecase配置信息 ExecuteCaptureRequest用于下发一次Request ProcessResultCb在创建session时作为回调方法注册到其中，一旦Session数据处理完成的时候便会调用该方法将结果发送到AdvancedCameraUsecase中。 ProcessDriverPartialCaptureResult在创建session时作为回调方法注册到其中，一旦Session中产生了partial meta data的时候，便会调用该方法将其发送至AdvancedCameraUsecase中。 ProcessMessageCb在创建session时作为回调方法注册到其中，一旦Session产生任何事件，便会调用该方法通知到AdvancedCameraUsecase中。 ExecuteFlush用于刷新AdvancedCameraUsecase。 Destroy用于安全销毁AdvancedCameraUsecase。 Feature 代表一个特定的功能。高通上的feature有HDR(高动态范围)、SuperNight（超级夜景）、MFNR（多帧降噪）等等,usecase选择相应的feature，然后关联一组pipeline，上层下发request请求，hal层会根据request去选择对应的feature。（feature2内部代码相对复杂，目前还不太了解，还在学习过程中）","title":""},{"content":"rbtree rbtree implementation adapted from linux kernel thus can be used in your own c program(of course in userspace).\n","permalink":"https://rong05.github.io/learn/data-structure_learn/rbtree-master/readme/","summary":"rbtree rbtree implementation adapted from linux kernel thus can be used in your own c program(of course in userspace).","title":""},{"content":"红黑树 ​\t红黑树（英语：Red–black tree）是一种自平衡二叉查找树,红黑树的结构复杂，但它的操作有着良好的最坏情形运行时间，查找、插入和删除时间复杂度为O(logn)。\n​\t其实红黑树也是二叉查找树的一种，二叉查找树在最坏的情形下可能会变成一个链表（当所有 节点按从小到大的顺序依次插入后）；这样树的平衡性被破坏，要提高查询效率需要维持这种平衡和降低树的高度，而其中可性的做法就是用策略在每次修改树的内容之后进行结构调整，使其保持一定的平衡条件；而红黑树就是其中一员。\n优点 ​\t红黑树在插入时间、删除时间和查找时间提供最好可能的最坏情形担保，多数用时间敏感或者实时性强的应用中。\n​\t红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入和删除操作时少量的旋转操作，整体来说性能要优于AVL树\n性质 ​\t红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。还需遵循以下规则：\n节点分为红色或者黑色 根节点比必须是黑色 所有叶子都是黑色（叶子是NIL节点，或者称为空（NULL）叶子） 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 红黑树的图例：\n操作 ​\t在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质，因此需对红黑树进行性质的恢复，但必须做到少量O(logn)的颜色变更,而且不超过三次树旋转（对于插入操作是两次）；由此可以看出红黑树的插入和删除复杂，但是操作时间仍然可以保持O(logn)\n树旋转 ​\t树旋转是不影响元素顺序，但会改变树的结构，将一个节点上移、一个节点下移；\n​\t左孩子旋转到父节点的位置为右旋；\n​\t右孩子旋转到父节点的位置为左旋；\n​\t红黑树的左旋代码如下：\nstatic void __rb_rotate_left(struct rb_node *node, struct rb_root *root) { struct rb_node *right = node-\u0026gt;rb_right;//取出node的右节点 struct rb_node *parent = rb_parent(node);//取出node的父亲节点 if ((node-\u0026gt;rb_right = right-\u0026gt;rb_left))//node的右子节点指向right的左子节点时 rb_set_parent(right-\u0026gt;rb_left, node);//并将right的左子节点与right脱离，right的左子节点的父亲节点指向node right-\u0026gt;rb_left = node;//将right的左子节点重新指向node /**** 到现在就完成了，node右侧树与node脱离，接下来就是将脱离的右侧树重新连接parent *****/ rb_set_parent(right, parent);//将right的父亲节点指向node父亲节点 if (parent)//node非根节点 { if (node == parent-\u0026gt;rb_left)//判断node所在parent的方向并将parent对应的节点重新指向right parent-\u0026gt;rb_left = right; else parent-\u0026gt;rb_right = right; } else //node是根节点，那将right设置为根节点 root-\u0026gt;rb_node = right; rb_set_parent(node, right);//最后将node的父亲节点设置为right } 红黑树的右旋代码如下：\nstatic void __rb_rotate_right(struct rb_node *node, struct rb_root *root) { struct rb_node *left = node-\u0026gt;rb_left;//取出node的左节点 struct rb_node *parent = rb_parent(node);//取出node的父亲节点 if ((node-\u0026gt;rb_left = left-\u0026gt;rb_right))//将node的左子节点指向left的右子节点 rb_set_parent(left-\u0026gt;rb_right, node);//将left的右子节点的父亲节点指向node left-\u0026gt;rb_right = node;//将left的右子节点重新指向node /**** 到现在就完成了，node左侧树与node脱离，接下来就是将脱离的左侧树重新连接parent *****/ rb_set_parent(left, parent);//将left的父亲节点指向node父亲节点 if (parent)//node非根节点 { if (node == parent-\u0026gt;rb_right)//判断node所在parent的方向并将parent对应的节点重新指向left parent-\u0026gt;rb_right = left; else parent-\u0026gt;rb_left = left; } else//node是根节点，那将left设置为根节点 root-\u0026gt;rb_node = left; rb_set_parent(node, left);//最后将node的父亲节点设置为left } 颜色调换 ​\t保持红黑树的性质，结点不能乱挪，还得靠变色了；具体怎么样来调整颜色还要看插入和删除的情形来定，在说明插入和删除操作的时候来详细说明，所以现在只需记住红黑树总是通过旋转和变色达到自平衡。\n插入 ​\t首先在增加节点时，将其标记成红色，如果设置为黑色就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换（color flips）和树旋转来调整。\n流程图如下：\n完成以上流程只是找到具体的插入位置，但在插入之后需重新调整平衡来保持红黑树的基本属性，进行重新调整平衡实现代码如下：\nvoid rb_insert_color(struct rb_node *node, struct rb_root *root)//已经查找到相应的位置，进行重新调整平衡 { struct rb_node *parent, *gparent; while ((parent = rb_parent(node)) \u0026amp;\u0026amp; rb_is_red(parent))//取出父亲节点，并父亲节点是红色的时候 { gparent = rb_parent(parent);//获取祖父节点 if (parent == gparent-\u0026gt;rb_left)//如果父亲节点是在祖父节点左侧 { { register struct rb_node *uncle = gparent-\u0026gt;rb_right; if (uncle \u0026amp;\u0026amp; rb_is_red(uncle))//存在在叔叔节点，父亲节点和叔叔节点都为红色，当父亲节点在祖父节点左侧 { rb_set_black(uncle);//将父亲节点和叔叔节点都置为黑色 rb_set_black(parent); rb_set_red(gparent);//再将祖父节点置为红色 （保持性质5） node = gparent;//将祖父节点当成是新加入的节点进行各种情形的檢查 continue; } } //情形4、当父亲节点为红色，叔叔节点缺失或为黑色，新节点为其父亲节点的右侧时，其父亲节点在祖父节点左侧 if (parent-\u0026gt;rb_right == node) { register struct rb_node *tmp; __rb_rotate_left(parent, root);//针对父亲节点进行一次左旋转，并将新节点位置和其父亲节点位置进行交换 tmp = parent; parent = node; node = tmp; } //完成情形4，还需解决仍然失效的性质4； //情形5、将父亲节点置为黑色，在将祖父节点置为红色，并针对祖父节点进行一次右旋转，使其结果满足性质4 rb_set_black(parent); rb_set_red(gparent); __rb_rotate_right(gparent, root); } else {//如果父亲节点是在祖父节点右侧， { register struct rb_node *uncle = gparent-\u0026gt;rb_left; if (uncle \u0026amp;\u0026amp; rb_is_red(uncle))//存在在叔叔节点，父亲节点和叔叔节点都为红色，当父亲节点在祖父节点右侧 { rb_set_black(uncle);//将父亲节点和叔叔节点都置为黑色 rb_set_black(parent); rb_set_red(gparent);//再将祖父节点置为红色 （保持性质5） node = gparent;//将祖父节点当成是新加入的节点进行各种情形的檢查 continue; } } //因为父亲节点是在祖父节点右侧，情形4和情形5中的左和右应当对调。 if (parent-\u0026gt;rb_left == node) { register struct rb_node *tmp; __rb_rotate_right(parent, root); tmp = parent; parent = node; node = tmp; } rb_set_black(parent); rb_set_red(gparent); __rb_rotate_left(gparent, root); } } rb_set_black(root-\u0026gt;rb_node);//将根节点设置为黑色（保持性质2） } 情形一 ​\t新节点在树的根节点上，只需将根节点重置为黑色，保持性质2。\n情形二 ​\t新节点的父亲节点为黑色，所以性质4没有失效，由于每次新增加的节点都为红色，尽管新节点存在两个黑色叶子节点，但是通過它的每个子节点的路径和它所取代的黑色的叶子的路径具有相同数目的黑色节点，所以满足性质5\n情形三 ​\t存在在叔叔节点，父亲节点和叔叔节点都为红色，将父亲节点和叔叔节点都置为黑色，再将祖父节点置为红色 ，这样就保持了性质5；紅色的祖父节点可能是根节点，这就违反了性质2，也有可能祖父节点的父节点是紅色的，这就违反了性质4；这种情形下需将祖父节点当成是新加入的节点进行各种情形的檢查。\n注意：在余下的情形下，假设父亲节点是在祖父节点左侧，如果父亲节点是在祖父节点右侧，情形4和情形5中的左和右应当对调。\n情形四 ​\t当父亲节点为红色，叔叔节点缺失或为黑色，新节点为其父亲节点的右侧时，其父亲节点在祖父节点左侧；针对父亲节点进行一次左旋转，并将新节点位置和其父亲节点位置进行交换；完成这种情形后，还需解决仍然失效的性质4，那就进行情形5处理；\n情形五 ​\t当父亲节点为红色，叔叔节点缺失或为黑色，新节点为其父亲节点的左侧时，其父亲节点在祖父节点左侧；将父亲节点置为黑色，在将祖父节点置为红色，并针对祖父节点进行一次右旋转，使其结果满足性质4；性质5也仍然保持滿足，因为通过这三個节点中任何一個的所有路径以前都通过祖父节点，現在它們都通过以前的父节点。在各自的情形下，这都是三个节点中唯一的黑色节点。\n删除 ​\t删除是红黑树最复杂的操作；红黑树的删除操作也包括两部分工作：一查找目标结点；二是删除后重新调整平衡。\n具体代码如下：\nvoid rb_erase(struct rb_node *node, struct rb_root *root) { struct rb_node *child, *parent; int color; if (!node-\u0026gt;rb_left)//不存在左子节点 child = node-\u0026gt;rb_right; else if (!node-\u0026gt;rb_right)//不存在右子节点 child = node-\u0026gt;rb_left; else//存在两个子节点 { struct rb_node *old = node, *left; node = node-\u0026gt;rb_right;//将右孩子节点设置当前节点 while ((left = node-\u0026gt;rb_left) != NULL)//找到old节点右侧的最小值节点 node = left; //将old节点与其父亲节点脱离，并将其位置替换其右侧最小值节点 if (rb_parent(old)) { if (rb_parent(old)-\u0026gt;rb_left == old) rb_parent(old)-\u0026gt;rb_left = node; else rb_parent(old)-\u0026gt;rb_right = node; } else root-\u0026gt;rb_node = node; child = node-\u0026gt;rb_right; parent = rb_parent(node); color = rb_color(node); if (parent == old) { parent = node; } else { //node节点脱离原先的位置，如果node节点存在右子节点，将其的位置由右子节点代替 if (child) rb_set_parent(child, parent); parent-\u0026gt;rb_left = child; //node节点继承old节点的右孩子节点 node-\u0026gt;rb_right = old-\u0026gt;rb_right; rb_set_parent(old-\u0026gt;rb_right, node); } //并继承old节点的父亲节点和左子节点 node-\u0026gt;rb_parent_color = old-\u0026gt;rb_parent_color; node-\u0026gt;rb_left = old-\u0026gt;rb_left; rb_set_parent(old-\u0026gt;rb_left, node); goto color;//重新调整平衡 } //old节点只存在一个孩子节点或者没有孩子节点 parent = rb_parent(node); color = rb_color(node); if (child) rb_set_parent(child, parent); if (parent) { if (parent-\u0026gt;rb_left == node) parent-\u0026gt;rb_left = child; else parent-\u0026gt;rb_right = child; } else root-\u0026gt;rb_node = child; color: //如果存在两个子节点时，如何新的节点时黑色，需重新调整平衡 //如果old节点存在一个或者不存在子节点，old节点为黑色，也需重新调整平衡 if (color == RB_BLACK) __rb_erase_color(child, parent, root); } static void __rb_erase_color(struct rb_node *node, struct rb_node *parent, struct rb_root *root) { struct rb_node *other; while ((!node || rb_is_black(node)) \u0026amp;\u0026amp; node != root-\u0026gt;rb_node)//node节点是黑色，而不为根节点 { if (parent-\u0026gt;rb_left == node)//node节点在其父亲节点左侧时 { other = parent-\u0026gt;rb_right; if (rb_is_red(other)) { //情形二：当node的兄弟节点为红色时，将node节点和其兄弟节点设置为黑色，父节点设置为黑色，并且针对父节点进行左旋转一次 rb_set_black(other); rb_set_red(parent); __rb_rotate_left(parent, root); other = parent-\u0026gt;rb_right; } if ((!other-\u0026gt;rb_left || rb_is_black(other-\u0026gt;rb_left)) \u0026amp;\u0026amp; (!other-\u0026gt;rb_right || rb_is_black(other-\u0026gt;rb_right))) { //情形三 //如果兄弟节点的不存在孩子节点或者孩子节点都为黑色时，将兄弟节点置成红色，并且找到祖父节点 rb_set_red(other); node = parent; parent = rb_parent(node); //针对node的父亲节点重新调整平衡，重新回到循环 } else { if (!other-\u0026gt;rb_right || rb_is_black(other-\u0026gt;rb_right)) {// 如果兄弟节点的不存在右子节点或者右子节点为黑色； //将兄弟节点的左孩子置为黑色，自己置成红色，并且针对兄弟节点进行一些右旋转一次 rb_set_black(other-\u0026gt;rb_left); rb_set_red(other); __rb_rotate_right(other, root); other = parent-\u0026gt;rb_right;//找到新的兄弟节点 } rb_set_color(other, rb_color(parent));//将兄弟节点的颜色设置成与父节点相同 rb_set_black(parent);//将父节点设置成黑色 rb_set_black(other-\u0026gt;rb_right);//兄弟的节点的右子节点设置为黑色 __rb_rotate_left(parent, root);//在针对父节点左旋转一次 node = root-\u0026gt;rb_node;//退出循环，已经为保证红黑树的基本属性 break; } } else {//node节点在其父亲节点右侧时，和在左侧的处理方式一样， other = parent-\u0026gt;rb_left; if (rb_is_red(other)) { rb_set_black(other); rb_set_red(parent); __rb_rotate_right(parent, root); other = parent-\u0026gt;rb_left; } if ((!other-\u0026gt;rb_left || rb_is_black(other-\u0026gt;rb_left)) \u0026amp;\u0026amp; (!other-\u0026gt;rb_right || rb_is_black(other-\u0026gt;rb_right))) { rb_set_red(other); node = parent; parent = rb_parent(node); } else { if (!other-\u0026gt;rb_left || rb_is_black(other-\u0026gt;rb_left)) { rb_set_black(other-\u0026gt;rb_right); rb_set_red(other); __rb_rotate_left(other, root); other = parent-\u0026gt;rb_left; } rb_set_color(other, rb_color(parent)); rb_set_black(parent); rb_set_black(other-\u0026gt;rb_left); __rb_rotate_right(parent, root); node = root-\u0026gt;rb_node; break; } } } if (node)//将根节点置成黑色 rb_set_black(node); } 情形一 新节点在树的根节点上，删除黑色的根节点。\n注意：在情形2、5和6下，我们假定N是它父亲的左儿子。如果它是右儿子，则在这些情形下的左和右应当对调。\n情形二 当node的兄弟节点为红色时，并且针对父节点进行左旋转一次，把红色兄弟转换成node的祖父，我们接着对调node的父亲和祖父的颜色。尽管所有路径上黑色节点的数目没有改变，但现在N有了一个黑色的兄弟和一个红色的父亲，所以我们可以接下去按情形4、情形5或情形6来处理。\n情形三 在父节点和兄弟节点、兄弟节点的孩子节点都是黑色的情况下，将兄弟节点置成红色，。结果是通过兄弟节点的所有路径，它们就是以前不通过node的那些路径，都少了一个黑色节点。因为删除N的初始的父亲使通过N的所有路径少了一个黑色节点，这使事情都平衡了起来。但是，通过父节点的所有路径现在比不通过父节点的路径少了一个黑色节点，所以仍然违反性质5。所以需针对node的父亲节点重新调整平衡；\n情形四 兄弟节点是黑色，兄弟节点的左儿子是红色，兄弟节点的右儿子是黑色，而node是它父亲的左儿子。在这种情形下我们在兄弟节点上做右旋转，这样兄弟节点的左儿子成为兄弟节点的父亲和node的新兄弟。我们接着交换兄弟节点和它的新父亲的颜色。所有路径仍有同样数目的黑色节点，但是现在node有了一个黑色兄弟，他的右儿子是红色的，所以我们进入了情形6。node和它的父亲都不受这个变换的影响。\n情形五 兄弟节点和兄弟节点的儿子都是黑色，但是node的父亲是红色。在这种情形下，我们简单的交换N的兄弟和父亲的颜色。这不影响不通过N的路径的黑色节点的数目，但是它在通过N的路径上对黑色节点数目增加了一，添补了在这些路径上删除的黑色节点。\n情形六 兄弟节点是黑色，兄弟节点的右儿子是红色，而node是它父亲的左儿子。在这种情形下我们在N的父亲上做左旋转，这样兄弟节点成为N的父亲节点和兄弟节点的右儿子的父亲。我们接着交换N的父亲和兄弟节点的颜色，并使兄弟节点的右儿子为黑色。子树在它的根上的仍是同样的颜色，所以性质3没有被违反。但是，N现在增加了一个黑色祖先：要么node的父亲变成黑色，要么它是黑色而兄弟节点被增加为一个黑色祖父。所以，通过node的路径都增加了一个黑色节点。\n此时，如果一个路径不通过node，则有两种可能性：\n它通过node的新兄弟。那么它以前和现在都必定通过兄弟节点和node的父亲，而它们只是交换了颜色。所以路径保持了同样数目的黑色节点。 它通过node的新叔父，兄弟节点的右儿子。那么它以前通过兄弟节点、兄弟节点的父亲和兄弟节点的右儿子，但是现在只通过兄弟节点，它被假定为它以前的父亲的颜色，和S的右儿子，它被从红色改变为黑色。合成效果是这个路径通过了同样数目的黑色节点。 在任何情况下，在这些路径上的黑色节点数目都没有改变。所以我们恢复了性质4。在示意图中的白色节点可以是红色或黑色，但是在变换前后都必须指定相同的颜色。\n外部链接 参考维基百科和linux内核中的红黑树，以帮助自我记忆和学习；\n维基百科\nLinux内核实现的红黑树\n某大神\n","permalink":"https://rong05.github.io/learn/data-structure_learn/read_black_ree/","summary":"红黑树 ​\t红黑树（英语：Red–black tree）是一种自平衡二叉查找树,红黑树的结构复杂，但它的操作有着良好的最坏情形运行时间，查找、插入和删除时间复杂度为O(logn)。\n​\t其实红黑树也是二叉查找树的一种，二叉查找树在最坏的情形下可能会变成一个链表（当所有 节点按从小到大的顺序依次插入后）；这样树的平衡性被破坏，要提高查询效率需要维持这种平衡和降低树的高度，而其中可性的做法就是用策略在每次修改树的内容之后进行结构调整，使其保持一定的平衡条件；而红黑树就是其中一员。\n优点 ​\t红黑树在插入时间、删除时间和查找时间提供最好可能的最坏情形担保，多数用时间敏感或者实时性强的应用中。\n​\t红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入和删除操作时少量的旋转操作，整体来说性能要优于AVL树\n性质 ​\t红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。还需遵循以下规则：\n节点分为红色或者黑色 根节点比必须是黑色 所有叶子都是黑色（叶子是NIL节点，或者称为空（NULL）叶子） 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 红黑树的图例：\n操作 ​\t在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质，因此需对红黑树进行性质的恢复，但必须做到少量O(logn)的颜色变更,而且不超过三次树旋转（对于插入操作是两次）；由此可以看出红黑树的插入和删除复杂，但是操作时间仍然可以保持O(logn)\n树旋转 ​\t树旋转是不影响元素顺序，但会改变树的结构，将一个节点上移、一个节点下移；\n​\t左孩子旋转到父节点的位置为右旋；\n​\t右孩子旋转到父节点的位置为左旋；\n​\t红黑树的左旋代码如下：\nstatic void __rb_rotate_left(struct rb_node *node, struct rb_root *root) { struct rb_node *right = node-\u0026gt;rb_right;//取出node的右节点 struct rb_node *parent = rb_parent(node);//取出node的父亲节点 if ((node-\u0026gt;rb_right = right-\u0026gt;rb_left))//node的右子节点指向right的左子节点时 rb_set_parent(right-\u0026gt;rb_left, node);//并将right的左子节点与right脱离，right的左子节点的父亲节点指向node right-\u0026gt;rb_left = node;//将right的左子节点重新指向node /**** 到现在就完成了，node右侧树与node脱离，接下来就是将脱离的右侧树重新连接parent *****/ rb_set_parent(right, parent);//将right的父亲节点指向node父亲节点 if (parent)//node非根节点 { if (node == parent-\u0026gt;rb_left)//判断node所在parent的方向并将parent对应的节点重新指向right parent-\u0026gt;rb_left = right; else parent-\u0026gt;rb_right = right; } else //node是根节点，那将right设置为根节点 root-\u0026gt;rb_node = right; rb_set_parent(node, right);//最后将node的父亲节点设置为right } 红黑树的右旋代码如下：","title":""}]
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LEAN</title>
    <link>https://rong05.github.io/</link>
    <description>Recent content on LEAN</description>
    <image>
      <title>LEAN</title>
      <url>https://rong05.github.io/papermod-cover.png</url>
      <link>https://rong05.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://rong05.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/android/android_binder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/android/android_binder/</guid>
      <description>Binder通讯原理 基于Android 11的源码剖析，笔记记录binder通讯原理的实现过程；
根据网络上的各路大神案例，都是从典型的mediaserver进程开始分析，binder服务的注册注册过程；
mediaserver进程启动的main函数开始分析，至于init.rc的注册启动进程就跳过了；main函数代码如下：
int main(int argc __unused, char **argv __unused) { signal(SIGPIPE, SIG_IGN); //创建与binder驱动交互和binder线程池的管理者 sp&amp;lt;ProcessState&amp;gt; proc(ProcessState::self()); //获取ServiceManager的客户端BpServiceManager sp&amp;lt;IServiceManager&amp;gt; sm(defaultServiceManager()); ALOGI(&amp;#34;ServiceManager: %p&amp;#34;, sm.get()); //创建MediaPlayerService服务，和向ServiceManager注册服务 MediaPlayerService::instantiate(); ResourceManagerService::instantiate(); registerExtensions(); ::android::hardware::configureRpcThreadpool(16, false); //启动binder线程池 ProcessState::self()-&amp;gt;startThreadPool(); IPCThreadState::self()-&amp;gt;joinThreadPool(); ::android::hardware::joinRpcThreadpool(); } Binder线程池的注册 每个采用 Binder 的进程会有一个或多个用于处理接收数据的线程，位于 Binder 线程池。采用 Binder 机制的进程最典型的就是应用程序进程了。那应用程序进程的 Binder 线程池是在什么时候启动的呢？
ProcessState 源码位置：frameworks/native/libs/binder/ProcessState.cpp
ProcessState 是 Binder 机制核心之一，它是 Binder 通信的基础，负责与 Binder 驱动的交互与 Binder 线程池的管理。它实现了单例模式，通过 self() 函数获取实例，每个进程仅有一个。
ProcessState创建 实现了单例模式，通过 self() 函数获取实例。来看看它的构造函数，如下：
ProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//访问binder设备，并与binder驱动交互 , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mBinderContextCheckFunc(nullptr) , mBinderContextUserData(nullptr) , mThreadPoolStarted(false) , mThreadPoolSeq(1) , mCallRestriction(CallRestriction::NONE) { // TODO(b/139016109): enforce in build system #if defined(__ANDROID_APEX__) LOG_ALWAYS_FATAL(&amp;#34;Cannot use libbinder in APEX (only system.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/android/android_selinux/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/android/android_selinux/</guid>
      <description>android SELinux权限配置 SELinux policy介绍 ​	SELinux中，每种东西都会被赋予一个安全属性，就是SContext一个字符串，主要由三部分组成。
进程的SContext ​	进程的SContext可通过ps -Z命令来查看，如下图所示：
​	以第一个进程/init的SContext为例，其值是u:r:init:s0,其中：
u为user的意思，一个SELinux用户 r为role的意思 init，代表该进程所属的domain为init s0为进程的级别 文件的SContext ​	文件的SContext可通过ls -Z来查看，如下图所示：
​	以最常见到的audioserver为例，其信息为u:object_r:audioserver_exec:s0:
u为user的意思，一个SELinux用户 object_r:文件的角色 audioserver_exec：代表该进程所属的domain为audioserver_exec，而exec表示该文件是可执行文件 s0为进程的级别 根据SELinux规范，完整的SContext字符串为：user:role:type[:range]；注意方括号中的内容表示可选项。
android源码中的SELinux定义 在android平台定制的SELinux，是通过编译sepolicy；（android7.0开始目录为system/sepolicy，而在device目录下有不同厂商的定义自己的sepolicy文件夹）
​	system/sepolicy：提供了Android平台中的安全策略源文件。同时，该目录下的tools还提供了诸如m4,checkpolicy等编译安全策略文件的工具。注意，这些工具运行于主机（即不是提供给Android系统使用的） external/libselinux：提供了Android平台中的libselinux，供Android系统使用。 external/libsepol：提供了供安全策略文件编译时使用的一个工具checkcon。 对我们而言，最重要的还是external/sepolicy。通过如下make命令查看执行情况： mmm system/sepolicy &amp;ndash;just-print
sepolicy的重头工作是编译sepolicy安全策略文件。这个文件来源于众多的te文件，初始化相关的文件（initial_sid,initial_sid_context,users,roles,fs_context等）。 file_context：该文件记载了不同目录的初始化SContext，所以它和死货打标签有关。 seapp_context：和Android中的应用程序打标签有关。 property_contexts：和Android系统中的属性服务（property_service）有关，它为各种不同的属性打标签。 SELinux分为两种模式，android 5.0后所有进程都是使用enforcing mode
enforcing mode ： 限制访问 permissive mode： 只审查权限，不限制 SELinux Policy文件路径
# Google原生目录 external/sepolicy (android7.0开始目录为system/sepolicy) #厂家目录,高通将mediatek 换为 qcom alps\device\mediatek\common\sepolicy alps\device\mediatek\&amp;lt;platform&amp;gt;\sepolicy 问题分析 ​	当在android系统执行过程中SELinux权限缺失时，会报如下错误，我们可以根据错误内容进行对应的权限添加；
​	type=1400 audit(862271.000:14): avc: denied { read write } for pid=666 comm=&amp;quot;cookoosvc&amp;quot; name=&amp;quot;ttyHSL3&amp;quot; dev=&amp;quot;tmpfs&amp;quot; ino=14643 scontext=u:r:cookoosvc:s0 tcontext=u:object_r:quec_device:s0 tclass=chr_file permissive=0</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/android/binder_driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/android/binder_driver/</guid>
      <description>Binder Driver探索 binder驱动的初始化 在binder.c中有以下一行代码；
device_initcall(binder_init); 在Linux内核的启动过程中，一个驱动的注册用module_init调用，即device_initcall，它可以将驱动设备加载进内核中，以供后续使用。
在Android8.0之后，现在Binder驱动有三个：/dev/binder; /dev/hwbinder; /dev/vndbinder.
static int __init binder_init(void) { int ret; char *device_name, *device_tmp; struct binder_device *device; struct hlist_node *tmp; char *device_names = NULL; //初始化binder缓冲区分配 ret = binder_alloc_shrinker_init(); if (ret) return ret; // ~0U：无符号整型，对0取反。 atomic_set(&amp;amp;binder_transaction_log.cur, ~0U); atomic_set(&amp;amp;binder_transaction_log_failed.cur, ~0U); // 创建/sys/kernel/debug/binder目录。 binder_debugfs_dir_entry_root = debugfs_create_dir(&amp;#34;binder&amp;#34;, NULL); // 创建/sys/kernel/debug/binder/proc目录用于记录每个进程基本信息。 if (binder_debugfs_dir_entry_root) binder_debugfs_dir_entry_proc = debugfs_create_dir(&amp;#34;proc&amp;#34;, binder_debugfs_dir_entry_root); if (binder_debugfs_dir_entry_root) { // 创建/sys/kernel/debug/binder/state文件用于记录状态信息， //并注册操作函数binder_state_fops。 debugfs_create_file(&amp;#34;state&amp;#34;, 0444, binder_debugfs_dir_entry_root, NULL, &amp;amp;binder_state_fops); // 创建/sys/kernel/debug/binder/stats文件用于记录统计信息， //并注册操作函数binder_stats_fops。 debugfs_create_file(&amp;#34;stats&amp;#34;, 0444, binder_debugfs_dir_entry_root, NULL, &amp;amp;binder_stats_fops); // 创建/sys/kernel/debug/binder/transactions文件用于记录transaction相关信息， //并注册操作函数binder_transactions_fops。 debugfs_create_file(&amp;#34;transactions&amp;#34;, 0444, binder_debugfs_dir_entry_root, NULL, &amp;amp;binder_transactions_fops); // 创建/sys/kernel/debug/binder/transaction_log文件用于记录transaction日志相关信息， //并注册操作函数binder_transaction_log_fops。 debugfs_create_file(&amp;#34;transaction_log&amp;#34;, 0444, binder_debugfs_dir_entry_root, &amp;amp;binder_transaction_log, &amp;amp;binder_transaction_log_fops); // 创建/sys/kernel/debug/binder/failed_transaction_log文件用于记录transaction失败日志相关信息， // 并注册操作函数binder_transaction_log_fops debugfs_create_file(&amp;#34;failed_transaction_log&amp;#34;, 0444, binder_debugfs_dir_entry_root, &amp;amp;binder_transaction_log_failed, &amp;amp;binder_transaction_log_fops); } if (!</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/android/mediacodec_learn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/android/mediacodec_learn/</guid>
      <description>MediaCodec学习记录 官方API：https://developer.android.google.cn/reference/android/media/MediaCodec
供参考的中文翻译：https://www.jianshu.com/p/06dfc5cf95a2
MediaCodec 介绍 MediaCodec是一个Codec，通过硬件加速解码和编码。它为芯片厂商和应用开发者搭建了一个统一接口。
一个编解码器可以处理输入的数据来产生输出的数据，编解码器使用一组输入和输出缓冲器来异步处理数据。你可以创建一个空的输入缓冲区，填充数据后发送到编解码器进行处理。编解码器使用输入的数据进行转换，然后输出到一个空的输出缓冲区。最后你获取到输出缓冲区的数据，消耗掉里面的数据，释放回编解码器。
MediaCodec采用异步方式处理数据，并且使用了一组输入输出buffer（ByteBuffer）。
使用者从MediaCodec请求一个空的输入buffer（ByteBuffer），填充满数据后将它传递给MediaCodec处理。 MediaCodec处理完这些数据并将处理结果输出至一个空的输出buffer（ByteBuffer）中。 使用者从MediaCodec获取输出buffer的数据，消耗掉里面的数据，使用完输出buffer的数据之后，将其释放回编解码器。 编解码器支持的数据类型： codec 处理3种类型的数据， compressed data （待解码的数据 或 编码后的数据）、raw audio data （待编码或解码后的数据）和 raw video data （待编码或解码后的数据）。
注意：
数据通过ByteBuffers类来表示。还可以用 Surface 来处理 raw video data 来提高性能。 可以设置Surface来获取/呈现原始的视频数据，因为 Surface 可以直接使用 native video buffers （在 native 层分配的 buffer）而不需要映射或拷贝到 ByteBuffers （ByteBuffers 是分配在 JVM 堆中的缓冲区） 中。 通常在使用Surface的时候，无法访问原始的视频数据，但是可以使用ImageReader访问解码后的原始视频帧。在使用ByteBuffer的模式下，可以使用Image类和getInput/OutputImage(int)获取原始视频帧。 压缩数据 MediaFormat#KEY_MIME格式类型。 对于视频类型，通常是一个单独的压缩视频帧。 对于音频数据，通常是一个单独的访问单元(一个编码的音频段通常包含由格式类型决定的几毫秒的音频)，但是这个要求稍微宽松一些，因为一个buffer可能包含多个编码的音频访问单元。 在这两种情况下，buffer都不会在任意字节边界上开始或结束，而是在帧/访问单元边界上开始或结束，除非它们被BUFFER_FLAG_PARTIAL_FRAME标记。 原始音频buffer 原始音频buffer包含PCM音频数据的整个帧，这是每个通道按通道顺序的一个样本。每个样本都是一个 AudioFormat#ENCODING_PCM_16BIT。
原始视频buffer 在ByteBuffer模式下，视频buffer根据它们的MediaFormat#KEY_COLOR_FORMAT进行布局。可以从getCodecInfo(). MediaCodecInfo.getCapabilitiesForType.CodecCapability.colorFormats获取支持的颜色格式。视频编解码器可以支持三种颜色格式:
native raw video format: CodecCapabilities.COLOR_FormatSurface，可以与输入/输出的Surface一起使用。 flexible YUV buffers 例如CodecCapabilities.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/android/mediacodec_source_learn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/android/mediacodec_source_learn/</guid>
      <description>MediaCodec源码学习 在另一个篇文章中已经介绍了MediaCodec的API，详情请看MediaCodec_learn;
主要从MediaCodec源码主要结构入手分析，并基于对主要结构的理解;
整体框架 与Android其他API类似，MediaCodec主要分为API、JNI、Native、service四个部分。
MediaCodec主要框架结构如：
应用代码编写时使用的是java层MediaCodec的接口。这里主要是通过JNI调用Native代码。 进入JNI代码后，主要与JMediaCodec打交道，JMediaCodec负责调用MediaCodec(c++)的方法。 在MediaCodec(c++)和ACodec中包含了解码器（客户端）的主要逻辑。最后ACodec作为MediaCodec与OMX的桥梁，负责调用OMX服务端的功能。 OMX服务端主要是OMX封装层和OMX管理层，其中使用 OpenMax 集成层标准实现的硬件编解码器。（server端不在此篇介绍） 接下来主要看一下client端是如何创建MediaCodec的。
MediaCodec的创建过程 MediaCodec(java)类的构造函数中主要调用了native_setup方法！
private MediaCodec( @NonNull String name, boolean nameIsType, boolean encoder) { Looper looper; //获取创建MediaCodec的当前线程Looper,并且创建事件处理handler if ((looper = Looper.myLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else if ((looper = Looper.getMainLooper()) != null) { mEventHandler = new EventHandler(this, looper); } else { mEventHandler = null; } mCallbackHandler = mEventHandler; mOnFrameRenderedHandler = mEventHandler; mBufferLock = new Object(); // save name used at creation mNameAtCreation = nameIsType ?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/av-learn/ffplay_learn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/av-learn/ffplay_learn/</guid>
      <description>[TOC]
ffplay源码分析 熟悉FFmpeg项目从源码看起，以下是我阅读FFplay的源代码的总结；FFplay是FFmpeg项目提供的播放器示例，它的源代码的量也是不少的，其中很多知识点是我们可以学习和借鉴的。
总结构图 参照雷神（雷霄骅）的FFplay的总体函数调用结构图，自己总结了一个最新版本的结构，其中还有诸多不足，以后有机会慢慢完善；如下图所示。
这就不对主要函数分别解析，我来学习一下其中关键性的思想和ffplay的体系结构。
视频部分 ffplay video的线程模式 ffplay选择了sdl作为显示SDK，以实现跨平台支持；因为使用了SDL，而video的显示也依赖SDL的窗口显示系统，所以先从main函数的SDL初始化看起：
int main(int argc, char **argv) { ... /* register all codecs, demux and protocols */ #if CONFIG_AVDEVICE avdevice_register_all(); //注册所有解码器 #endif avformat_network_init(); init_opts(); signal(SIGINT, sigterm_handler); /* Interrupt (ANSI). */ signal(SIGTERM, sigterm_handler); /* Termination (ANSI). */ show_banner(argc, argv, options); //打印ffmpag库版本信息，编译时间，编译选项，类库信息等 parse_options(NULL, argc, argv, options, opt_input_file); //解析输入的命令。 ... if (SDL_Init(flags)) { //初始化sdl av_log(NULL, AV_LOG_FATAL, &amp;#34;Could not initialize SDL - %s\n&amp;#34;, SDL_GetError()); av_log(NULL, AV_LOG_FATAL, &amp;#34;(Did you set the DISPLAY variable?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/av-learn/rtp_protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/av-learn/rtp_protocol/</guid>
      <description>rtp协议解析 ​	rtp (实时传输协议)是一个网络传输协议，属于应用层协议
​	RTP协议详细说明了在互联网上传递音频和视频的标准数据包格式。它一开始被设计为一个多播协议，但后来被用在很多单播应用中。RTP协议常用于流媒体系统（配合RTSP协议），视频会议和一键通（Push to Talk）系统（配合H.323或SIP），使它成为IP电话产业的技术基础。RTP协议和RTP控制协议RTCP一起使用，而且它是创建在UDP协议上的。
​	rtp被划分在传输层，建立在udp上。同UDP协议一样，为了实现其实时传输功能，RTP也有固定的封装形式。RTP用来为端到端的实时传输提供时间信息和流同步，但并不保证服务质量。服务质量由RTCP来提供。
Rtp协议封装 ​	rtp传输过程中，根据以太网的MTU一般为1500字节，去除ip协议包头、udp协议包头和PPPoE协议内容，rtp数据分组最大值应为1400字节（这个只是标准值，实际值应该按照MTU大小来决定）。
​	注意 RTP 本身没有提供任何的机制来确保实时的传输或其他的服务质量保证，而是由低层的服务来完成。它不保证传输或防止乱序传输,它不假定下层网络是否可靠,是否按顺序传送数据包。RTP 包含的序列号允许接受方重构发送方的数据包顺序，但序列号也用来确定一个数据包的正确位置,例如,在视频解码的时候不用按顺序的对数据包进行解码。
rtp head ​
​	rtp头结构体的定义中大端和小端模式是有区别的，需要区分对待。
​	前 12 个字节出现在每个 RTP 包中，仅仅在被混合器插入时，才出现 CSRC 识别符列表。各个域的含义如下所示：
版本(version)：2 比特，此域定义了 RTP 的版本。此协议定义的版本是 2。(值 1 被 RTP 草案版本使用,值 0 用在最初&amp;quot;vat&amp;quot;语音工具使用的协议中。)
填充(P)：1 比特，若填料比特被设置,则此包包含一到多个附加在末端的填充比特,填充比特不算作负载的一部分。填充的最后一个字节指明可以忽略多少个填充比特。填充可能用于某些具有固定长度的加密算法，或者用于在底层数据单元中传输多个 RTP 包。
扩展(X)：1 比特，若设置扩展比特,固定头(仅)后面跟随一个头扩展。
CSRC 计数(CC)：4 比特，CSRC 计数包含了跟在固定头后面 CSRC 识别符的数目。
标志(M)：1 比特，标志的解释由具体协议规定。它用来允许在比特流中标记重要的事件,如帧边界。
负载类型(PT)：7 比特，此域定义了负载的格式，由具体应用决定其解释，协议可以规定负载类型码和负载格式之间一个默认的匹配。其他的负载类型码可以通过非 RTP 方法动态定义。RTP发送端在任意给定时间发出一个单独的 RTP 负载类型；此域不用来复用不同的媒体流。
序列号(sequence number)：16 比特，每发送一个 RTP 数据包,序列号加 1，接收端可以据此检测丢包和重建包序列。序列号的初始值是随机的(不可预测),以使即便在源本身不加密时(有时包要通过翻译器,它会这样做)，对加密算法泛知的普通文本攻击也会更加困难。
时间戳(timestamp) ：32 比特，时间戳反映了 RTP 数据包中第一个字节的采样时间。时钟频率依赖于负载数据格式,并在描述文件(profile)中进行描述。也可以通过 RTP 方法对负载格式动态描述。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/camera/cmax/camx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/camera/cmax/camx/</guid>
      <description>camx 高通camx框架 目前高通主流芯片使用camera框架基本都是camx架构。 之前旧的架构叫做mm-camera，camx架构和之前架构代码更加复杂、具有较强的客制化。 我们先来看下camx整体的架构图：
camx的框架入口为camx包中的camxhal3entry.cpp，代码路径在vendor/qcom/proprietary/camx/下,编译结果是camera.qcom.so Camx通过chxentensionInterface调用到chi-cdk包下的代码，这里面一般是手机厂商自己定制功能的地方，代码目录在vendor/qcom/proprietary/chi-cdk/，编译结果是com.qti.chi.override.so Chi对Camx的操作，需要通过ExtensionModule进行操作，因此，CamX对外提供的接口扩展需要通过ExtensionModule进行，里面一个重要的变量就是g_chiContextOps。 Camx对Chi的操作，是通过HAL3Module接口的m_ChiAppCallbacks进行的，因此chi里面释放的接口，都会在m_ChiAppCallbacks里面体现。 camera数据通路 在camx框架上大致的camera数据流向如下图：
CSID: 摄像机串行接口解码器模块 IFE：图像前端 IFE_Lite：图像前端 lite BPS：Bayer处理区段 IFE：图像处理引擎 VPU：视频处理单元（编解码器） DPU：显示处理单元 这些都是表示的是芯片内部的一个硬件处理单元，数据在这些单元内部的处理还是比较复杂的，在不同的处理单元里面，会进行一些复杂的算法处理；有个认识，有个基本概念。
Camx基本组件及概念 usecase 是一种抽象概念；高通的介绍是A set of streams configured by the client combined with a set of static properties specifying the processing of those streams(由客户端配置的一组流，这组流是有着一系列静态属性相结合描述的流。)See createCaptureSession in the Android CameraDevice documentation；
具体实现是在CHI中通过Usecase类完成的，该类主要负责了其中的业务处理以及资源的管理。 简单说明：按照android 的Camera2 API来说；把预览的surface和录像的surface都设进去，然后去创建session，就是表示我预览和录像都需要拿到camera数据。假设我预览设置的size是1080 x 720，录像是1080p的，那这个1080 x 720预览+1080p录像就是一个usecase（用例）。
CameraUsecaseBase作为Usecase类的基类提供了一系列通用接口，其中，AdvancedCameraUsecase
又继承于CameraUsecaseBase，相机中绝大部分场景会通过实例化AdvancedCameraUsecase
来完成，它包括了几个主要接口：
create创建AdvancedCameraUsecase实例，并获取相对应的Usecase配置信息 ExecuteCaptureRequest用于下发一次Request ProcessResultCb在创建session时作为回调方法注册到其中，一旦Session数据处理完成的时候便会调用该方法将结果发送到AdvancedCameraUsecase中。 ProcessDriverPartialCaptureResult在创建session时作为回调方法注册到其中，一旦Session中产生了partial meta data的时候，便会调用该方法将其发送至AdvancedCameraUsecase中。 ProcessMessageCb在创建session时作为回调方法注册到其中，一旦Session产生任何事件，便会调用该方法通知到AdvancedCameraUsecase中。 ExecuteFlush用于刷新AdvancedCameraUsecase。 Destroy用于安全销毁AdvancedCameraUsecase。 Feature 代表一个特定的功能。高通上的feature有HDR(高动态范围)、SuperNight（超级夜景）、MFNR（多帧降噪）等等,usecase选择相应的feature，然后关联一组pipeline，上层下发request请求，hal层会根据request去选择对应的feature。（feature2内部代码相对复杂，目前还不太了解，还在学习过程中）</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/data-structure_learn/rbtree-master/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/data-structure_learn/rbtree-master/readme/</guid>
      <description>rbtree rbtree implementation adapted from linux kernel thus can be used in your own c program(of course in userspace).</description>
    </item>
    
    <item>
      <title></title>
      <link>https://rong05.github.io/learn/data-structure_learn/read_black_ree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rong05.github.io/learn/data-structure_learn/read_black_ree/</guid>
      <description>红黑树 ​	红黑树（英语：Red–black tree）是一种自平衡二叉查找树,红黑树的结构复杂，但它的操作有着良好的最坏情形运行时间，查找、插入和删除时间复杂度为O(logn)。
​	其实红黑树也是二叉查找树的一种，二叉查找树在最坏的情形下可能会变成一个链表（当所有 节点按从小到大的顺序依次插入后）；这样树的平衡性被破坏，要提高查询效率需要维持这种平衡和降低树的高度，而其中可性的做法就是用策略在每次修改树的内容之后进行结构调整，使其保持一定的平衡条件；而红黑树就是其中一员。
优点 ​	红黑树在插入时间、删除时间和查找时间提供最好可能的最坏情形担保，多数用时间敏感或者实时性强的应用中。
​	红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入和删除操作时少量的旋转操作，整体来说性能要优于AVL树
性质 ​	红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。还需遵循以下规则：
节点分为红色或者黑色 根节点比必须是黑色 所有叶子都是黑色（叶子是NIL节点，或者称为空（NULL）叶子） 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 红黑树的图例：
操作 ​	在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质，因此需对红黑树进行性质的恢复，但必须做到少量O(logn)的颜色变更,而且不超过三次树旋转（对于插入操作是两次）；由此可以看出红黑树的插入和删除复杂，但是操作时间仍然可以保持O(logn)
树旋转 ​	树旋转是不影响元素顺序，但会改变树的结构，将一个节点上移、一个节点下移；
​	左孩子旋转到父节点的位置为右旋；
​	右孩子旋转到父节点的位置为左旋；
​	红黑树的左旋代码如下：
static void __rb_rotate_left(struct rb_node *node, struct rb_root *root) { struct rb_node *right = node-&amp;gt;rb_right;//取出node的右节点 struct rb_node *parent = rb_parent(node);//取出node的父亲节点 if ((node-&amp;gt;rb_right = right-&amp;gt;rb_left))//node的右子节点指向right的左子节点时 rb_set_parent(right-&amp;gt;rb_left, node);//并将right的左子节点与right脱离，right的左子节点的父亲节点指向node right-&amp;gt;rb_left = node;//将right的左子节点重新指向node /**** 到现在就完成了，node右侧树与node脱离，接下来就是将脱离的右侧树重新连接parent *****/ rb_set_parent(right, parent);//将right的父亲节点指向node父亲节点 if (parent)//node非根节点 { if (node == parent-&amp;gt;rb_left)//判断node所在parent的方向并将parent对应的节点重新指向right parent-&amp;gt;rb_left = right; else parent-&amp;gt;rb_right = right; } else //node是根节点，那将right设置为根节点 root-&amp;gt;rb_node = right; rb_set_parent(node, right);//最后将node的父亲节点设置为right } 红黑树的右旋代码如下：</description>
    </item>
    
  </channel>
</rss>
